{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37c8b3ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.utils import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "# from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "from tensorflow.keras import backend \n",
    "from tensorflow.keras import utils\n",
    "\n",
    "from keras_nlp.layers import SinePositionEncoding\n",
    "\n",
    "import pydot\n",
    "\n",
    "from funkcije import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3440ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model_weights_{epoch}.h5', save_best_only=False, save_weights_only=True, monitor='val_loss', mode='min')\n",
    "#Ckeckpoint se vise ne koristi\n",
    "early_stopping = EarlyStopping(patience = 10, restore_best_weights = True, monitor = 'val_loss', mode = 'min', verbose = 1)\n",
    "\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac52b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Translation_Model(Model):\n",
    "    def __init__(self, num_input_words, num_target_words, input_embedding_matrix, target_embedding_matrix, latent_dim = 256, dropout_rate = 0.5, custom_dropout_rate = 0.05):\n",
    "        super(Transformer_Translation_Model, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.custom_dropout_rate = custom_dropout_rate\n",
    "        self.num_input_words = num_input_words\n",
    "        self.num_target_words = num_target_words\n",
    "        self.input_embedding_matrix = input_embedding_matrix\n",
    "        self.target_embedding_matrix = target_embedding_matrix\n",
    "        self.embedding_size = 300\n",
    "        self.input_pad_len = 80\n",
    "        self.target_pad_len = 60\n",
    "        \n",
    "        encoder_inputs = Input(shape=(self.input_pad_len,))\n",
    "        x = CustomDropout(1.0, custom_dropout_rate)(encoder_inputs)\n",
    "        # x = PositionalEmbedding(input_pad_len, num_input_words + 1, embedding_size)(encoder_inputs)\n",
    "        encoder_embedding = Embedding(input_dim = num_input_words + 1, output_dim = embedding_size, mask_zero = True, weights = [input_embedding_matrix], trainable = False)(x)\n",
    "        encoder_pos_encoding = SinePositionEncoding()(encoder_embedding)\n",
    "        x = encoder_embedding + encoder_pos_encoding\n",
    "        # encoder_outputs = TransformerEncoder(embedding_size, latent_dim, num_heads)(x)\n",
    "        for i in range(num_transformer_layers):\n",
    "            xt = MultiHeadAttention(num_heads=num_heads, key_dim=self.embedding_size)(x, x, x)\n",
    "            x = LayerNormalization()(x + xt)\n",
    "            xt = Dense(self.latent_dim, activation=\"relu\") (x)\n",
    "            xt = Dense(self.embedding_size) (xt)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "        encoder_outputs = x\n",
    "        self.encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "        \n",
    "        decoder_inputs = Input(shape=(self.target_pad_len,))\n",
    "        encoded_seq_inputs = Input(shape=(self.input_pad_len, self.embedding_size))\n",
    "        # x = PositionalEmbedding(target_pad_len, num_target_words + 1, embedding_size)(decoder_inputs)\n",
    "        decoder_embedding = Embedding(input_dim = num_input_words + 1, output_dim = self.embedding_size, mask_zero = True, trainable = True)(decoder_inputs)\n",
    "        decoder_pos_encoding = SinePositionEncoding()(decoder_embedding)\n",
    "        x = decoder_embedding + decoder_pos_encoding\n",
    "        # x = TransformerDecoder(embedding_size, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "        for i in range(num_transformer_layers):\n",
    "            causal_mask = self.get_causal_attention_mask(x)\n",
    "            xt = MultiHeadAttention(num_heads=num_heads, key_dim=self.embedding_size) (x, x, x, attention_mask=causal_mask)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "            xt = MultiHeadAttention(num_heads=num_heads, key_dim=self.embedding_size) (x, encoded_seq_inputs, encoded_seq_inputs)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "            xt = Dense(latent_dim, activation=\"relu\") (x)\n",
    "            xt = Dense(self.embedding_size) (xt)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "        x = layers.Dropout(self.dropout_rate)(x)\n",
    "        decoder_outputs = layers.Dense(num_target_words + 1, activation=\"softmax\")(x)\n",
    "        self.decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "        \n",
    "        decoder_outputs = self.decoder([decoder_inputs, encoder_outputs])\n",
    "        self.transformer = keras.Model(\n",
    "            [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    "        )\n",
    "        print(self.transformer.summary(expand_nested=True))\n",
    "        utils.plot_model(self.transformer, show_shapes=True, expand_nested=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.transformer([x[0], x[1]])\n",
    "        \n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "    \n",
    "    def translate(self, encoder_input, decoder_input):\n",
    "        return self.transformer([encoder_input, decoder_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06158376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trenira model na train_data i evaluira ga na val_data\n",
    "#Embedding learning rate je poseban learning_rate koji se koristi u embedding slojevima, iz razloga sto oni vec imaju pretrenirane podatke za pocetne vrednosti\n",
    "#Model se trenira dok val_loss ne krene da raste, i cuva tezine epohe koja ima najbolji val_loss\n",
    "#Koristi se u cv_evaluate, napravio funkciju jer inace dolazi do prekoracenje GPU RAMa, neko je napisao da je do unakrsne validacije\n",
    "def train_and_evaluate(train_data, val_data, epochs = 200, batch_size = 128, learning_rate = 0.001, latent_dim = 256, dropout_rate = 0.5, embedding_learning_rate = 0.001):\n",
    "     \n",
    "     input_texts, target_texts = clean_texts(train_data.iloc[:,1], train_data.iloc[:,0])\n",
    "     input_word_index, target_word_index, max_input_seq_len, max_target_seq_len = analyse_texts(input_texts, target_texts)\n",
    "     input_pad_len = 80\n",
    "     target_pad_len = 60\n",
    "     num_input_words = len(input_word_index) - 1\n",
    "     num_target_words = len(target_word_index) - 1\n",
    "     #print(num_input_words)\n",
    "     inverted_input_word_index = {value: key for key,value in input_word_index.items()}\n",
    "     inverted_target_word_index = {value: key for (key,value) in target_word_index.items()}\n",
    "     #print(len(inverted_input_word_index))\n",
    "     input_embedding_matrix, target_embedding_matrix = load_embedding_data_get_matrices(inverted_input_word_index, inverted_target_word_index)\n",
    "     print('Embeddings loaded.')\n",
    "     encoder_input_data, decoder_input_data, decoder_output_data = create_model_data(input_texts, target_texts, input_word_index, target_word_index, input_pad_len, target_pad_len)\n",
    "     #print(input_embedding_matrix.shape)\n",
    "     \n",
    "     input_texts_val, target_texts_val = clean_texts(val_data.iloc[:,1], val_data.iloc[:,0])\n",
    "     encoder_input_data_val, decoder_input_data_val, decoder_output_data_val = create_model_data(input_texts_val, target_texts_val, input_word_index, target_word_index, input_pad_len, target_pad_len)\n",
    "     \n",
    "     #print('Data preprocessed.')\n",
    "     model_transformer = Transformer_Translation_Model(num_input_words, num_target_words, input_embedding_matrix, target_embedding_matrix, latent_dim = latent_dim, dropout_rate = dropout_rate)\n",
    "     #print('Model loaded.')\n",
    "     other_layers = model_transformer.layers #Mora da se prilagodi za transformer\n",
    "     embedding_layers = [] #Paznja! Mora se prilagoditi svaki put kad se model menja\n",
    "\n",
    "     optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers = [(Adam(learning_rate), other_layers), (Adam(embedding_learning_rate), embedding_layers)])\n",
    "     model_transformer.compile(optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "     #print('Model compiled.')\n",
    "     history = model_transformer.fit([encoder_input_data, decoder_input_data], decoder_output_data, validation_data = ([encoder_input_data_val, decoder_input_data_val], decoder_output_data_val), epochs = epochs, batch_size = batch_size, callbacks = [early_stopping], verbose = 1)\n",
    "     #print('Model fit.')\n",
    "     best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "     \n",
    "     #print('Best epoch: ', best_epoch)\n",
    "     best_loss = np.min(history.history['val_loss'])\n",
    "     #print('Best loss:', best_loss)\n",
    "     #print(model_transformer.evaluate([encoder_input_data_val, decoder_input_data_val], decoder_output_data_val))\n",
    "     \n",
    "     wer, smooth_bleu4, smooth_bleu3, smooth_bleu2, smooth_bleu1 = evaluate(model_transformer, input_texts_val, target_texts_val, input_word_index, target_word_index, inverted_target_word_index, input_pad_len, target_pad_len)\n",
    "     return best_epoch, best_loss, wer, smooth_bleu4, smooth_bleu3, smooth_bleu2, smooth_bleu1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e4d380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trenira po model za svaki fold, racuna WER, smooth BLEU(1,2,3,4), kao i val_loss i broj epoha do konvergencije\n",
    "#Vraca podatke iz svake instance modela, odnosno za svaki fold, da bi se dalje procesirale\n",
    "def cv_evaluate(train_val_data = None, df_folds = None, folds = 5, epochs = 200, batch_size = 128, learning_rate = 0.001, latent_dim = 256, dropout_rate = 0.5, embedding_learning_rate = None):\n",
    "    if embedding_learning_rate == None:\n",
    "        embedding_learning_rate = learning_rate\n",
    "    if df_folds == None:\n",
    "        df_np = train_val_data.to_numpy()\n",
    "        np.random.shuffle(df_np)\n",
    "        total_size = df_np.shape[0]\n",
    "        fold_size = total_size/folds\n",
    "        df_folds = [df_np[int(i*fold_size):int((i+1)*fold_size),] for i in range(folds)]\n",
    "    #input_word_embeddings, target_word_embeddings = load_embedding_data() #Doslo je do prekoracenje memorije\n",
    "    losses = []\n",
    "    best_epochs = []\n",
    "    wers = []\n",
    "    smooth_bleu1s = []\n",
    "    smooth_bleu2s = []\n",
    "    smooth_bleu3s = []\n",
    "    smooth_bleu4s = []\n",
    "    for i in range(folds):\n",
    "        train_folds = [fold for j, fold in enumerate(df_folds) if j!=i]\n",
    "        train_folds_pd = [pd.DataFrame(data = fold) for fold in train_folds]\n",
    "        train_data = pd.concat(train_folds_pd)\n",
    "        val_data = pd.DataFrame(df_folds[i])\n",
    "        print('Current Latent Dim:', latent_dim)\n",
    "        print('Current Dropout Rate: ', dropout_rate)\n",
    "        print('Current Fold: {}/{}'.format(i+1, folds))\n",
    "        print('Current Learning Rate: ', learning_rate)\n",
    "        print('Current Learning Rate Multiplier: ', embedding_learning_rate/learning_rate)\n",
    "        \n",
    "        best_epoch, best_loss, wer, smooth_bleu4, smooth_bleu3, smooth_bleu2, smooth_bleu1 = train_and_evaluate(train_data, val_data, epochs = epochs, batch_size = batch_size, learning_rate = learning_rate, latent_dim = latent_dim, dropout_rate = dropout_rate, embedding_learning_rate = embedding_learning_rate)\n",
    "        best_epochs.append(best_epoch)\n",
    "        losses.append(best_loss)\n",
    "        wers.append(wer)\n",
    "        smooth_bleu4s.append(smooth_bleu4)\n",
    "        smooth_bleu3s.append(smooth_bleu3)\n",
    "        smooth_bleu2s.append(smooth_bleu2)\n",
    "        smooth_bleu1s.append(smooth_bleu1)\n",
    "    return best_epochs, losses, wers, smooth_bleu4s, smooth_bleu3s, smooth_bleu2s, smooth_bleu1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb8f5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluira modele za razlicite vrednosti latent_dim i dropout_rate\n",
    "#U 3d matrici cuva rezultate, treca dimenzija predstavlja vrednosti za razlicite foldove, uprosecavanjem se dobija zeljena metrika\n",
    "#Isto cuva i broj epoha do konvergencije \n",
    "def cv_grid_search(df, dropout_rates, latent_dims, epochs = 200, learning_rate = 0.0002, folds = 5):\n",
    "    df_np = df.to_numpy()\n",
    "    np.random.shuffle(df_np)\n",
    "    total_size = df_np.shape[0]\n",
    "    fold_size = total_size/folds\n",
    "    df_folds = [df_np[int(i*fold_size):int((i+1)*fold_size),] for i in range(folds)]\n",
    "    \n",
    "    loss_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    epoch_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    wer_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu4_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu3_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu2_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu1_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    for i in range(len(latent_dims)):\n",
    "        for j in range(len(dropout_rates)):\n",
    "            best_epochs, losses, wers, smooth_bleu4s, smooth_bleu3s, smooth_bleu2s, smooth_bleu1s = cv_evaluate(df_folds = df_folds, folds = folds, epochs = epochs, learning_rate = learning_rate, latent_dim = latent_dims[i], dropout_rate = dropout_rates[j])\n",
    "            print(losses)\n",
    "            print(best_epochs)\n",
    "            loss_matrix[i,j,:] = losses\n",
    "            epoch_matrix[i,j,:] = best_epochs\n",
    "            wer_matrix[i,j,:] = wers\n",
    "            smooth_bleu4_matrix[i,j,:] = smooth_bleu4s\n",
    "            smooth_bleu3_matrix[i,j,:] = smooth_bleu3s\n",
    "            smooth_bleu2_matrix[i,j,:] = smooth_bleu2s\n",
    "            smooth_bleu1_matrix[i,j,:] = smooth_bleu1s\n",
    "    #Pakuju se rezultati u dictionary radi intuitivnijeg poziva funkcije\n",
    "    metrics_dict = {'loss': loss_matrix, 'epoch': epoch_matrix, 'wer': wer_matrix, 'smooth_bleu4': smooth_bleu4_matrix, 'smooth_bleu3': smooth_bleu3_matrix, 'smooth_bleu2': smooth_bleu2_matrix, 'smooth_bleu1': smooth_bleu1_matrix }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb591a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/PHOENIX-2014-T.train.corpus.csv', sep='|')\n",
    "df_train = df_train.drop(columns=['name','video','start','end','speaker'])\n",
    "train_size = df_train.shape[0]\n",
    "#Orth je glossovana recenica, translation je originalna engleska\n",
    "\n",
    "df_val = pd.read_csv('data/PHOENIX-2014-T.dev.corpus.csv', sep = '|')\n",
    "df_val.drop(columns = ['name', 'video', 'start', 'end', 'speaker'], inplace = True)\n",
    "val_size = df_val.shape[0]\n",
    "\n",
    "df_test = pd.read_csv('data/PHOENIX-2014-T.test.corpus.csv', sep = '|')\n",
    "df_test.drop(columns = ['name', 'video', 'start', 'end', 'speaker'], inplace = True)\n",
    "test_size = df_test.shape[0]\n",
    "\n",
    "df_train_val = pd.concat([df_train, df_val])\n",
    "df_full = pd.concat([df_train_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c341b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiperparametri za optimizaciju: dropout rate i latentna dimenzija\n",
    "dropout_rates = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "latent_dims = [256, 512, 1024] #Treba probati i vecu latentnu dimenziju i dropout rate, posto optimalna vrednost ispada najveca\n",
    "learning_rate = 0.0002\n",
    "folds = 5\n",
    "\n",
    "num_heads = 8\n",
    "num_transformer_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "036af7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 80)]                 0         []                            \n",
      "                                                                                                  \n",
      " custom_dropout_1 (CustomDr  (None, 80)                   0         ['input_4[0][0]']             \n",
      " opout)                                                                                           \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 80, 300)              588000    ['custom_dropout_1[0][0]']    \n",
      "                                                                                                  \n",
      " sine_position_encoding_2 (  (None, 80, 300)              0         ['embedding_2[0][0]']         \n",
      " SinePositionEncoding)                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, 80, 300)              0         ['embedding_2[0][0]',         \n",
      " OpLambda)                                                           'sine_position_encoding_2[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 80, 300)              2887500   ['tf.__operators__.add_7[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'tf.__operators__.add_7[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.add_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (None, 80, 300)              0         ['tf.__operators__.add_7[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 80, 300)              600       ['tf.__operators__.add_8[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 80, 256)              77056     ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 80, 300)              77100     ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (None, 80, 300)              0         ['layer_normalization_5[0][0]'\n",
      " OpLambda)                                                          , 'dense_6[0][0]']            \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 60)]                 0         []                            \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 80, 300)              600       ['tf.__operators__.add_9[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " model_3 (Functional)        (None, 60, 725)              6737181   ['input_5[0][0]',             \n",
      "                                                                     'layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_5 (InputLayer)       [(None, 60)]                 0         []                           |\n",
      "|                                                                                                |\n",
      "| embedding_3 (Embedding)    (None, 60, 300)              588000    []                           |\n",
      "|                                                                                                |\n",
      "| sine_position_encoding_3   (None, 60, 300)              0         []                           |\n",
      "| (SinePositionEncoding)                                                                         |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.add_10 (  (None, 60, 300)              0         []                           |\n",
      "| TFOpLambda)                                                                                    |\n",
      "|                                                                                                |\n",
      "| tf.compat.v1.shape_1 (TFO  (3,)                         0         []                           |\n",
      "| pLambda)                                                                                       |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_  ()                           0         []                           |\n",
      "| 6 (SlicingOpLambda)                                                                            |\n",
      "|                                                                                                |\n",
      "| tf.range_2 (TFOpLambda)    (60,)                        0         []                           |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_  (60, 1)                      0         []                           |\n",
      "| 7 (SlicingOpLambda)                                                                            |\n",
      "|                                                                                                |\n",
      "| tf.range_3 (TFOpLambda)    (60,)                        0         []                           |\n",
      "|                                                                                                |\n",
      "| tf.math.greater_equal_1 (  (60, 60)                     0         []                           |\n",
      "| TFOpLambda)                                                                                    |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_  ()                           0         []                           |\n",
      "| 5 (SlicingOpLambda)                                                                            |\n",
      "|                                                                                                |\n",
      "| tf.cast_1 (TFOpLambda)     (60, 60)                     0         []                           |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_  ()                           0         []                           |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 8 (SlicingOpLambda)                                                                            |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.getitem_  ()                           0         []                           |\n",
      "| 9 (SlicingOpLambda)                                                                            |\n",
      "|                                                                                                |\n",
      "| tf.expand_dims_1 (TFOpLam  (1,)                         0         []                           |\n",
      "| bda)                                                                                           |\n",
      "|                                                                                                |\n",
      "| tf.reshape_1 (TFOpLambda)  (1, 60, 60)                  0         []                           |\n",
      "|                                                                                                |\n",
      "| tf.concat_1 (TFOpLambda)   (3,)                         0         []                           |\n",
      "|                                                                                                |\n",
      "| tf.tile_1 (TFOpLambda)     (None, 60, 60)               0         []                           |\n",
      "|                                                                                                |\n",
      "| multi_head_attention_4 (M  (None, 60, 300)              2887500   []                           |\n",
      "| ultiHeadAttention)                                                                             |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.add_11 (  (None, 60, 300)              0         []                           |\n",
      "| TFOpLambda)                                                                                    |\n",
      "|                                                                                                |\n",
      "| layer_normalization_7 (La  (None, 60, 300)              600       []                           |\n",
      "| yerNormalization)                                                                              |\n",
      "|                                                                                                |\n",
      "| input_6 (InputLayer)       [(None, 80, 300)]            0         []                           |\n",
      "|                                                                                                |\n",
      "| multi_head_attention_5 (M  (None, 60, 300)              2887500   []                           |\n",
      "| ultiHeadAttention)                                                                             |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.add_12 (  (None, 60, 300)              0         []                           |\n",
      "| TFOpLambda)                                                                                    |\n",
      "|                                                                                                |\n",
      "| layer_normalization_8 (La  (None, 60, 300)              600       []                           |\n",
      "| yerNormalization)                                                                              |\n",
      "|                                                                                                |\n",
      "| dense_7 (Dense)            (None, 60, 256)              77056     []                           |\n",
      "|                                                                                                |\n",
      "| dense_8 (Dense)            (None, 60, 300)              77100     []                           |\n",
      "|                                                                                                |\n",
      "| tf.__operators__.add_13 (  (None, 60, 300)              0         []                           |\n",
      "| TFOpLambda)                                                                                    |\n",
      "|                                                                                                |\n",
      "| layer_normalization_9 (La  (None, 60, 300)              600       []                           |\n",
      "| yerNormalization)                                                                              |\n",
      "|                                                                                                |\n",
      "| dropout_1 (Dropout)        (None, 60, 300)              0         []                           |\n",
      "|                                                                                                |\n",
      "| dense_9 (Dense)            (None, 60, 725)              218225    []                           |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "==================================================================================================\n",
      "Total params: 10368037 (39.55 MB)\n",
      "Trainable params: 9780037 (37.31 MB)\n",
      "Non-trainable params: 588000 (2.24 MB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 12:10:06.009442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-14 12:10:06.064503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-09-14 12:10:06.086892: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4019871a30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-14 12:10:06.086907: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2023-09-14 12:10:06.089859: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-14 12:10:06.187361: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 12s 137ms/step - loss: 1.1698 - acc: 0.8286 - val_loss: 0.8434 - val_acc: 0.8496\n",
      "Epoch 2/200\n",
      "48/48 [==============================] - 4s 76ms/step - loss: 0.8416 - acc: 0.8546 - val_loss: 0.7431 - val_acc: 0.8648\n",
      "Epoch 3/200\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 0.7784 - acc: 0.8637 - val_loss: 0.7206 - val_acc: 0.8674\n",
      "Epoch 4/200\n",
      "48/48 [==============================] - 3s 64ms/step - loss: 0.7441 - acc: 0.8665 - val_loss: 0.6780 - val_acc: 0.8735\n",
      "Epoch 5/200\n",
      "48/48 [==============================] - 3s 57ms/step - loss: 0.7068 - acc: 0.8692 - val_loss: 0.6510 - val_acc: 0.8752\n",
      "Epoch 6/200\n",
      "48/48 [==============================] - 3s 59ms/step - loss: 0.6729 - acc: 0.8732 - val_loss: 0.6201 - val_acc: 0.8798\n",
      "Epoch 7/200\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 0.6369 - acc: 0.8780 - val_loss: 0.5817 - val_acc: 0.8869\n",
      "Epoch 8/200\n",
      "48/48 [==============================] - 3s 60ms/step - loss: 0.6033 - acc: 0.8831 - val_loss: 0.5615 - val_acc: 0.8896\n",
      "Epoch 9/200\n",
      "48/48 [==============================] - 3s 58ms/step - loss: 0.5750 - acc: 0.8873 - val_loss: 0.5348 - val_acc: 0.8944\n",
      "Epoch 10/200\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 0.5465 - acc: 0.8917 - val_loss: 0.5100 - val_acc: 0.8977\n",
      "Epoch 11/200\n",
      "48/48 [==============================] - 3s 58ms/step - loss: 0.5244 - acc: 0.8950 - val_loss: 0.4973 - val_acc: 0.9003\n",
      "Epoch 12/200\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 0.5046 - acc: 0.8979 - val_loss: 0.4787 - val_acc: 0.9030\n",
      "Epoch 13/200\n",
      "48/48 [==============================] - 3s 57ms/step - loss: 0.4888 - acc: 0.9000 - val_loss: 0.4702 - val_acc: 0.9033\n",
      "Epoch 14/200\n",
      "48/48 [==============================] - 3s 61ms/step - loss: 0.4761 - acc: 0.9017 - val_loss: 0.4633 - val_acc: 0.9054\n",
      "Epoch 15/200\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.4608 - acc: 0.9041 - val_loss: 0.4572 - val_acc: 0.9052\n",
      "Epoch 16/200\n",
      "48/48 [==============================] - 3s 53ms/step - loss: 0.4500 - acc: 0.9053 - val_loss: 0.4537 - val_acc: 0.9049\n",
      "Epoch 17/200\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 0.4352 - acc: 0.9075 - val_loss: 0.4437 - val_acc: 0.9078\n",
      "Epoch 18/200\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 0.4296 - acc: 0.9077 - val_loss: 0.4403 - val_acc: 0.9077\n",
      "Epoch 19/200\n",
      "48/48 [==============================] - 3s 58ms/step - loss: 0.4162 - acc: 0.9103 - val_loss: 0.4388 - val_acc: 0.9087\n",
      "Epoch 20/200\n",
      "48/48 [==============================] - 3s 58ms/step - loss: 0.4996 - acc: 0.8971 - val_loss: 0.5179 - val_acc: 0.8915\n",
      "Epoch 21/200\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 0.4543 - acc: 0.9016 - val_loss: 0.4347 - val_acc: 0.9085\n",
      "Epoch 22/200\n",
      "48/48 [==============================] - 3s 58ms/step - loss: 0.4122 - acc: 0.9094 - val_loss: 0.4306 - val_acc: 0.9094\n",
      "Epoch 23/200\n",
      "48/48 [==============================] - 3s 57ms/step - loss: 0.3929 - acc: 0.9130 - val_loss: 0.4301 - val_acc: 0.9097\n",
      "Epoch 24/200\n",
      "48/48 [==============================] - 3s 56ms/step - loss: 0.3814 - acc: 0.9151 - val_loss: 0.4256 - val_acc: 0.9111\n",
      "Epoch 25/200\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.3754 - acc: 0.9156 - val_loss: 0.4182 - val_acc: 0.9120\n",
      "Epoch 26/200\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 0.3661 - acc: 0.9176 - val_loss: 0.4174 - val_acc: 0.9123\n",
      "Epoch 27/200\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.3621 - acc: 0.9178 - val_loss: 0.4187 - val_acc: 0.9126\n",
      "Epoch 28/200\n",
      "48/48 [==============================] - 3s 57ms/step - loss: 0.3529 - acc: 0.9196 - val_loss: 0.4150 - val_acc: 0.9129\n",
      "Epoch 29/200\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.3442 - acc: 0.9208 - val_loss: 0.4156 - val_acc: 0.9131\n",
      "Epoch 30/200\n",
      "48/48 [==============================] - 3s 56ms/step - loss: 0.3455 - acc: 0.9202 - val_loss: 0.4175 - val_acc: 0.9134\n",
      "Epoch 31/200\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.3383 - acc: 0.9215 - val_loss: 0.4140 - val_acc: 0.9134\n",
      "Epoch 32/200\n",
      "48/48 [==============================] - 3s 56ms/step - loss: 0.3318 - acc: 0.9227 - val_loss: 0.4159 - val_acc: 0.9134\n",
      "Epoch 33/200\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.3255 - acc: 0.9239 - val_loss: 0.4136 - val_acc: 0.9141\n",
      "Epoch 34/200\n",
      "48/48 [==============================] - 3s 56ms/step - loss: 0.3157 - acc: 0.9252 - val_loss: 0.4146 - val_acc: 0.9141\n",
      "Epoch 35/200\n",
      "48/48 [==============================] - 3s 56ms/step - loss: 0.3119 - acc: 0.9258 - val_loss: 0.4176 - val_acc: 0.9134\n",
      "Epoch 36/200\n",
      "48/48 [==============================] - 3s 53ms/step - loss: 0.3079 - acc: 0.9264 - val_loss: 0.4197 - val_acc: 0.9136\n",
      "Epoch 37/200\n",
      "48/48 [==============================] - 3s 56ms/step - loss: 0.3025 - acc: 0.9275 - val_loss: 0.4153 - val_acc: 0.9145\n",
      "Epoch 38/200\n",
      "48/48 [==============================] - 3s 56ms/step - loss: 0.2955 - acc: 0.9288 - val_loss: 0.4206 - val_acc: 0.9133\n",
      "Epoch 39/200\n",
      "48/48 [==============================] - 3s 53ms/step - loss: 0.2939 - acc: 0.9288 - val_loss: 0.4189 - val_acc: 0.9140\n",
      "Epoch 40/200\n",
      "48/48 [==============================] - 3s 53ms/step - loss: 0.2866 - acc: 0.9301 - val_loss: 0.4214 - val_acc: 0.9144\n",
      "Epoch 41/200\n",
      "48/48 [==============================] - 3s 53ms/step - loss: 0.2823 - acc: 0.9306 - val_loss: 0.4221 - val_acc: 0.9142\n",
      "Epoch 42/200\n",
      "48/48 [==============================] - 3s 53ms/step - loss: 0.2786 - acc: 0.9311 - val_loss: 0.4220 - val_acc: 0.9143\n",
      "Epoch 43/200\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.2694 - acc: 0.9328Restoring model weights from the end of the best epoch: 33.\n",
      "48/48 [==============================] - 3s 54ms/step - loss: 0.2692 - acc: 0.9329 - val_loss: 0.4302 - val_acc: 0.9144\n",
      "Epoch 43: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 12:12:19.318423: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.09GiB (rounded to 1169664000)requested by op Einsum\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-09-14 12:12:19.318449: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-09-14 12:12:19.318455: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 48, Chunks in use: 48. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 240B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318458: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318462: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 102, Chunks in use: 102. 124.5KiB allocated for chunks. 124.5KiB in use in bin. 117.3KiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318465: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 8, Chunks in use: 7. 22.8KiB allocated for chunks. 20.2KiB in use in bin. 18.2KiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318467: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 6.5KiB allocated for chunks. 6.5KiB in use in bin. 5.9KiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318470: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 53, Chunks in use: 53. 503.5KiB allocated for chunks. 503.5KiB in use in bin. 496.9KiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318473: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 2, Chunks in use: 2. 39.0KiB allocated for chunks. 39.0KiB in use in bin. 21.3KiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318476: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318479: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 2, Chunks in use: 2. 190.2KiB allocated for chunks. 190.2KiB in use in bin. 164.1KiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318481: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 2, Chunks in use: 2. 281.0KiB allocated for chunks. 281.0KiB in use in bin. 164.1KiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318484: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 23, Chunks in use: 22. 7.18MiB allocated for chunks. 6.89MiB in use in bin. 6.45MiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318487: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 9, Chunks in use: 9. 6.93MiB allocated for chunks. 6.93MiB in use in bin. 6.03MiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318489: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 0. 1.12MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318492: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 81, Chunks in use: 79. 219.48MiB allocated for chunks. 214.45MiB in use in bin. 213.02MiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318495: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 4.99MiB allocated for chunks. 4.99MiB in use in bin. 2.75MiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318497: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318499: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318505: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318507: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318510: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 139.43MiB allocated for chunks. 139.43MiB in use in bin. 139.43MiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318513: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 4. 4.64GiB allocated for chunks. 4.37GiB in use in bin. 4.36GiB client-requested in use in bin.\n",
      "2023-09-14 12:12:19.318515: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 1.09GiB was 256.00MiB, Chunk State: \n",
      "2023-09-14 12:12:19.318521: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 278.87MiB | Requested Size: 139.43MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.75MiB | Requested Size: 2.75MiB | in_use: 1 | bin_num: -1, next:   Size: 139.43MiB | Requested Size: 139.43MiB | in_use: 1 | bin_num: -1\n",
      "2023-09-14 12:12:19.318524: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 5386272768\n",
      "2023-09-14 12:12:19.318527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6000000 of size 256 next 1\n",
      "2023-09-14 12:12:19.318529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6000100 of size 1280 next 2\n",
      "2023-09-14 12:12:19.318532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6000600 of size 256 next 3\n",
      "2023-09-14 12:12:19.318533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6000700 of size 256 next 4\n",
      "2023-09-14 12:12:19.318535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6000800 of size 2385664 next 6\n",
      "2023-09-14 12:12:19.318538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6246f00 of size 256 next 9\n",
      "2023-09-14 12:12:19.318540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6247000 of size 256 next 10\n",
      "2023-09-14 12:12:19.318542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6247100 of size 256 next 5\n",
      "2023-09-14 12:12:19.318545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6247200 of size 9728 next 8\n",
      "2023-09-14 12:12:19.318548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f3eb6249800 of size 2385664 next 38\n",
      "2023-09-14 12:12:19.318551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb648ff00 of size 3365120 next 12\n",
      "2023-09-14 12:12:19.318554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb67c5800 of size 2880000 next 13\n",
      "2023-09-14 12:12:19.318556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a84a00 of size 9728 next 11\n",
      "2023-09-14 12:12:19.318558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a87000 of size 9728 next 7\n",
      "2023-09-14 12:12:19.318559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a89600 of size 256 next 14\n",
      "2023-09-14 12:12:19.318561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a89700 of size 256 next 19\n",
      "2023-09-14 12:12:19.318563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a89800 of size 1280 next 20\n",
      "2023-09-14 12:12:19.318565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a89d00 of size 256 next 21\n",
      "2023-09-14 12:12:19.318567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a89e00 of size 1280 next 23\n",
      "2023-09-14 12:12:19.318569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a8a300 of size 1280 next 24\n",
      "2023-09-14 12:12:19.318571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a8a800 of size 256 next 25\n",
      "2023-09-14 12:12:19.318573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a8a900 of size 256 next 26\n",
      "2023-09-14 12:12:19.318575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a8aa00 of size 1024 next 28\n",
      "2023-09-14 12:12:19.318577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6a8ae00 of size 614144 next 31\n",
      "2023-09-14 12:12:19.318580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b20d00 of size 307200 next 32\n",
      "2023-09-14 12:12:19.318583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b6bd00 of size 1280 next 27\n",
      "2023-09-14 12:12:19.318585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b6c200 of size 1280 next 29\n",
      "2023-09-14 12:12:19.318587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b6c700 of size 1280 next 30\n",
      "2023-09-14 12:12:19.318589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b6cc00 of size 9728 next 35\n",
      "2023-09-14 12:12:19.318591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b6f200 of size 9728 next 36\n",
      "2023-09-14 12:12:19.318594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b71800 of size 9728 next 40\n",
      "2023-09-14 12:12:19.318596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b73e00 of size 1280 next 42\n",
      "2023-09-14 12:12:19.318598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b74300 of size 1280 next 44\n",
      "2023-09-14 12:12:19.318600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b74800 of size 1280 next 46\n",
      "2023-09-14 12:12:19.318602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b74d00 of size 9728 next 47\n",
      "2023-09-14 12:12:19.318604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b77300 of size 9728 next 48\n",
      "2023-09-14 12:12:19.318605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b79900 of size 9728 next 50\n",
      "2023-09-14 12:12:19.318607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7bf00 of size 1280 next 52\n",
      "2023-09-14 12:12:19.318609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7c400 of size 1280 next 54\n",
      "2023-09-14 12:12:19.318611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7c900 of size 1280 next 56\n",
      "2023-09-14 12:12:19.318613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7ce00 of size 1024 next 57\n",
      "2023-09-14 12:12:19.318615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7d200 of size 1280 next 58\n",
      "2023-09-14 12:12:19.318617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7d700 of size 1280 next 61\n",
      "2023-09-14 12:12:19.318618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7dc00 of size 1280 next 63\n",
      "2023-09-14 12:12:19.318620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7e100 of size 256 next 64\n",
      "2023-09-14 12:12:19.318622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7e200 of size 256 next 65\n",
      "2023-09-14 12:12:19.318624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7e300 of size 3072 next 68\n",
      "2023-09-14 12:12:19.318626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b7ef00 of size 9728 next 70\n",
      "2023-09-14 12:12:19.318628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b81500 of size 9728 next 66\n",
      "2023-09-14 12:12:19.318630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b83b00 of size 1280 next 395\n",
      "2023-09-14 12:12:19.318632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b84000 of size 1280 next 72\n",
      "2023-09-14 12:12:19.318633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b84500 of size 1280 next 74\n",
      "2023-09-14 12:12:19.318635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b84a00 of size 1024 next 390\n",
      "2023-09-14 12:12:19.318637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b84e00 of size 1280 next 78\n",
      "2023-09-14 12:12:19.318639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b85300 of size 1280 next 79\n",
      "2023-09-14 12:12:19.318641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b85800 of size 1280 next 80\n",
      "2023-09-14 12:12:19.318643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b85d00 of size 9728 next 83\n",
      "2023-09-14 12:12:19.318645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b88300 of size 9728 next 84\n",
      "2023-09-14 12:12:19.318647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b8a900 of size 9728 next 85\n",
      "2023-09-14 12:12:19.318649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b8cf00 of size 1280 next 86\n",
      "2023-09-14 12:12:19.318650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b8d400 of size 1280 next 88\n",
      "2023-09-14 12:12:19.318652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b8d900 of size 1280 next 90\n",
      "2023-09-14 12:12:19.318654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b8de00 of size 9728 next 94\n",
      "2023-09-14 12:12:19.318656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b90400 of size 9728 next 95\n",
      "2023-09-14 12:12:19.318658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b92a00 of size 9728 next 96\n",
      "2023-09-14 12:12:19.318660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b95000 of size 1280 next 92\n",
      "2023-09-14 12:12:19.318661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b95500 of size 1280 next 98\n",
      "2023-09-14 12:12:19.318663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b95a00 of size 1280 next 100\n",
      "2023-09-14 12:12:19.318665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b95f00 of size 1024 next 102\n",
      "2023-09-14 12:12:19.318667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b96300 of size 1280 next 104\n",
      "2023-09-14 12:12:19.318669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b96800 of size 1280 next 105\n",
      "2023-09-14 12:12:19.318670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b96d00 of size 1280 next 106\n",
      "2023-09-14 12:12:19.318672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b97200 of size 3072 next 367\n",
      "2023-09-14 12:12:19.318674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b97e00 of size 6656 next 110\n",
      "2023-09-14 12:12:19.318676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b99800 of size 256 next 111\n",
      "2023-09-14 12:12:19.318678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b99900 of size 256 next 112\n",
      "2023-09-14 12:12:19.318680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b99a00 of size 256 next 371\n",
      "2023-09-14 12:12:19.318682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b99b00 of size 256 next 307\n",
      "2023-09-14 12:12:19.318684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f3eb6b99c00 of size 2560 next 113\n",
      "2023-09-14 12:12:19.318685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9a600 of size 256 next 114\n",
      "2023-09-14 12:12:19.318687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9a700 of size 256 next 117\n",
      "2023-09-14 12:12:19.318689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9a800 of size 256 next 118\n",
      "2023-09-14 12:12:19.318691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9a900 of size 256 next 119\n",
      "2023-09-14 12:12:19.318693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9aa00 of size 256 next 120\n",
      "2023-09-14 12:12:19.318695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9ab00 of size 256 next 121\n",
      "2023-09-14 12:12:19.318696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9ac00 of size 256 next 122\n",
      "2023-09-14 12:12:19.318698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9ad00 of size 9728 next 126\n",
      "2023-09-14 12:12:19.318701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9d300 of size 9728 next 127\n",
      "2023-09-14 12:12:19.318703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6b9f900 of size 9728 next 128\n",
      "2023-09-14 12:12:19.318705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6ba1f00 of size 9728 next 129\n",
      "2023-09-14 12:12:19.318707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6ba4500 of size 9728 next 134\n",
      "2023-09-14 12:12:19.318708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6ba6b00 of size 9728 next 135\n",
      "2023-09-14 12:12:19.318710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6ba9100 of size 9728 next 136\n",
      "2023-09-14 12:12:19.318712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6bab700 of size 9728 next 137\n",
      "2023-09-14 12:12:19.318714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6badd00 of size 9728 next 142\n",
      "2023-09-14 12:12:19.318716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6bb0300 of size 9728 next 143\n",
      "2023-09-14 12:12:19.318718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6bb2900 of size 17664 next 33\n",
      "2023-09-14 12:12:19.318720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6bb6e00 of size 307200 next 34\n",
      "2023-09-14 12:12:19.318722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c01e00 of size 9728 next 144\n",
      "2023-09-14 12:12:19.318724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c04400 of size 1280 next 149\n",
      "2023-09-14 12:12:19.318726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c04900 of size 1280 next 150\n",
      "2023-09-14 12:12:19.318727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c04e00 of size 1280 next 151\n",
      "2023-09-14 12:12:19.318729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c05300 of size 1280 next 152\n",
      "2023-09-14 12:12:19.318733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c05800 of size 1280 next 153\n",
      "2023-09-14 12:12:19.318736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c05d00 of size 1280 next 154\n",
      "2023-09-14 12:12:19.318738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c06200 of size 1280 next 155\n",
      "2023-09-14 12:12:19.318740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c06700 of size 1280 next 156\n",
      "2023-09-14 12:12:19.318742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c06c00 of size 1280 next 157\n",
      "2023-09-14 12:12:19.318743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c07100 of size 1280 next 158\n",
      "2023-09-14 12:12:19.318745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c07600 of size 1280 next 159\n",
      "2023-09-14 12:12:19.318747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c07b00 of size 1280 next 160\n",
      "2023-09-14 12:12:19.318749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c08000 of size 1024 next 163\n",
      "2023-09-14 12:12:19.318751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c08400 of size 1024 next 164\n",
      "2023-09-14 12:12:19.318753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c08800 of size 1024 next 165\n",
      "2023-09-14 12:12:19.318754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c08c00 of size 1024 next 166\n",
      "2023-09-14 12:12:19.318756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c09000 of size 1280 next 170\n",
      "2023-09-14 12:12:19.318758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c09500 of size 1280 next 171\n",
      "2023-09-14 12:12:19.318760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c09a00 of size 1280 next 172\n",
      "2023-09-14 12:12:19.318762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c09f00 of size 1280 next 173\n",
      "2023-09-14 12:12:19.318764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0a400 of size 1280 next 174\n",
      "2023-09-14 12:12:19.318766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0a900 of size 1280 next 175\n",
      "2023-09-14 12:12:19.318768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0ae00 of size 1280 next 176\n",
      "2023-09-14 12:12:19.318770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0b300 of size 1280 next 177\n",
      "2023-09-14 12:12:19.318771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0b800 of size 1280 next 178\n",
      "2023-09-14 12:12:19.318773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0bd00 of size 1280 next 179\n",
      "2023-09-14 12:12:19.318775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0c200 of size 1280 next 180\n",
      "2023-09-14 12:12:19.318777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0c700 of size 1280 next 181\n",
      "2023-09-14 12:12:19.318779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0cc00 of size 9728 next 190\n",
      "2023-09-14 12:12:19.318781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c0f200 of size 9728 next 191\n",
      "2023-09-14 12:12:19.318782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c11800 of size 9728 next 192\n",
      "2023-09-14 12:12:19.318784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c13e00 of size 9728 next 193\n",
      "2023-09-14 12:12:19.318786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c16400 of size 9728 next 198\n",
      "2023-09-14 12:12:19.318788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c18a00 of size 9728 next 199\n",
      "2023-09-14 12:12:19.318790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c1b000 of size 9728 next 200\n",
      "2023-09-14 12:12:19.318792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c1d600 of size 9728 next 201\n",
      "2023-09-14 12:12:19.318793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c1fc00 of size 9728 next 206\n",
      "2023-09-14 12:12:19.318795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c22200 of size 9728 next 207\n",
      "2023-09-14 12:12:19.318797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c24800 of size 9728 next 208\n",
      "2023-09-14 12:12:19.318799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c26e00 of size 9728 next 209\n",
      "2023-09-14 12:12:19.318801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c29400 of size 1280 next 214\n",
      "2023-09-14 12:12:19.318803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c29900 of size 1280 next 215\n",
      "2023-09-14 12:12:19.318804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c29e00 of size 1280 next 216\n",
      "2023-09-14 12:12:19.318806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2a300 of size 1280 next 217\n",
      "2023-09-14 12:12:19.318808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2a800 of size 1280 next 218\n",
      "2023-09-14 12:12:19.318810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2ad00 of size 1280 next 219\n",
      "2023-09-14 12:12:19.318812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2b200 of size 1280 next 220\n",
      "2023-09-14 12:12:19.318814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2b700 of size 1280 next 221\n",
      "2023-09-14 12:12:19.318816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2bc00 of size 1280 next 222\n",
      "2023-09-14 12:12:19.318818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2c100 of size 1280 next 223\n",
      "2023-09-14 12:12:19.318819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2c600 of size 1280 next 224\n",
      "2023-09-14 12:12:19.318821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2cb00 of size 1280 next 225\n",
      "2023-09-14 12:12:19.318823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2d000 of size 9728 next 230\n",
      "2023-09-14 12:12:19.318825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c2f600 of size 9728 next 231\n",
      "2023-09-14 12:12:19.318827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c31c00 of size 9728 next 232\n",
      "2023-09-14 12:12:19.318829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c34200 of size 9728 next 233\n",
      "2023-09-14 12:12:19.318830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c36800 of size 9728 next 238\n",
      "2023-09-14 12:12:19.318832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c38e00 of size 9728 next 239\n",
      "2023-09-14 12:12:19.318834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c3b400 of size 9728 next 240\n",
      "2023-09-14 12:12:19.318836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c3da00 of size 9728 next 241\n",
      "2023-09-14 12:12:19.318838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c40000 of size 9728 next 246\n",
      "2023-09-14 12:12:19.318839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c42600 of size 9728 next 247\n",
      "2023-09-14 12:12:19.318841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c44c00 of size 9728 next 248\n",
      "2023-09-14 12:12:19.318843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c47200 of size 9728 next 249\n",
      "2023-09-14 12:12:19.318845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c49800 of size 1280 next 254\n",
      "2023-09-14 12:12:19.318847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c49d00 of size 1280 next 255\n",
      "2023-09-14 12:12:19.318848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4a200 of size 1280 next 256\n",
      "2023-09-14 12:12:19.318850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4a700 of size 1280 next 257\n",
      "2023-09-14 12:12:19.318852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4ac00 of size 1280 next 258\n",
      "2023-09-14 12:12:19.318854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4b100 of size 1280 next 259\n",
      "2023-09-14 12:12:19.318856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4b600 of size 1280 next 260\n",
      "2023-09-14 12:12:19.318858: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4bb00 of size 1280 next 261\n",
      "2023-09-14 12:12:19.318860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4c000 of size 1280 next 262\n",
      "2023-09-14 12:12:19.318861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4c500 of size 2304 next 60\n",
      "2023-09-14 12:12:19.318863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c4ce00 of size 307200 next 59\n",
      "2023-09-14 12:12:19.318865: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6c97e00 of size 307200 next 62\n",
      "2023-09-14 12:12:19.318867: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6ce2e00 of size 397056 next 15\n",
      "2023-09-14 12:12:19.318869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb6d43d00 of size 2880000 next 16\n",
      "2023-09-14 12:12:19.318871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7002f00 of size 873728 next 69\n",
      "2023-09-14 12:12:19.318873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb70d8400 of size 307200 next 82\n",
      "2023-09-14 12:12:19.318875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7123400 of size 307200 next 107\n",
      "2023-09-14 12:12:19.318877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f3eb716e400 of size 307200 next 109\n",
      "2023-09-14 12:12:19.318879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb71b9400 of size 307200 next 162\n",
      "2023-09-14 12:12:19.318880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7204400 of size 307200 next 167\n",
      "2023-09-14 12:12:19.318882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb724f400 of size 470272 next 18\n",
      "2023-09-14 12:12:19.318884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb72c2100 of size 2880000 next 17\n",
      "2023-09-14 12:12:19.318886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7581300 of size 2880000 next 22\n",
      "2023-09-14 12:12:19.318889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7840500 of size 307200 next 161\n",
      "2023-09-14 12:12:19.318891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb788b500 of size 562944 next 116\n",
      "2023-09-14 12:12:19.318892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7914c00 of size 870144 next 115\n",
      "2023-09-14 12:12:19.318895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb79e9300 of size 307200 next 168\n",
      "2023-09-14 12:12:19.318896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7a34300 of size 307200 next 169\n",
      "2023-09-14 12:12:19.318898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7a7f300 of size 1280 next 263\n",
      "2023-09-14 12:12:19.318900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7a7f800 of size 1280 next 264\n",
      "2023-09-14 12:12:19.318902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7a7fd00 of size 522752 next 39\n",
      "2023-09-14 12:12:19.318904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7aff700 of size 2880000 next 37\n",
      "2023-09-14 12:12:19.318906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb7dbe900 of size 2880000 next 41\n",
      "2023-09-14 12:12:19.318908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb807db00 of size 2880000 next 43\n",
      "2023-09-14 12:12:19.318910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb833cd00 of size 2880000 next 45\n",
      "2023-09-14 12:12:19.318912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb85fbf00 of size 2880000 next 49\n",
      "2023-09-14 12:12:19.318915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb88bb100 of size 2880000 next 51\n",
      "2023-09-14 12:12:19.318917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb8b7a300 of size 2880000 next 53\n",
      "2023-09-14 12:12:19.318919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb8e39500 of size 2880000 next 55\n",
      "2023-09-14 12:12:19.318921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb90f8700 of size 2880000 next 71\n",
      "2023-09-14 12:12:19.318923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb93b7900 of size 2880000 next 67\n",
      "2023-09-14 12:12:19.318925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb9676b00 of size 2880000 next 73\n",
      "2023-09-14 12:12:19.318926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb9935d00 of size 2880000 next 75\n",
      "2023-09-14 12:12:19.318928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb9bf4f00 of size 2880000 next 77\n",
      "2023-09-14 12:12:19.318930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eb9eb4100 of size 5232128 next 87\n",
      "2023-09-14 12:12:19.318932: I tenso"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'multi_head_attention_3' (type MultiHeadAttention).\n\n{{function_node __wrapped__Einsum_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1523,8,80,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Einsum] name: \n\nCall arguments received by layer 'multi_head_attention_3' (type MultiHeadAttention):\n  • query=tf.Tensor(shape=(1523, 80, 300), dtype=float32)\n  • value=tf.Tensor(shape=(1523, 80, 300), dtype=float32)\n  • key=tf.Tensor(shape=(1523, 80, 300), dtype=float32)\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=None\n  • use_causal_mask=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44729/2752926902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Metrika nad kojom se vrsi selekcija je smooth BLEU4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0maverage_bleu4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smooth_bleu4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_44729/4102772494.py\u001b[0m in \u001b[0;36mcv_grid_search\u001b[0;34m(df, dropout_rates, latent_dims, epochs, learning_rate, folds)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mbest_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu4s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu3s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_rates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_44729/758511062.py\u001b[0m in \u001b[0;36mcv_evaluate\u001b[0;34m(train_val_data, df_folds, folds, epochs, batch_size, learning_rate, latent_dim, dropout_rate, embedding_learning_rate)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current Learning Rate Multiplier: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_learning_rate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_learning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mbest_epochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_44729/1883826830.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(train_data, val_data, epochs, batch_size, learning_rate, latent_dim, dropout_rate, embedding_learning_rate)\u001b[0m\n\u001b[1;32m     41\u001b[0m      \u001b[0;31m#print(model_transformer.evaluate([encoder_input_data_val, decoder_input_data_val], decoder_output_data_val))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m      \u001b[0mwer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_texts_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_texts_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted_target_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pad_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_pad_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_bleu1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/faks/mu/txt2gloss/funkcije.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, test_input_sentences, test_references, input_word_index, target_word_index, inverted_target_word_index, input_pad_len, target_pad_len)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mumlaut_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mtest_references\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mumlaut_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_references\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverted_target_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pad_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_pad_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0msmooth_bleu4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmoothingFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_references\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0msmooth_bleu3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmoothingFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_references\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/faks/mu/txt2gloss/funkcije.py\u001b[0m in \u001b[0;36mtranslate_from_text\u001b[0;34m(model, input_sentences, input_word_index, target_word_index, inverted_target_word_index, input_pad_len, target_pad_len)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_placeholder_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_word_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pad_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_pad_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdecoder_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtarget_word_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<Start>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0moutput_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_target_word_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_sentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0moutput_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<End>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' - '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput_sentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_44729/2412815186.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, encoder_input, decoder_input)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6656\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'multi_head_attention_3' (type MultiHeadAttention).\n\n{{function_node __wrapped__Einsum_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1523,8,80,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Einsum] name: \n\nCall arguments received by layer 'multi_head_attention_3' (type MultiHeadAttention):\n  • query=tf.Tensor(shape=(1523, 80, 300), dtype=float32)\n  • value=tf.Tensor(shape=(1523, 80, 300), dtype=float32)\n  • key=tf.Tensor(shape=(1523, 80, 300), dtype=float32)\n  • attention_mask=None\n  • return_attention_scores=False\n  • training=None\n  • use_causal_mask=False"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eba3b1700 of size 2880000 next 89\n",
      "2023-09-14 12:12:19.318934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eba670900 of size 2880000 next 91\n",
      "2023-09-14 12:12:19.318936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3eba92fb00 of size 2880000 next 93\n",
      "2023-09-14 12:12:19.318940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebabeed00 of size 2880000 next 97\n",
      "2023-09-14 12:12:19.318942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebaeadf00 of size 2880000 next 99\n",
      "2023-09-14 12:12:19.318944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebb16d100 of size 2880000 next 101\n",
      "2023-09-14 12:12:19.318946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f3ebb42c300 of size 2880000 next 103\n",
      "2023-09-14 12:12:19.318948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebb6eb500 of size 2880000 next 123\n",
      "2023-09-14 12:12:19.318949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebb9aa700 of size 2880000 next 124\n",
      "2023-09-14 12:12:19.318951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebbc69900 of size 2880000 next 125\n",
      "2023-09-14 12:12:19.318953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebbf28b00 of size 2880000 next 130\n",
      "2023-09-14 12:12:19.318955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebc1e7d00 of size 2880000 next 131\n",
      "2023-09-14 12:12:19.318957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebc4a6f00 of size 2880000 next 132\n",
      "2023-09-14 12:12:19.318959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebc766100 of size 2880000 next 133\n",
      "2023-09-14 12:12:19.318961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebca25300 of size 2880000 next 138\n",
      "2023-09-14 12:12:19.318963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebcce4500 of size 2880000 next 139\n",
      "2023-09-14 12:12:19.318965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebcfa3700 of size 2880000 next 140\n",
      "2023-09-14 12:12:19.318966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebd262900 of size 2880000 next 141\n",
      "2023-09-14 12:12:19.318969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebd521b00 of size 2880000 next 145\n",
      "2023-09-14 12:12:19.318972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebd7e0d00 of size 2880000 next 146\n",
      "2023-09-14 12:12:19.318974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebda9ff00 of size 2880000 next 147\n",
      "2023-09-14 12:12:19.318976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebdd5f100 of size 2880000 next 148\n",
      "2023-09-14 12:12:19.318978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebe01e300 of size 2352128 next 182\n",
      "2023-09-14 12:12:19.318980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebe25c700 of size 2352128 next 183\n",
      "2023-09-14 12:12:19.318982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebe49ab00 of size 2352128 next 184\n",
      "2023-09-14 12:12:19.318984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebe6d8f00 of size 2352128 next 185\n",
      "2023-09-14 12:12:19.318985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebe917300 of size 2880000 next 186\n",
      "2023-09-14 12:12:19.318987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebebd6500 of size 2880000 next 187\n",
      "2023-09-14 12:12:19.318989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebee95700 of size 2880000 next 188\n",
      "2023-09-14 12:12:19.318991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebf154900 of size 2880000 next 189\n",
      "2023-09-14 12:12:19.318993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebf413b00 of size 2880000 next 194\n",
      "2023-09-14 12:12:19.318994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebf6d2d00 of size 2880000 next 195\n",
      "2023-09-14 12:12:19.318996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebf991f00 of size 2880000 next 196\n",
      "2023-09-14 12:12:19.318998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebfc51100 of size 2880000 next 197\n",
      "2023-09-14 12:12:19.319000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ebff10300 of size 2880000 next 202\n",
      "2023-09-14 12:12:19.319002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec01cf500 of size 2880000 next 203\n",
      "2023-09-14 12:12:19.319004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec048e700 of size 2880000 next 204\n",
      "2023-09-14 12:12:19.319006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec074d900 of size 2880000 next 205\n",
      "2023-09-14 12:12:19.319007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec0a0cb00 of size 2880000 next 210\n",
      "2023-09-14 12:12:19.319009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec0ccbd00 of size 2880000 next 211\n",
      "2023-09-14 12:12:19.319011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec0f8af00 of size 2880000 next 212\n",
      "2023-09-14 12:12:19.319013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec124a100 of size 2880000 next 213\n",
      "2023-09-14 12:12:19.319015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec1509300 of size 2880000 next 226\n",
      "2023-09-14 12:12:19.319017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec17c8500 of size 2880000 next 227\n",
      "2023-09-14 12:12:19.319018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec1a87700 of size 2880000 next 228\n",
      "2023-09-14 12:12:19.319020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec1d46900 of size 2880000 next 229\n",
      "2023-09-14 12:12:19.319022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec2005b00 of size 2880000 next 234\n",
      "2023-09-14 12:12:19.319024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec22c4d00 of size 2880000 next 235\n",
      "2023-09-14 12:12:19.319026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec2583f00 of size 2880000 next 236\n",
      "2023-09-14 12:12:19.319028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec2843100 of size 2880000 next 237\n",
      "2023-09-14 12:12:19.319029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec2b02300 of size 2880000 next 242\n",
      "2023-09-14 12:12:19.319031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec2dc1500 of size 2880000 next 243\n",
      "2023-09-14 12:12:19.319033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec3080700 of size 2880000 next 244\n",
      "2023-09-14 12:12:19.319035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec333f900 of size 2880000 next 245\n",
      "2023-09-14 12:12:19.319037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec35feb00 of size 2880000 next 250\n",
      "2023-09-14 12:12:19.319039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec38bdd00 of size 2880000 next 251\n",
      "2023-09-14 12:12:19.319042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec3b7cf00 of size 2880000 next 252\n",
      "2023-09-14 12:12:19.319045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec3e3c100 of size 2880000 next 253\n",
      "2023-09-14 12:12:19.319048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec40fb300 of size 307200 next 265\n",
      "2023-09-14 12:12:19.319051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4146300 of size 307200 next 266\n",
      "2023-09-14 12:12:19.319054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4191300 of size 307200 next 267\n",
      "2023-09-14 12:12:19.319057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec41dc300 of size 1024 next 268\n",
      "2023-09-14 12:12:19.319060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec41dc700 of size 1024 next 269\n",
      "2023-09-14 12:12:19.319063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec41dcb00 of size 1024 next 270\n",
      "2023-09-14 12:12:19.319066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec41dcf00 of size 1024 next 271\n",
      "2023-09-14 12:12:19.319069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec41dd300 of size 307200 next 272\n",
      "2023-09-14 12:12:19.319073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4228300 of size 307200 next 273\n",
      "2023-09-14 12:12:19.319075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4273300 of size 307200 next 274\n",
      "2023-09-14 12:12:19.319077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec42be300 of size 307200 next 275\n",
      "2023-09-14 12:12:19.319079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4309300 of size 1280 next 276\n",
      "2023-09-14 12:12:19.319081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4309800 of size 1280 next 277\n",
      "2023-09-14 12:12:19.319083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4309d00 of size 1280 next 278\n",
      "2023-09-14 12:12:19.319085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430a200 of size 1280 next 279\n",
      "2023-09-14 12:12:19.319086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430a700 of size 1280 next 280\n",
      "2023-09-14 12:12:19.319088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430ac00 of size 1280 next 281\n",
      "2023-09-14 12:12:19.319090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430b100 of size 1280 next 282\n",
      "2023-09-14 12:12:19.319092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430b600 of size 1280 next 283\n",
      "2023-09-14 12:12:19.319094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430bb00 of size 1280 next 284\n",
      "2023-09-14 12:12:19.319096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430c000 of size 1280 next 285\n",
      "2023-09-14 12:12:19.319097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430c500 of size 1280 next 286\n",
      "2023-09-14 12:12:19.319099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430ca00 of size 1280 next 287\n",
      "2023-09-14 12:12:19.319101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec430cf00 of size 870144 next 288\n",
      "2023-09-14 12:12:19.319103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec43e1600 of size 870144 next 289\n",
      "2023-09-14 12:12:19.319105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec44b5d00 of size 870144 next 290\n",
      "2023-09-14 12:12:19.319107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec458a400 of size 870144 next 291\n",
      "2023-09-14 12:12:19.319109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec465eb00 of size 3072 next 292\n",
      "2023-09-14 12:12:19.319113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec465f700 of size 3072 next 293\n",
      "2023-09-14 12:12:19.319115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4660300 of size 3072 next 294\n",
      "2023-09-14 12:12:19.319117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4660f00 of size 3072 next 295\n",
      "2023-09-14 12:12:19.319118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4661b00 of size 256 next 296\n",
      "2023-09-14 12:12:19.319120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4661c00 of size 256 next 297\n",
      "2023-09-14 12:12:19.319122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4661d00 of size 256 next 321\n",
      "2023-09-14 12:12:19.319124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4661e00 of size 96000 next 320\n",
      "2023-09-14 12:12:19.319126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679500 of size 256 next 319\n",
      "2023-09-14 12:12:19.319128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679600 of size 256 next 318\n",
      "2023-09-14 12:12:19.319130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679700 of size 256 next 317\n",
      "2023-09-14 12:12:19.319132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679800 of size 256 next 316\n",
      "2023-09-14 12:12:19.319135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679900 of size 256 next 315\n",
      "2023-09-14 12:12:19.319138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679a00 of size 256 next 299\n",
      "2023-09-14 12:12:19.319140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679b00 of size 256 next 359\n",
      "2023-09-14 12:12:19.319142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679c00 of size 256 next 357\n",
      "2023-09-14 12:12:19.319144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4679d00 of size 98816 next 342\n",
      "2023-09-14 12:12:19.319146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4691f00 of size 256 next 347\n",
      "2023-09-14 12:12:19.319148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4692000 of size 256 next 368\n",
      "2023-09-14 12:12:19.319150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4692100 of size 145408 next 327\n",
      "2023-09-14 12:12:19.319152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b5900 of size 256 next 328\n",
      "2023-09-14 12:12:19.319154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b5a00 of size 256 next 329\n",
      "2023-09-14 12:12:19.319156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b5b00 of size 256 next 346\n",
      "2023-09-14 12:12:19.319158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b5c00 of size 256 next 325\n",
      "2023-09-14 12:12:19.319160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b5d00 of size 256 next 324\n",
      "2023-09-14 12:12:19.319163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b5e00 of size 256 next 323\n",
      "2023-09-14 12:12:19.319166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b5f00 of size 256 next 322\n",
      "2023-09-14 12:12:19.319168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46b6000 of size 142336 next 334\n",
      "2023-09-14 12:12:19.319170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46d8c00 of size 256 next 370\n",
      "2023-09-14 12:12:19.319172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46d8d00 of size 256 next 302\n",
      "2023-09-14 12:12:19.319174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46d8e00 of size 256 next 343\n",
      "2023-09-14 12:12:19.319176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46d8f00 of size 256 next 301\n",
      "2023-09-14 12:12:19.319177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46d9000 of size 9728 next 303\n",
      "2023-09-14 12:12:19.319179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46db600 of size 22272 next 340\n",
      "2023-09-14 12:12:19.319181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec46e0d00 of size 307200 next 76\n",
      "2023-09-14 12:12:19.319183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec472bd00 of size 870144 next 108\n",
      "2023-09-14 12:12:19.319185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f3ec4800400 of size 1174784 next 378\n",
      "2023-09-14 12:12:19.319187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec491f100 of size 2352128 next 387\n",
      "2023-09-14 12:12:19.319191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4b5d500 of size 2880000 next 361\n",
      "2023-09-14 12:12:19.319193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ec4e1c700 of size 2880000 next 81\n",
      "2023-09-14 12:12:19.319195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f3ec50db900 of size 292416000 next 331\n",
      "2023-09-14 12:12:19.319197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3ed67ba300 of size 146208000 next 369\n",
      "2023-09-14 12:12:19.319199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3edf329800 of size 1169664000 next 348\n",
      "2023-09-14 12:12:19.319201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3f24ea4000 of size 1169664000 next 373\n",
      "2023-09-14 12:12:19.319203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3f6aa1e800 of size 1169664000 next 345\n",
      "2023-09-14 12:12:19.319205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f3fb0599000 of size 1186099200 next 18446744073709551615\n",
      "2023-09-14 12:12:19.319207: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-09-14 12:12:19.319210: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 48 Chunks of size 256 totalling 12.0KiB\n",
      "2023-09-14 12:12:19.319212: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 1024 totalling 12.0KiB\n",
      "2023-09-14 12:12:19.319216: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 90 Chunks of size 1280 totalling 112.5KiB\n",
      "2023-09-14 12:12:19.319219: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2304 totalling 2.2KiB\n",
      "2023-09-14 12:12:19.319221: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 3072 totalling 18.0KiB\n",
      "2023-09-14 12:12:19.319223: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6656 totalling 6.5KiB\n",
      "2023-09-14 12:12:19.319226: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 53 Chunks of size 9728 totalling 503.5KiB\n",
      "2023-09-14 12:12:19.319228: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 17664 totalling 17.2KiB\n",
      "2023-09-14 12:12:19.319230: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 22272 totalling 21.8KiB\n",
      "2023-09-14 12:12:19.319232: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 96000 totalling 93.8KiB\n",
      "2023-09-14 12:12:19.319234: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 98816 totalling 96.5KiB\n",
      "2023-09-14 12:12:19.319236: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 142336 totalling 139.0KiB\n",
      "2023-09-14 12:12:19.319238: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 145408 totalling 142.0KiB\n",
      "2023-09-14 12:12:19.319241: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 19 Chunks of size 307200 totalling 5.57MiB\n",
      "2023-09-14 12:12:19.319244: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 397056 totalling 387.8KiB\n",
      "2023-09-14 12:12:19.319247: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 470272 totalling 459.2KiB\n",
      "2023-09-14 12:12:19.319249: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 522752 totalling 510.5KiB\n",
      "2023-09-14 12:12:19.319251: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 562944 totalling 549.8KiB\n",
      "2023-09-14 12:12:19.319253: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 614144 totalling 599.8KiB\n",
      "2023-09-14 12:12:19.319255: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 6 Chunks of size 870144 totalling 4.98MiB\n",
      "2023-09-14 12:12:19.319258: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 873728 totalling 853.2KiB\n",
      "2023-09-14 12:12:19.319260: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 2352128 totalling 11.22MiB\n",
      "2023-09-14 12:12:19.319262: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2385664 totalling 2.27MiB\n",
      "2023-09-14 12:12:19.319264: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 72 Chunks of size 2880000 totalling 197.75MiB\n",
      "2023-09-14 12:12:19.319266: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3365120 totalling 3.21MiB\n",
      "2023-09-14 12:12:19.319269: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5232128 totalling 4.99MiB\n",
      "2023-09-14 12:12:19.319273: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 146208000 totalling 139.43MiB\n",
      "2023-09-14 12:12:19.319275: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 1169664000 totalling 3.27GiB\n",
      "2023-09-14 12:12:19.319277: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1186099200 totalling 1.10GiB\n",
      "2023-09-14 12:12:19.319279: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 4.74GiB\n",
      "2023-09-14 12:12:19.319281: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 5386272768 memory_limit_: 5386272768 available bytes: 0 curr_region_allocation_bytes_: 10772545536\n",
      "2023-09-14 12:12:19.319286: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      5386272768\n",
      "InUse:                      5087106560\n",
      "MaxInUse:                   5087106560\n",
      "NumAllocs:                      915601\n",
      "MaxAllocSize:               1186099200\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-09-14 12:12:19.319293: W tensorflow/tsl/framework/bfc_allocator.cc:497] *****_____******************************************************************************************\n",
      "2023-09-14 12:12:19.319309: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at einsum_op_impl.h:522 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1523,8,80,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    }
   ],
   "source": [
    "#Izvrsava se grid search nad hiperparametrima, i radi se unakrsna validacija za evaluaciju performansi\n",
    "#Metrika nad kojom se vrsi selekcija je smooth BLEU4\n",
    "\n",
    "metrics = cv_grid_search(df_train_val, dropout_rates, latent_dims, epochs = 200, learning_rate = learning_rate, folds = folds)\n",
    "average_bleu4 = np.mean(metrics['smooth_bleu4'], axis = -1)\n",
    "\n",
    "plt.title('Average smooth BLEU4, crossvalidated')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.xticks(range(len(dropout_rates)), dropout_rates)\n",
    "plt.ylabel('Latent Dim')\n",
    "plt.yticks(range(len(latent_dims)),latent_dims)\n",
    "plt.imshow(average_bleu4)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
