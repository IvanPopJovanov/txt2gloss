{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c8b3ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smeki RedTech\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.utils import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras import backend \n",
    "from tensorflow.keras import utils\n",
    "\n",
    "from keras_nlp.layers import SinePositionEncoding\n",
    "\n",
    "#import pydot\n",
    "\n",
    "from funkcije import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f4d73",
   "metadata": {},
   "source": [
    "U fajlu funkcije.py smo implementirali mnoge funkcije za pretprocesiranje i neke druge korisne stvari koje cemo da koristimo u vise notebooka."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f28160",
   "metadata": {},
   "source": [
    "Inicijalizujemo callback koji cemo da koristimo pri svakom treniranju modela. Naime, svaki model treniramo do trenutka dok performanse na validacionom skupu ne opadne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e94962",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience = 10, restore_best_weights = True, monitor = 'val_loss', mode = 'min', verbose = 1)\n",
    "\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7837658",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8993ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Translation_Model(Model):\n",
    "    def __init__(self, num_input_words, num_target_words, input_embedding_matrix, target_embedding_matrix, latent_dim = 512, dropout_rate = 0.5, custom_dropout_rate = 0.05):\n",
    "        super(Transformer_Translation_Model, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.custom_dropout_rate = custom_dropout_rate\n",
    "        self.num_input_words = num_input_words\n",
    "        self.num_target_words = num_target_words\n",
    "        self.input_embedding_matrix = input_embedding_matrix\n",
    "        self.target_embedding_matrix = target_embedding_matrix\n",
    "        self.embedding_size = 300\n",
    "        self.input_pad_len = 80\n",
    "        self.target_pad_len = 60\n",
    "        \n",
    "        encoder_inputs = Input(shape=(self.input_pad_len,))\n",
    "        x = CustomDropout(1.0, custom_dropout_rate)(encoder_inputs)\n",
    "        encoder_embedding = Embedding(input_dim = num_input_words + 1, output_dim = embedding_size, mask_zero = True, weights = [input_embedding_matrix], trainable = False)(x)\n",
    "        encoder_pos_encoding = SinePositionEncoding()(encoder_embedding)\n",
    "        x = encoder_embedding + encoder_pos_encoding\n",
    "        for i in range(num_transformer_layers):\n",
    "            xt = MultiHeadAttention(num_heads=num_heads, key_dim=self.embedding_size)(x, x, x)\n",
    "            x = LayerNormalization()(x + xt)\n",
    "            xt = Dense(self.latent_dim, activation=\"relu\") (x)\n",
    "            xt = Dense(self.embedding_size) (xt)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "        encoder_outputs = x\n",
    "        self.encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "        \n",
    "        decoder_inputs = Input(shape=(self.target_pad_len,))\n",
    "        encoded_seq_inputs = Input(shape=(self.input_pad_len, self.embedding_size))\n",
    "        decoder_embedding = Embedding(input_dim = num_input_words + 1, output_dim = self.embedding_size, mask_zero = True, trainable = True)(decoder_inputs)\n",
    "        decoder_pos_encoding = SinePositionEncoding()(decoder_embedding)\n",
    "        x = decoder_embedding + decoder_pos_encoding\n",
    "        for i in range(num_transformer_layers):\n",
    "            causal_mask = self.get_causal_attention_mask(x)\n",
    "            xt = MultiHeadAttention(num_heads=num_heads, key_dim=self.embedding_size) (x, x, x, attention_mask=causal_mask)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "            xt = MultiHeadAttention(num_heads=num_heads, key_dim=self.embedding_size) (x, encoded_seq_inputs, encoded_seq_inputs)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "            xt = Dense(latent_dim, activation=\"relu\") (x)\n",
    "            xt = Dense(self.embedding_size) (xt)\n",
    "            x = LayerNormalization() (x + xt)\n",
    "        x = layers.Dropout(self.dropout_rate)(x)\n",
    "        decoder_outputs = layers.Dense(num_target_words + 1, activation=\"softmax\")(x)\n",
    "        self.decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "        \n",
    "        decoder_outputs = self.decoder([decoder_inputs, encoder_outputs])\n",
    "        self.transformer = keras.Model(\n",
    "            [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    "        )\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.transformer([x[0], x[1]])\n",
    "        \n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "    \n",
    "    def translate(self, encoder_input, decoder_input):\n",
    "        decoder_state = self.encoder.predict(encoder_input, verbose = 0)\n",
    "        data_size = encoder_input.shape[0]\n",
    "        decoder_output = np.zeros((data_size, self.target_pad_len))\n",
    "        decoder_output[:, 0] = decoder_input[:, 0]\n",
    "        for i in range(1,self.target_pad_len - 1):\n",
    "            decoder_output_temp = self.decoder.predict([decoder_output, decoder_state], verbose = 0)\n",
    "            next_words = np.argmax(decoder_output_temp, axis = -1)\n",
    "            decoder_output[:, i] = next_words[:,i-1].reshape((data_size,))\n",
    "        return decoder_output[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421b32e",
   "metadata": {},
   "source": [
    "## Pomocne funkcije\n",
    "\n",
    "Funkcija train_and_evaluate istrenira model na train_data i evaluira ga na val_data. Kao mere za evaluaciju pamti Word Error Rate, BLEU 1-4 (smoothovan). Smoothovan BLEU se pokazao kao bolji u slucajevima kada recenicu imaju mali broj reci, sto je slucaj sa glossovanim recenicama.\n",
    "\n",
    "Takodje cuva dostignut val_loss, kao i broj epoha do konvergencije.\n",
    "\n",
    "Funkcija takodje daje mogucnost treniranja Embedding slojeva sa razlicitim learning_rate-om od ostalih slojeva. Ideja iza ovoga je da, posto su pocetne vrednosti Embedding slojeva pretrenirane, ima smisla da se taj sloj sporije trenira od ostalih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06158376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_data, val_data, epochs = 200, batch_size = 128, learning_rate = 0.001, latent_dim = 256, dropout_rate = 0.5, embedding_learning_rate = 0.001):\n",
    "     \n",
    "     input_texts, target_texts = clean_texts(train_data.iloc[:,1], train_data.iloc[:,0])\n",
    "     input_word_index, target_word_index, max_input_seq_len, max_target_seq_len = analyse_texts(input_texts, target_texts)\n",
    "     input_pad_len = 80\n",
    "     target_pad_len = 60\n",
    "     num_input_words = len(input_word_index) - 1\n",
    "     num_target_words = len(target_word_index) - 1\n",
    "     inverted_input_word_index = {value: key for key,value in input_word_index.items()}\n",
    "     inverted_target_word_index = {value: key for (key,value) in target_word_index.items()}\n",
    "     input_embedding_matrix, target_embedding_matrix = load_embedding_data_get_matrices(inverted_input_word_index, inverted_target_word_index)\n",
    "     print('Embeddings loaded.')\n",
    "     encoder_input_data, decoder_input_data, decoder_output_data = create_model_data(input_texts, target_texts, input_word_index, target_word_index, input_pad_len, target_pad_len)\n",
    "     \n",
    "     input_texts_val, target_texts_val = clean_texts(val_data.iloc[:,1], val_data.iloc[:,0])\n",
    "     encoder_input_data_val, decoder_input_data_val, decoder_output_data_val = create_model_data(input_texts_val, target_texts_val, input_word_index, target_word_index, input_pad_len, target_pad_len)\n",
    "     \n",
    "     model_transformer = Transformer_Translation_Model(num_input_words, num_target_words, input_embedding_matrix, target_embedding_matrix, latent_dim = latent_dim, dropout_rate = dropout_rate)\n",
    "     other_layers = model_transformer.layers \n",
    "     embedding_layers = [] \n",
    "\n",
    "     optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers = [(Adam(learning_rate), other_layers), (Adam(embedding_learning_rate), embedding_layers)])\n",
    "     model_transformer.compile(optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "     history = model_transformer.fit([encoder_input_data, decoder_input_data], decoder_output_data, validation_data = ([encoder_input_data_val, decoder_input_data_val], decoder_output_data_val), epochs = epochs, batch_size = batch_size, callbacks = [early_stopping], verbose = 1)\n",
    "     best_epoch = np.argmin(history.history['val_loss']) + 1\n",
    "     \n",
    "     best_loss = np.min(history.history['val_loss'])\n",
    "     K.clear_session()\n",
    "     wer, smooth_bleu4, smooth_bleu3, smooth_bleu2, smooth_bleu1 = evaluate(model_transformer, input_texts_val, target_texts_val, input_word_index, target_word_index, inverted_target_word_index, input_pad_len, target_pad_len)\n",
    "     K.clear_session()\n",
    "     return best_epoch, best_loss, wer, smooth_bleu4, smooth_bleu3, smooth_bleu2, smooth_bleu1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c6821",
   "metadata": {},
   "source": [
    "Funkcija cv_evaluate trenira po model za svaki fold, racuna odgovarajuce metrike.\n",
    "\n",
    "Funkcija vraca podatke iz svake instance modela, odnosno folda, da bi se dalje procesirale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e4d380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_evaluate(train_val_data = None, df_folds = None, folds = 5, epochs = 200, batch_size = 32, learning_rate = 0.001, latent_dim = 256, dropout_rate = 0.5, embedding_learning_rate = None):\n",
    "    if embedding_learning_rate == None:\n",
    "        embedding_learning_rate = learning_rate\n",
    "    if df_folds == None:\n",
    "        df_np = train_val_data.to_numpy()\n",
    "        np.random.shuffle(df_np)\n",
    "        total_size = df_np.shape[0]\n",
    "        fold_size = total_size/folds\n",
    "        df_folds = [df_np[int(i*fold_size):int((i+1)*fold_size),] for i in range(folds)]\n",
    "    losses = []\n",
    "    best_epochs = []\n",
    "    wers = []\n",
    "    smooth_bleu1s = []\n",
    "    smooth_bleu2s = []\n",
    "    smooth_bleu3s = []\n",
    "    smooth_bleu4s = []\n",
    "    for i in range(folds):\n",
    "        train_folds = [fold for j, fold in enumerate(df_folds) if j!=i]\n",
    "        train_folds_pd = [pd.DataFrame(data = fold) for fold in train_folds]\n",
    "        train_data = pd.concat(train_folds_pd)\n",
    "        val_data = pd.DataFrame(df_folds[i])\n",
    "        print('Current Latent Dim:', latent_dim)\n",
    "        print('Current Dropout Rate: ', dropout_rate)\n",
    "        print('Current Fold: {}/{}'.format(i+1, folds))\n",
    "        print('Current Learning Rate: ', learning_rate)\n",
    "        print('Current Learning Rate Multiplier: ', embedding_learning_rate/learning_rate)\n",
    "        \n",
    "        best_epoch, best_loss, wer, smooth_bleu4, smooth_bleu3, smooth_bleu2, smooth_bleu1 = train_and_evaluate(train_data, val_data, epochs = epochs, batch_size = batch_size, learning_rate = learning_rate, latent_dim = latent_dim, dropout_rate = dropout_rate, embedding_learning_rate = embedding_learning_rate)\n",
    "        best_epochs.append(best_epoch)\n",
    "        losses.append(best_loss)\n",
    "        wers.append(wer)\n",
    "        smooth_bleu4s.append(smooth_bleu4)\n",
    "        smooth_bleu3s.append(smooth_bleu3)\n",
    "        smooth_bleu2s.append(smooth_bleu2)\n",
    "        smooth_bleu1s.append(smooth_bleu1)\n",
    "    return best_epochs, losses, wers, smooth_bleu4s, smooth_bleu3s, smooth_bleu2s, smooth_bleu1s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9187e7",
   "metadata": {},
   "source": [
    "Funkcija grid_search_cv evaluira model za razlicite vrednosti parametara latent_dim i dropout_rate. Rezultate vraca u obliku dictionary-ja kojim je moguce pristupiti svim izracunatim metrikama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb8f5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_grid_search(df, dropout_rates, latent_dims, epochs = 200, learning_rate = 0.0002, folds = 5):\n",
    "    df_np = df.to_numpy()\n",
    "    np.random.shuffle(df_np)\n",
    "    total_size = df_np.shape[0]\n",
    "    fold_size = total_size/folds\n",
    "    df_folds = [df_np[int(i*fold_size):int((i+1)*fold_size),] for i in range(folds)]\n",
    "    \n",
    "    loss_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    epoch_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    wer_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu4_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu3_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu2_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    smooth_bleu1_matrix = np.zeros((len(latent_dims),len(dropout_rates), folds))\n",
    "    for i in range(len(latent_dims)):\n",
    "        for j in range(len(dropout_rates)):\n",
    "            best_epochs, losses, wers, smooth_bleu4s, smooth_bleu3s, smooth_bleu2s, smooth_bleu1s = cv_evaluate(df_folds = df_folds, folds = folds, epochs = epochs, learning_rate = learning_rate, latent_dim = latent_dims[i], dropout_rate = dropout_rates[j])\n",
    "            print(losses)\n",
    "            print(best_epochs)\n",
    "            loss_matrix[i,j,:] = losses\n",
    "            epoch_matrix[i,j,:] = best_epochs\n",
    "            wer_matrix[i,j,:] = wers\n",
    "            smooth_bleu4_matrix[i,j,:] = smooth_bleu4s\n",
    "            smooth_bleu3_matrix[i,j,:] = smooth_bleu3s\n",
    "            smooth_bleu2_matrix[i,j,:] = smooth_bleu2s\n",
    "            smooth_bleu1_matrix[i,j,:] = smooth_bleu1s\n",
    "    #Pakuju se rezultati u dictionary radi intuitivnijeg poziva funkcije\n",
    "    metrics_dict = {'loss': loss_matrix, 'epoch': epoch_matrix, 'wer': wer_matrix, 'smooth_bleu4': smooth_bleu4_matrix, 'smooth_bleu3': smooth_bleu3_matrix, 'smooth_bleu2': smooth_bleu2_matrix, 'smooth_bleu1': smooth_bleu1_matrix }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb23a7",
   "metadata": {},
   "source": [
    "# Glavni program\n",
    "\n",
    "Za pocetak samo ucitavamo podatke i spajamo trening i validacioni skup u jedan koji cemo koristiti za unakrsnu validaciju. Kasnije cemo model evaluirati na test skupu. Ne radimo ugnjezdenu unakrsnu validaciju jer bi predugo trajalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1d9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/PHOENIX-2014-T.train.corpus.csv', sep='|')\n",
    "df_train = df_train.drop(columns=['name','video','start','end','speaker'])\n",
    "train_size = df_train.shape[0]\n",
    "#Orth je glossovana recenica, translation je originalna engleska\n",
    "\n",
    "df_val = pd.read_csv('data/PHOENIX-2014-T.dev.corpus.csv', sep = '|')\n",
    "df_val.drop(columns = ['name', 'video', 'start', 'end', 'speaker'], inplace = True)\n",
    "val_size = df_val.shape[0]\n",
    "\n",
    "df_test = pd.read_csv('data/PHOENIX-2014-T.test.corpus.csv', sep = '|')\n",
    "df_test.drop(columns = ['name', 'video', 'start', 'end', 'speaker'], inplace = True)\n",
    "test_size = df_test.shape[0]\n",
    "\n",
    "df_train_val = pd.concat([df_train, df_val])\n",
    "df_full = pd.concat([df_train_val, df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b68ec6",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Hiperparametri koje cemo da optimizujemo su dropout_rate i latent_dim. Learning rate fiksiramo na vrednost koja nam je iz testiranja dobro radila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c341b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "latent_dims = [256, 512, 1024] \n",
    "learning_rate = 0.0002\n",
    "folds = 5\n",
    "\n",
    "num_heads = 8\n",
    "num_transformer_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee3bdc",
   "metadata": {},
   "source": [
    "Radimo grid search sa unakrsnom validacijom, metrika koju optimizujemo je smooth BLEU4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036af7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 18:08:46.612916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.627623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.627752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.628374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.628461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.628534: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.684779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.684921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.685005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-18 18:08:46.685067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9502 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 18:08:49.919171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-18 18:08:49.963827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-09-18 18:08:49.984889: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1b0edfc5f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-18 18:08:49.984904: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti, Compute Capability 8.6\n",
      "2023-09-18 18:08:49.987622: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-18 18:08:50.074710: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 13s 42ms/step - loss: 0.9156 - acc: 0.8518 - val_loss: 0.7389 - val_acc: 0.8672\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.7352 - acc: 0.8669 - val_loss: 0.6659 - val_acc: 0.8722\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6630 - acc: 0.8743 - val_loss: 0.6070 - val_acc: 0.8820\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6044 - acc: 0.8826 - val_loss: 0.5558 - val_acc: 0.8894\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5616 - acc: 0.8885 - val_loss: 0.5294 - val_acc: 0.8923\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5318 - acc: 0.8926 - val_loss: 0.5045 - val_acc: 0.8969\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5087 - acc: 0.8960 - val_loss: 0.4934 - val_acc: 0.8989\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.4907 - acc: 0.8984 - val_loss: 0.4808 - val_acc: 0.9004\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4750 - acc: 0.9007 - val_loss: 0.4639 - val_acc: 0.9028\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4615 - acc: 0.9027 - val_loss: 0.4575 - val_acc: 0.9041\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4493 - acc: 0.9043 - val_loss: 0.4550 - val_acc: 0.9049\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4390 - acc: 0.9057 - val_loss: 0.4458 - val_acc: 0.9062\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4272 - acc: 0.9072 - val_loss: 0.4479 - val_acc: 0.9057\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4181 - acc: 0.9087 - val_loss: 0.4386 - val_acc: 0.9076\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4084 - acc: 0.9098 - val_loss: 0.4316 - val_acc: 0.9094\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3981 - acc: 0.9112 - val_loss: 0.4267 - val_acc: 0.9088\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3891 - acc: 0.9130 - val_loss: 0.4254 - val_acc: 0.9097\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3800 - acc: 0.9143 - val_loss: 0.4256 - val_acc: 0.9104\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3738 - acc: 0.9156 - val_loss: 0.4277 - val_acc: 0.9097\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3657 - acc: 0.9166 - val_loss: 0.4222 - val_acc: 0.9108\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3580 - acc: 0.9180 - val_loss: 0.4191 - val_acc: 0.9114\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3519 - acc: 0.9188 - val_loss: 0.4219 - val_acc: 0.9102\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3437 - acc: 0.9201 - val_loss: 0.4164 - val_acc: 0.9131\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3370 - acc: 0.9213 - val_loss: 0.4206 - val_acc: 0.9122\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3313 - acc: 0.9225 - val_loss: 0.4178 - val_acc: 0.9135\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3238 - acc: 0.9237 - val_loss: 0.4206 - val_acc: 0.9131\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3178 - acc: 0.9244 - val_loss: 0.4200 - val_acc: 0.9123\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3134 - acc: 0.9253 - val_loss: 0.4181 - val_acc: 0.9135\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3068 - acc: 0.9264 - val_loss: 0.4209 - val_acc: 0.9129\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3010 - acc: 0.9274 - val_loss: 0.4223 - val_acc: 0.9133\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2945 - acc: 0.9287 - val_loss: 0.4241 - val_acc: 0.9129\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2905 - acc: 0.9291 - val_loss: 0.4292 - val_acc: 0.9134\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2841 - acc: 0.9301Restoring model weights from the end of the best epoch: 23.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2841 - acc: 0.9301 - val_loss: 0.4265 - val_acc: 0.9133\n",
      "Epoch 33: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 14s 47ms/step - loss: 0.9221 - acc: 0.8522 - val_loss: 0.7351 - val_acc: 0.8652\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7262 - acc: 0.8675 - val_loss: 0.6607 - val_acc: 0.8734\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6570 - acc: 0.8754 - val_loss: 0.5913 - val_acc: 0.8829\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5910 - acc: 0.8850 - val_loss: 0.5475 - val_acc: 0.8901\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5506 - acc: 0.8908 - val_loss: 0.5275 - val_acc: 0.8922\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5204 - acc: 0.8949 - val_loss: 0.5007 - val_acc: 0.8975\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4999 - acc: 0.8979 - val_loss: 0.4861 - val_acc: 0.8991\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4804 - acc: 0.9005 - val_loss: 0.4781 - val_acc: 0.9007\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4657 - acc: 0.9022 - val_loss: 0.4632 - val_acc: 0.9030\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4505 - acc: 0.9048 - val_loss: 0.4552 - val_acc: 0.9039\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4378 - acc: 0.9062 - val_loss: 0.4496 - val_acc: 0.9048\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4291 - acc: 0.9076 - val_loss: 0.4430 - val_acc: 0.9072\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4172 - acc: 0.9090 - val_loss: 0.4449 - val_acc: 0.9062\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4063 - acc: 0.9109 - val_loss: 0.4358 - val_acc: 0.9081\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3956 - acc: 0.9125 - val_loss: 0.4375 - val_acc: 0.9062\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3885 - acc: 0.9136 - val_loss: 0.4260 - val_acc: 0.9090\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3778 - acc: 0.9151 - val_loss: 0.4225 - val_acc: 0.9094\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3696 - acc: 0.9167 - val_loss: 0.4254 - val_acc: 0.9101\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3628 - acc: 0.9176 - val_loss: 0.4199 - val_acc: 0.9100\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3552 - acc: 0.9187 - val_loss: 0.4157 - val_acc: 0.9120\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3461 - acc: 0.9200 - val_loss: 0.4169 - val_acc: 0.9121\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3402 - acc: 0.9213 - val_loss: 0.4169 - val_acc: 0.9120\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3325 - acc: 0.9223 - val_loss: 0.4150 - val_acc: 0.9128\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3273 - acc: 0.9228 - val_loss: 0.4202 - val_acc: 0.9126\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3209 - acc: 0.9241 - val_loss: 0.4212 - val_acc: 0.9133\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3138 - acc: 0.9252 - val_loss: 0.4178 - val_acc: 0.9136\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3085 - acc: 0.9262 - val_loss: 0.4188 - val_acc: 0.9130\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3000 - acc: 0.9277 - val_loss: 0.4290 - val_acc: 0.9117\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2953 - acc: 0.9284 - val_loss: 0.4281 - val_acc: 0.9129\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2889 - acc: 0.9296 - val_loss: 0.4294 - val_acc: 0.9128\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2820 - acc: 0.9307 - val_loss: 0.4289 - val_acc: 0.9128\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2785 - acc: 0.9316 - val_loss: 0.4293 - val_acc: 0.9125\n",
      "Epoch 33/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.9320Restoring model weights from the end of the best epoch: 23.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2742 - acc: 0.9321 - val_loss: 0.4356 - val_acc: 0.9140\n",
      "Epoch 33: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 13s 45ms/step - loss: 0.9321 - acc: 0.8510 - val_loss: 0.7513 - val_acc: 0.8633\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7410 - acc: 0.8669 - val_loss: 0.6788 - val_acc: 0.8709\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6800 - acc: 0.8724 - val_loss: 0.6373 - val_acc: 0.8753\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6209 - acc: 0.8799 - val_loss: 0.5786 - val_acc: 0.8831\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5771 - acc: 0.8856 - val_loss: 0.5499 - val_acc: 0.8882\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5403 - acc: 0.8909 - val_loss: 0.5193 - val_acc: 0.8938\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5123 - acc: 0.8952 - val_loss: 0.5037 - val_acc: 0.8956\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4930 - acc: 0.8977 - val_loss: 0.4877 - val_acc: 0.8977\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4775 - acc: 0.9001 - val_loss: 0.4789 - val_acc: 0.9001\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4625 - acc: 0.9023 - val_loss: 0.4850 - val_acc: 0.8986\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4489 - acc: 0.9044 - val_loss: 0.4625 - val_acc: 0.9017\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4371 - acc: 0.9058 - val_loss: 0.4520 - val_acc: 0.9037\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4257 - acc: 0.9074 - val_loss: 0.4447 - val_acc: 0.9055\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4151 - acc: 0.9095 - val_loss: 0.4386 - val_acc: 0.9066\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4060 - acc: 0.9105 - val_loss: 0.4420 - val_acc: 0.9056\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3963 - acc: 0.9121 - val_loss: 0.4317 - val_acc: 0.9075\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3865 - acc: 0.9136 - val_loss: 0.4349 - val_acc: 0.9076\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3788 - acc: 0.9146 - val_loss: 0.4246 - val_acc: 0.9094\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3708 - acc: 0.9159 - val_loss: 0.4229 - val_acc: 0.9095\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3625 - acc: 0.9175 - val_loss: 0.4235 - val_acc: 0.9095\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3553 - acc: 0.9187 - val_loss: 0.4247 - val_acc: 0.9101\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3509 - acc: 0.9192 - val_loss: 0.4190 - val_acc: 0.9107\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3428 - acc: 0.9207 - val_loss: 0.4212 - val_acc: 0.9110\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3351 - acc: 0.9216 - val_loss: 0.4217 - val_acc: 0.9113\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3323 - acc: 0.9223 - val_loss: 0.4219 - val_acc: 0.9121\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3231 - acc: 0.9237 - val_loss: 0.4260 - val_acc: 0.9100\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3183 - acc: 0.9239 - val_loss: 0.4249 - val_acc: 0.9115\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3108 - acc: 0.9256 - val_loss: 0.4284 - val_acc: 0.9117\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3068 - acc: 0.9264 - val_loss: 0.4331 - val_acc: 0.9102\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2994 - acc: 0.9278 - val_loss: 0.4304 - val_acc: 0.9119\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2954 - acc: 0.9281 - val_loss: 0.4298 - val_acc: 0.9111\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2887 - acc: 0.9290Restoring model weights from the end of the best epoch: 22.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2887 - acc: 0.9290 - val_loss: 0.4328 - val_acc: 0.9120\n",
      "Epoch 32: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 13s 44ms/step - loss: 0.9456 - acc: 0.8506 - val_loss: 0.7257 - val_acc: 0.8699\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7463 - acc: 0.8651 - val_loss: 0.6489 - val_acc: 0.8765\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.6802 - acc: 0.8714 - val_loss: 0.5948 - val_acc: 0.8838\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6163 - acc: 0.8805 - val_loss: 0.5445 - val_acc: 0.8913\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5694 - acc: 0.8867 - val_loss: 0.5032 - val_acc: 0.8988\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5351 - acc: 0.8923 - val_loss: 0.4878 - val_acc: 0.9003\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5107 - acc: 0.8959 - val_loss: 0.4667 - val_acc: 0.9036\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4922 - acc: 0.8986 - val_loss: 0.4528 - val_acc: 0.9053\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4743 - acc: 0.9008 - val_loss: 0.4418 - val_acc: 0.9081\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4595 - acc: 0.9030 - val_loss: 0.4337 - val_acc: 0.9092\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5037 - acc: 0.8951 - val_loss: 0.4437 - val_acc: 0.9062\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4459 - acc: 0.9036 - val_loss: 0.4270 - val_acc: 0.9085\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4301 - acc: 0.9067 - val_loss: 0.4232 - val_acc: 0.9103\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4183 - acc: 0.9081 - val_loss: 0.4130 - val_acc: 0.9123\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4110 - acc: 0.9092 - val_loss: 0.4110 - val_acc: 0.9125\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3999 - acc: 0.9112 - val_loss: 0.4088 - val_acc: 0.9136\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3917 - acc: 0.9124 - val_loss: 0.4053 - val_acc: 0.9140\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3857 - acc: 0.9134 - val_loss: 0.4035 - val_acc: 0.9130\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3755 - acc: 0.9152 - val_loss: 0.3995 - val_acc: 0.9151\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3686 - acc: 0.9164 - val_loss: 0.4000 - val_acc: 0.9155\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3605 - acc: 0.9174 - val_loss: 0.3963 - val_acc: 0.9160\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3532 - acc: 0.9185 - val_loss: 0.3983 - val_acc: 0.9175\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3469 - acc: 0.9195 - val_loss: 0.4022 - val_acc: 0.9163\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3415 - acc: 0.9205 - val_loss: 0.4014 - val_acc: 0.9168\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3342 - acc: 0.9216 - val_loss: 0.4000 - val_acc: 0.9158\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3267 - acc: 0.9231 - val_loss: 0.4036 - val_acc: 0.9165\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3204 - acc: 0.9243 - val_loss: 0.4014 - val_acc: 0.9176\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3154 - acc: 0.9248 - val_loss: 0.4037 - val_acc: 0.9175\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3081 - acc: 0.9260 - val_loss: 0.4007 - val_acc: 0.9175\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3029 - acc: 0.9270 - val_loss: 0.4060 - val_acc: 0.9173\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2974 - acc: 0.9279Restoring model weights from the end of the best epoch: 21.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2974 - acc: 0.9279 - val_loss: 0.4127 - val_acc: 0.9169\n",
      "Epoch 31: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 13s 43ms/step - loss: 0.9238 - acc: 0.8511 - val_loss: 0.7445 - val_acc: 0.8649\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7379 - acc: 0.8665 - val_loss: 0.6786 - val_acc: 0.8713\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6813 - acc: 0.8714 - val_loss: 0.6350 - val_acc: 0.8769\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6259 - acc: 0.8789 - val_loss: 0.5752 - val_acc: 0.8864\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5756 - acc: 0.8859 - val_loss: 0.5407 - val_acc: 0.8917\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5422 - acc: 0.8909 - val_loss: 0.5111 - val_acc: 0.8960\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5165 - acc: 0.8943 - val_loss: 0.4962 - val_acc: 0.8981\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4968 - acc: 0.8975 - val_loss: 0.4904 - val_acc: 0.8989\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4806 - acc: 0.8996 - val_loss: 0.4736 - val_acc: 0.9016\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4660 - acc: 0.9017 - val_loss: 0.4692 - val_acc: 0.9028\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4528 - acc: 0.9039 - val_loss: 0.4586 - val_acc: 0.9041\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4396 - acc: 0.9055 - val_loss: 0.4556 - val_acc: 0.9043\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4301 - acc: 0.9068 - val_loss: 0.4478 - val_acc: 0.9058\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4216 - acc: 0.9080 - val_loss: 0.4424 - val_acc: 0.9066\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4096 - acc: 0.9099 - val_loss: 0.4413 - val_acc: 0.9066\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4010 - acc: 0.9109 - val_loss: 0.4430 - val_acc: 0.9064\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3914 - acc: 0.9125 - val_loss: 0.4337 - val_acc: 0.9074\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3839 - acc: 0.9135 - val_loss: 0.4298 - val_acc: 0.9091\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3749 - acc: 0.9149 - val_loss: 0.4266 - val_acc: 0.9111\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3679 - acc: 0.9163 - val_loss: 0.4225 - val_acc: 0.9114\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3593 - acc: 0.9175 - val_loss: 0.4241 - val_acc: 0.9099\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3535 - acc: 0.9186 - val_loss: 0.4276 - val_acc: 0.9105\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3468 - acc: 0.9198 - val_loss: 0.4254 - val_acc: 0.9098\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3402 - acc: 0.9206 - val_loss: 0.4209 - val_acc: 0.9120\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3314 - acc: 0.9223 - val_loss: 0.4238 - val_acc: 0.9123\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3271 - acc: 0.9230 - val_loss: 0.4214 - val_acc: 0.9123\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3209 - acc: 0.9240 - val_loss: 0.4320 - val_acc: 0.9115\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3179 - acc: 0.9245 - val_loss: 0.4239 - val_acc: 0.9123\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3093 - acc: 0.9259 - val_loss: 0.4267 - val_acc: 0.9125\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3034 - acc: 0.9272 - val_loss: 0.4233 - val_acc: 0.9125\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2992 - acc: 0.9278 - val_loss: 0.4248 - val_acc: 0.9125\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2911 - acc: 0.9291 - val_loss: 0.4310 - val_acc: 0.9133\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2880 - acc: 0.9296 - val_loss: 0.4286 - val_acc: 0.9130\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2820 - acc: 0.9308Restoring model weights from the end of the best epoch: 24.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2820 - acc: 0.9308 - val_loss: 0.4357 - val_acc: 0.9129\n",
      "Epoch 34: early stopping\n",
      "[0.4164224863052368, 0.41500693559646606, 0.41899019479751587, 0.39634546637535095, 0.4209042489528656]\n",
      "[23, 23, 22, 21, 24]\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9533 - acc: 0.8503 - val_loss: 0.7437 - val_acc: 0.8654\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7581 - acc: 0.8655 - val_loss: 0.6813 - val_acc: 0.8705\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6959 - acc: 0.8699 - val_loss: 0.6414 - val_acc: 0.8764\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6423 - acc: 0.8773 - val_loss: 0.5848 - val_acc: 0.8840\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5892 - acc: 0.8846 - val_loss: 0.5501 - val_acc: 0.8892\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5547 - acc: 0.8898 - val_loss: 0.5170 - val_acc: 0.8942\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5269 - acc: 0.8940 - val_loss: 0.5005 - val_acc: 0.8976\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5083 - acc: 0.8969 - val_loss: 0.4828 - val_acc: 0.9006\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4913 - acc: 0.8989 - val_loss: 0.4793 - val_acc: 0.9012\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4784 - acc: 0.9004 - val_loss: 0.4682 - val_acc: 0.9021\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4663 - acc: 0.9025 - val_loss: 0.4547 - val_acc: 0.9047\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4567 - acc: 0.9039 - val_loss: 0.4616 - val_acc: 0.9033\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4460 - acc: 0.9053 - val_loss: 0.4417 - val_acc: 0.9069\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4355 - acc: 0.9063 - val_loss: 0.4431 - val_acc: 0.9067\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4282 - acc: 0.9077 - val_loss: 0.4428 - val_acc: 0.9073\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4208 - acc: 0.9087 - val_loss: 0.4328 - val_acc: 0.9080\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4126 - acc: 0.9101 - val_loss: 0.4351 - val_acc: 0.9082\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4070 - acc: 0.9107 - val_loss: 0.4287 - val_acc: 0.9087\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3995 - acc: 0.9120 - val_loss: 0.4247 - val_acc: 0.9096\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3915 - acc: 0.9135 - val_loss: 0.4231 - val_acc: 0.9108\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3851 - acc: 0.9145 - val_loss: 0.4232 - val_acc: 0.9100\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3784 - acc: 0.9156 - val_loss: 0.4197 - val_acc: 0.9108\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3744 - acc: 0.9158 - val_loss: 0.4192 - val_acc: 0.9117\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3678 - acc: 0.9170 - val_loss: 0.4180 - val_acc: 0.9116\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3619 - acc: 0.9182 - val_loss: 0.4182 - val_acc: 0.9124\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3566 - acc: 0.9190 - val_loss: 0.4154 - val_acc: 0.9122\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3495 - acc: 0.9204 - val_loss: 0.4160 - val_acc: 0.9135\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3423 - acc: 0.9213 - val_loss: 0.4177 - val_acc: 0.9138\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3397 - acc: 0.9217 - val_loss: 0.4176 - val_acc: 0.9128\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3339 - acc: 0.9225 - val_loss: 0.4179 - val_acc: 0.9150\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3272 - acc: 0.9239 - val_loss: 0.4230 - val_acc: 0.9134\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3234 - acc: 0.9247 - val_loss: 0.4169 - val_acc: 0.9146\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3194 - acc: 0.9253 - val_loss: 0.4227 - val_acc: 0.9140\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3148 - acc: 0.9261 - val_loss: 0.4255 - val_acc: 0.9136\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3077 - acc: 0.9272 - val_loss: 0.4218 - val_acc: 0.9137\n",
      "Epoch 36/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.9280Restoring model weights from the end of the best epoch: 26.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3059 - acc: 0.9278 - val_loss: 0.4318 - val_acc: 0.9137\n",
      "Epoch 36: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 0.9621 - acc: 0.8505 - val_loss: 0.7485 - val_acc: 0.8639\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7574 - acc: 0.8659 - val_loss: 0.6876 - val_acc: 0.8695\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6950 - acc: 0.8702 - val_loss: 0.6458 - val_acc: 0.8752\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6455 - acc: 0.8765 - val_loss: 0.5951 - val_acc: 0.8827\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5959 - acc: 0.8831 - val_loss: 0.5556 - val_acc: 0.8881\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5624 - acc: 0.8884 - val_loss: 0.5386 - val_acc: 0.8909\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5368 - acc: 0.8924 - val_loss: 0.5049 - val_acc: 0.8963\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5170 - acc: 0.8955 - val_loss: 0.4968 - val_acc: 0.8968\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5027 - acc: 0.8969 - val_loss: 0.4906 - val_acc: 0.8977\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4886 - acc: 0.8996 - val_loss: 0.4787 - val_acc: 0.9006\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4763 - acc: 0.9009 - val_loss: 0.4701 - val_acc: 0.9012\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4636 - acc: 0.9029 - val_loss: 0.4659 - val_acc: 0.9020\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4543 - acc: 0.9042 - val_loss: 0.4548 - val_acc: 0.9041\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4468 - acc: 0.9055 - val_loss: 0.4472 - val_acc: 0.9049\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4373 - acc: 0.9067 - val_loss: 0.4453 - val_acc: 0.9060\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4287 - acc: 0.9076 - val_loss: 0.4485 - val_acc: 0.9052\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4195 - acc: 0.9088 - val_loss: 0.4361 - val_acc: 0.9074\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4144 - acc: 0.9096 - val_loss: 0.4287 - val_acc: 0.9087\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4048 - acc: 0.9115 - val_loss: 0.4284 - val_acc: 0.9088\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3984 - acc: 0.9124 - val_loss: 0.4315 - val_acc: 0.9090\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3939 - acc: 0.9131 - val_loss: 0.4282 - val_acc: 0.9097\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3861 - acc: 0.9145 - val_loss: 0.4262 - val_acc: 0.9105\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3806 - acc: 0.9150 - val_loss: 0.4205 - val_acc: 0.9115\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3737 - acc: 0.9162 - val_loss: 0.4281 - val_acc: 0.9111\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3688 - acc: 0.9170 - val_loss: 0.4208 - val_acc: 0.9114\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3621 - acc: 0.9181 - val_loss: 0.4231 - val_acc: 0.9105\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3576 - acc: 0.9189 - val_loss: 0.4211 - val_acc: 0.9118\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3534 - acc: 0.9196 - val_loss: 0.4181 - val_acc: 0.9123\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3488 - acc: 0.9201 - val_loss: 0.4191 - val_acc: 0.9122\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3422 - acc: 0.9215 - val_loss: 0.4215 - val_acc: 0.9121\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3379 - acc: 0.9221 - val_loss: 0.4222 - val_acc: 0.9134\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3325 - acc: 0.9228 - val_loss: 0.4194 - val_acc: 0.9138\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3260 - acc: 0.9245 - val_loss: 0.4191 - val_acc: 0.9134\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3228 - acc: 0.9246 - val_loss: 0.4208 - val_acc: 0.9131\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3184 - acc: 0.9255 - val_loss: 0.4318 - val_acc: 0.9126\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3138 - acc: 0.9261 - val_loss: 0.4290 - val_acc: 0.9128\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3103 - acc: 0.9266 - val_loss: 0.4245 - val_acc: 0.9138\n",
      "Epoch 38/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3059 - acc: 0.9275Restoring model weights from the end of the best epoch: 28.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3058 - acc: 0.9275 - val_loss: 0.4240 - val_acc: 0.9139\n",
      "Epoch 38: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 37ms/step - loss: 0.9461 - acc: 0.8510 - val_loss: 0.7460 - val_acc: 0.8636\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7525 - acc: 0.8661 - val_loss: 0.6878 - val_acc: 0.8683\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6914 - acc: 0.8706 - val_loss: 0.6394 - val_acc: 0.8750\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6360 - acc: 0.8782 - val_loss: 0.5819 - val_acc: 0.8842\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5861 - acc: 0.8852 - val_loss: 0.5543 - val_acc: 0.8891\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5544 - acc: 0.8904 - val_loss: 0.5333 - val_acc: 0.8929\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5301 - acc: 0.8936 - val_loss: 0.5093 - val_acc: 0.8949\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5120 - acc: 0.8959 - val_loss: 0.4941 - val_acc: 0.8977\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4970 - acc: 0.8980 - val_loss: 0.4913 - val_acc: 0.8974\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4822 - acc: 0.9002 - val_loss: 0.4788 - val_acc: 0.8995\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4708 - acc: 0.9020 - val_loss: 0.4696 - val_acc: 0.9012\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4577 - acc: 0.9036 - val_loss: 0.4636 - val_acc: 0.9022\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4469 - acc: 0.9052 - val_loss: 0.4511 - val_acc: 0.9040\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4373 - acc: 0.9068 - val_loss: 0.4458 - val_acc: 0.9055\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4261 - acc: 0.9086 - val_loss: 0.4433 - val_acc: 0.9058\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4187 - acc: 0.9094 - val_loss: 0.4388 - val_acc: 0.9067\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4085 - acc: 0.9109 - val_loss: 0.4371 - val_acc: 0.9071\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4024 - acc: 0.9124 - val_loss: 0.4400 - val_acc: 0.9074\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3953 - acc: 0.9134 - val_loss: 0.4295 - val_acc: 0.9082\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3885 - acc: 0.9139 - val_loss: 0.4330 - val_acc: 0.9087\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3826 - acc: 0.9152 - val_loss: 0.4262 - val_acc: 0.9098\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3735 - acc: 0.9167 - val_loss: 0.4266 - val_acc: 0.9098\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3690 - acc: 0.9175 - val_loss: 0.4218 - val_acc: 0.9095\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3617 - acc: 0.9185 - val_loss: 0.4214 - val_acc: 0.9102\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3561 - acc: 0.9194 - val_loss: 0.4190 - val_acc: 0.9112\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3503 - acc: 0.9202 - val_loss: 0.4217 - val_acc: 0.9106\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3460 - acc: 0.9209 - val_loss: 0.4240 - val_acc: 0.9117\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3404 - acc: 0.9223 - val_loss: 0.4188 - val_acc: 0.9121\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3342 - acc: 0.9231 - val_loss: 0.4262 - val_acc: 0.9113\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3286 - acc: 0.9238 - val_loss: 0.4248 - val_acc: 0.9120\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3236 - acc: 0.9245 - val_loss: 0.4259 - val_acc: 0.9111\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3205 - acc: 0.9252 - val_loss: 0.4257 - val_acc: 0.9115\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3152 - acc: 0.9262 - val_loss: 0.4313 - val_acc: 0.9113\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3088 - acc: 0.9270 - val_loss: 0.4261 - val_acc: 0.9122\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3047 - acc: 0.9277 - val_loss: 0.4302 - val_acc: 0.9117\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3002 - acc: 0.9284 - val_loss: 0.4359 - val_acc: 0.9128\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2935 - acc: 0.9295 - val_loss: 0.4387 - val_acc: 0.9115\n",
      "Epoch 38/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.9301Restoring model weights from the end of the best epoch: 28.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2916 - acc: 0.9301 - val_loss: 0.4382 - val_acc: 0.9118\n",
      "Epoch 38: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9756 - acc: 0.8490 - val_loss: 0.7179 - val_acc: 0.8698\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7602 - acc: 0.8644 - val_loss: 0.6509 - val_acc: 0.8767\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6955 - acc: 0.8698 - val_loss: 0.6052 - val_acc: 0.8831\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6388 - acc: 0.8770 - val_loss: 0.5563 - val_acc: 0.8889\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.5918 - acc: 0.8835 - val_loss: 0.5268 - val_acc: 0.8939\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5585 - acc: 0.8888 - val_loss: 0.4983 - val_acc: 0.8974\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5373 - acc: 0.8915 - val_loss: 0.4778 - val_acc: 0.9015\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5160 - acc: 0.8949 - val_loss: 0.4659 - val_acc: 0.9035\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5014 - acc: 0.8967 - val_loss: 0.4611 - val_acc: 0.9032\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4880 - acc: 0.8987 - val_loss: 0.4604 - val_acc: 0.9041\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4762 - acc: 0.9003 - val_loss: 0.4445 - val_acc: 0.9070\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4642 - acc: 0.9022 - val_loss: 0.4469 - val_acc: 0.9052\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4559 - acc: 0.9033 - val_loss: 0.4332 - val_acc: 0.9085\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4453 - acc: 0.9049 - val_loss: 0.4306 - val_acc: 0.9098\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4365 - acc: 0.9065 - val_loss: 0.4216 - val_acc: 0.9104\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4273 - acc: 0.9076 - val_loss: 0.4201 - val_acc: 0.9109\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4205 - acc: 0.9089 - val_loss: 0.4174 - val_acc: 0.9109\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4125 - acc: 0.9098 - val_loss: 0.4133 - val_acc: 0.9128\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4045 - acc: 0.9110 - val_loss: 0.4115 - val_acc: 0.9129\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3978 - acc: 0.9125 - val_loss: 0.4101 - val_acc: 0.9139\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3898 - acc: 0.9133 - val_loss: 0.4097 - val_acc: 0.9128\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3834 - acc: 0.9145 - val_loss: 0.4050 - val_acc: 0.9152\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3785 - acc: 0.9156 - val_loss: 0.4036 - val_acc: 0.9150\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3721 - acc: 0.9165 - val_loss: 0.4068 - val_acc: 0.9145\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3663 - acc: 0.9171 - val_loss: 0.4074 - val_acc: 0.9148\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3598 - acc: 0.9180 - val_loss: 0.3983 - val_acc: 0.9156\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3569 - acc: 0.9185 - val_loss: 0.4016 - val_acc: 0.9162\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3504 - acc: 0.9201 - val_loss: 0.4009 - val_acc: 0.9161\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3447 - acc: 0.9205 - val_loss: 0.4063 - val_acc: 0.9152\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3388 - acc: 0.9219 - val_loss: 0.3999 - val_acc: 0.9172\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3344 - acc: 0.9223 - val_loss: 0.4077 - val_acc: 0.9159\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3301 - acc: 0.9230 - val_loss: 0.4014 - val_acc: 0.9164\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3247 - acc: 0.9242 - val_loss: 0.4033 - val_acc: 0.9173\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3205 - acc: 0.9250 - val_loss: 0.4050 - val_acc: 0.9162\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3168 - acc: 0.9254 - val_loss: 0.4083 - val_acc: 0.9150\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3126 - acc: 0.9264Restoring model weights from the end of the best epoch: 26.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3126 - acc: 0.9264 - val_loss: 0.4104 - val_acc: 0.9167\n",
      "Epoch 36: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9536 - acc: 0.8507 - val_loss: 0.7375 - val_acc: 0.8660\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7517 - acc: 0.8657 - val_loss: 0.6765 - val_acc: 0.8718\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6890 - acc: 0.8710 - val_loss: 0.6337 - val_acc: 0.8769\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6345 - acc: 0.8783 - val_loss: 0.5805 - val_acc: 0.8848\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5890 - acc: 0.8845 - val_loss: 0.5540 - val_acc: 0.8888\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5551 - acc: 0.8898 - val_loss: 0.5217 - val_acc: 0.8948\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5309 - acc: 0.8932 - val_loss: 0.5048 - val_acc: 0.8972\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5128 - acc: 0.8953 - val_loss: 0.4915 - val_acc: 0.8985\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4947 - acc: 0.8979 - val_loss: 0.4806 - val_acc: 0.9008\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4797 - acc: 0.9004 - val_loss: 0.4720 - val_acc: 0.9019\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4691 - acc: 0.9018 - val_loss: 0.4699 - val_acc: 0.9026\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4596 - acc: 0.9034 - val_loss: 0.4610 - val_acc: 0.9044\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4470 - acc: 0.9051 - val_loss: 0.4552 - val_acc: 0.9051\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.9638 - acc: 0.8630 - val_loss: 0.8680 - val_acc: 0.8462\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7978 - acc: 0.8619 - val_loss: 0.7603 - val_acc: 0.8628\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.7752 - acc: 0.8634 - val_loss: 0.7312 - val_acc: 0.8643\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6556 - acc: 0.8735 - val_loss: 0.5502 - val_acc: 0.8867\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5078 - acc: 0.8939 - val_loss: 0.4775 - val_acc: 0.9005\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4627 - acc: 0.9018 - val_loss: 0.4702 - val_acc: 0.9010\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4433 - acc: 0.9046 - val_loss: 0.4511 - val_acc: 0.9048\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4316 - acc: 0.9067 - val_loss: 0.4437 - val_acc: 0.9069\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4240 - acc: 0.9080 - val_loss: 0.4404 - val_acc: 0.9064\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4168 - acc: 0.9092 - val_loss: 0.4398 - val_acc: 0.9066\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4106 - acc: 0.9101 - val_loss: 0.4355 - val_acc: 0.9079\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4039 - acc: 0.9110 - val_loss: 0.4302 - val_acc: 0.9085\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3995 - acc: 0.9117 - val_loss: 0.4343 - val_acc: 0.9083\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3942 - acc: 0.9124 - val_loss: 0.4340 - val_acc: 0.9084\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3896 - acc: 0.9130 - val_loss: 0.4300 - val_acc: 0.9107\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3852 - acc: 0.9139 - val_loss: 0.4314 - val_acc: 0.9085\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3813 - acc: 0.9144 - val_loss: 0.4276 - val_acc: 0.9103\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3760 - acc: 0.9153 - val_loss: 0.4288 - val_acc: 0.9102\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3700 - acc: 0.9166 - val_loss: 0.4296 - val_acc: 0.9102\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3656 - acc: 0.9171 - val_loss: 0.4260 - val_acc: 0.9103\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3616 - acc: 0.9182 - val_loss: 0.4251 - val_acc: 0.9115\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3584 - acc: 0.9182 - val_loss: 0.4281 - val_acc: 0.9118\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3519 - acc: 0.9196 - val_loss: 0.4244 - val_acc: 0.9113\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3476 - acc: 0.9203 - val_loss: 0.4276 - val_acc: 0.9119\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3440 - acc: 0.9206 - val_loss: 0.4247 - val_acc: 0.9125\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3402 - acc: 0.9215 - val_loss: 0.4285 - val_acc: 0.9116\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3374 - acc: 0.9216 - val_loss: 0.4296 - val_acc: 0.9108\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3333 - acc: 0.9228 - val_loss: 0.4300 - val_acc: 0.9125\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3258 - acc: 0.9241 - val_loss: 0.4253 - val_acc: 0.9121\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3242 - acc: 0.9237 - val_loss: 0.4361 - val_acc: 0.9091\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3200 - acc: 0.9248 - val_loss: 0.4318 - val_acc: 0.9117\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3152 - acc: 0.9254 - val_loss: 0.4327 - val_acc: 0.9120\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3110 - acc: 0.9263Restoring model weights from the end of the best epoch: 36.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3110 - acc: 0.9263 - val_loss: 0.4341 - val_acc: 0.9124\n",
      "Epoch 46: early stopping\n",
      "[0.41542574763298035, 0.4181099236011505, 0.4187959134578705, 0.39830562472343445, 0.42441171407699585]\n",
      "[26, 28, 28, 26, 36]\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9873 - acc: 0.8488 - val_loss: 0.7451 - val_acc: 0.8656\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7665 - acc: 0.8651 - val_loss: 0.6894 - val_acc: 0.8697\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7095 - acc: 0.8688 - val_loss: 0.6547 - val_acc: 0.8737\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6679 - acc: 0.8730 - val_loss: 0.6170 - val_acc: 0.8788\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6266 - acc: 0.8792 - val_loss: 0.5772 - val_acc: 0.8848\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5905 - acc: 0.8840 - val_loss: 0.5516 - val_acc: 0.8879\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5664 - acc: 0.8875 - val_loss: 0.5299 - val_acc: 0.8922\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5450 - acc: 0.8907 - val_loss: 0.5144 - val_acc: 0.8948\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5305 - acc: 0.8926 - val_loss: 0.5012 - val_acc: 0.8967\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5155 - acc: 0.8949 - val_loss: 0.4930 - val_acc: 0.8986\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5040 - acc: 0.8970 - val_loss: 0.4922 - val_acc: 0.8988\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4956 - acc: 0.8980 - val_loss: 0.4797 - val_acc: 0.9008\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4859 - acc: 0.8994 - val_loss: 0.4733 - val_acc: 0.9006\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4781 - acc: 0.9002 - val_loss: 0.4638 - val_acc: 0.9028\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4694 - acc: 0.9021 - val_loss: 0.4653 - val_acc: 0.9009\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4622 - acc: 0.9027 - val_loss: 0.4608 - val_acc: 0.9032\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4563 - acc: 0.9038 - val_loss: 0.4532 - val_acc: 0.9043\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4489 - acc: 0.9050 - val_loss: 0.4514 - val_acc: 0.9054\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4423 - acc: 0.9058 - val_loss: 0.4521 - val_acc: 0.9055\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4382 - acc: 0.9066 - val_loss: 0.4461 - val_acc: 0.9062\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4309 - acc: 0.9075 - val_loss: 0.4548 - val_acc: 0.9052\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4276 - acc: 0.9081 - val_loss: 0.4447 - val_acc: 0.9068\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4213 - acc: 0.9091 - val_loss: 0.4391 - val_acc: 0.9082\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4177 - acc: 0.9093 - val_loss: 0.4370 - val_acc: 0.9077\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4123 - acc: 0.9105 - val_loss: 0.4376 - val_acc: 0.9078\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4078 - acc: 0.9112 - val_loss: 0.4322 - val_acc: 0.9087\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4028 - acc: 0.9120 - val_loss: 0.4339 - val_acc: 0.9093\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3980 - acc: 0.9125 - val_loss: 0.4376 - val_acc: 0.9088\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3942 - acc: 0.9134 - val_loss: 0.4300 - val_acc: 0.9106\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3916 - acc: 0.9138 - val_loss: 0.4313 - val_acc: 0.9097\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3867 - acc: 0.9146 - val_loss: 0.4301 - val_acc: 0.9101\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3828 - acc: 0.9151 - val_loss: 0.4367 - val_acc: 0.9095\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3787 - acc: 0.9162 - val_loss: 0.4310 - val_acc: 0.9105\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3755 - acc: 0.9163 - val_loss: 0.4286 - val_acc: 0.9105\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3698 - acc: 0.9175 - val_loss: 0.4305 - val_acc: 0.9112\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3679 - acc: 0.9179 - val_loss: 0.4292 - val_acc: 0.9109\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3638 - acc: 0.9182 - val_loss: 0.4278 - val_acc: 0.9113\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3623 - acc: 0.9184 - val_loss: 0.4264 - val_acc: 0.9113\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3570 - acc: 0.9191 - val_loss: 0.4336 - val_acc: 0.9114\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3534 - acc: 0.9202 - val_loss: 0.4272 - val_acc: 0.9125\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3504 - acc: 0.9204 - val_loss: 0.4346 - val_acc: 0.9105\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3472 - acc: 0.9210 - val_loss: 0.4396 - val_acc: 0.9119\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3441 - acc: 0.9213 - val_loss: 0.4306 - val_acc: 0.9120\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3414 - acc: 0.9219 - val_loss: 0.4291 - val_acc: 0.9127\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3368 - acc: 0.9228 - val_loss: 0.4306 - val_acc: 0.9124\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3335 - acc: 0.9233 - val_loss: 0.4361 - val_acc: 0.9116\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3297 - acc: 0.9239 - val_loss: 0.4336 - val_acc: 0.9120\n",
      "Epoch 48/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3280 - acc: 0.9244Restoring model weights from the end of the best epoch: 38.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3283 - acc: 0.9243 - val_loss: 0.4359 - val_acc: 0.9118\n",
      "Epoch 48: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9907 - acc: 0.8493 - val_loss: 0.7517 - val_acc: 0.8648\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7720 - acc: 0.8650 - val_loss: 0.6960 - val_acc: 0.8694\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7108 - acc: 0.8690 - val_loss: 0.6592 - val_acc: 0.8729\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6713 - acc: 0.8731 - val_loss: 0.6206 - val_acc: 0.8792\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6258 - acc: 0.8795 - val_loss: 0.5760 - val_acc: 0.8856\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6176 - acc: 0.8809 - val_loss: 0.5554 - val_acc: 0.8880\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5660 - acc: 0.8878 - val_loss: 0.5290 - val_acc: 0.8920\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5440 - acc: 0.8909 - val_loss: 0.5117 - val_acc: 0.8949\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5264 - acc: 0.8935 - val_loss: 0.5029 - val_acc: 0.8961\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5132 - acc: 0.8960 - val_loss: 0.4963 - val_acc: 0.8962\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5027 - acc: 0.8973 - val_loss: 0.4819 - val_acc: 0.8996\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4916 - acc: 0.8990 - val_loss: 0.4758 - val_acc: 0.9003\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4815 - acc: 0.9002 - val_loss: 0.4695 - val_acc: 0.9011\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4725 - acc: 0.9019 - val_loss: 0.4642 - val_acc: 0.9030\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4666 - acc: 0.9029 - val_loss: 0.4692 - val_acc: 0.9024\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4582 - acc: 0.9042 - val_loss: 0.4558 - val_acc: 0.9042\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4543 - acc: 0.9044 - val_loss: 0.4569 - val_acc: 0.9026\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4452 - acc: 0.9059 - val_loss: 0.4488 - val_acc: 0.9049\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4386 - acc: 0.9068 - val_loss: 0.4464 - val_acc: 0.9051\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4334 - acc: 0.9077 - val_loss: 0.4427 - val_acc: 0.9071\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4265 - acc: 0.9086 - val_loss: 0.4374 - val_acc: 0.9065\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4223 - acc: 0.9093 - val_loss: 0.4397 - val_acc: 0.9074\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4154 - acc: 0.9103 - val_loss: 0.4356 - val_acc: 0.9077\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4111 - acc: 0.9111 - val_loss: 0.4345 - val_acc: 0.9080\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4183 - acc: 0.9096 - val_loss: 0.4383 - val_acc: 0.9069\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4050 - acc: 0.9117 - val_loss: 0.4286 - val_acc: 0.9092\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3966 - acc: 0.9136 - val_loss: 0.4294 - val_acc: 0.9092\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3923 - acc: 0.9138 - val_loss: 0.4272 - val_acc: 0.9096\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3891 - acc: 0.9145 - val_loss: 0.4315 - val_acc: 0.9096\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3845 - acc: 0.9152 - val_loss: 0.4284 - val_acc: 0.9092\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3793 - acc: 0.9162 - val_loss: 0.4246 - val_acc: 0.9096\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3750 - acc: 0.9169 - val_loss: 0.4229 - val_acc: 0.9110\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3711 - acc: 0.9179 - val_loss: 0.4223 - val_acc: 0.9100\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3683 - acc: 0.9182 - val_loss: 0.4252 - val_acc: 0.9108\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3632 - acc: 0.9186 - val_loss: 0.4290 - val_acc: 0.9111\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3601 - acc: 0.9194 - val_loss: 0.4261 - val_acc: 0.9103\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3573 - acc: 0.9201 - val_loss: 0.4233 - val_acc: 0.9119\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3528 - acc: 0.9208 - val_loss: 0.4280 - val_acc: 0.9117\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3505 - acc: 0.9212 - val_loss: 0.4247 - val_acc: 0.9106\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3461 - acc: 0.9221 - val_loss: 0.4214 - val_acc: 0.9117\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3420 - acc: 0.9224 - val_loss: 0.4269 - val_acc: 0.9123\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3372 - acc: 0.9232 - val_loss: 0.4260 - val_acc: 0.9131\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3351 - acc: 0.9238 - val_loss: 0.4209 - val_acc: 0.9133\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3303 - acc: 0.9245 - val_loss: 0.4267 - val_acc: 0.9129\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3278 - acc: 0.9249 - val_loss: 0.4263 - val_acc: 0.9131\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3248 - acc: 0.9257 - val_loss: 0.4284 - val_acc: 0.9131\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3207 - acc: 0.9261 - val_loss: 0.4298 - val_acc: 0.9126\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3159 - acc: 0.9273 - val_loss: 0.4309 - val_acc: 0.9122\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3139 - acc: 0.9272 - val_loss: 0.4365 - val_acc: 0.9123\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3101 - acc: 0.9281 - val_loss: 0.4322 - val_acc: 0.9131\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3078 - acc: 0.9285 - val_loss: 0.4372 - val_acc: 0.9123\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3043 - acc: 0.9294 - val_loss: 0.4380 - val_acc: 0.9123\n",
      "Epoch 53/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3026 - acc: 0.9293Restoring model weights from the end of the best epoch: 43.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3022 - acc: 0.9294 - val_loss: 0.4390 - val_acc: 0.9121\n",
      "Epoch 53: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 0.9800 - acc: 0.8495 - val_loss: 0.7520 - val_acc: 0.8623\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7660 - acc: 0.8659 - val_loss: 0.6887 - val_acc: 0.8685\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7056 - acc: 0.8696 - val_loss: 0.6548 - val_acc: 0.8713\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6612 - acc: 0.8746 - val_loss: 0.6093 - val_acc: 0.8790\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6147 - acc: 0.8812 - val_loss: 0.5711 - val_acc: 0.8854\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5794 - acc: 0.8860 - val_loss: 0.5429 - val_acc: 0.8898\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5812 - acc: 0.8848 - val_loss: 0.5280 - val_acc: 0.8920\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5394 - acc: 0.8917 - val_loss: 0.5233 - val_acc: 0.8931\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5252 - acc: 0.8938 - val_loss: 0.5066 - val_acc: 0.8952\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5141 - acc: 0.8954 - val_loss: 0.4963 - val_acc: 0.8965\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5020 - acc: 0.8970 - val_loss: 0.4907 - val_acc: 0.8972\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4922 - acc: 0.8988 - val_loss: 0.4854 - val_acc: 0.8980\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4850 - acc: 0.8996 - val_loss: 0.4818 - val_acc: 0.8980\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4783 - acc: 0.9006 - val_loss: 0.4759 - val_acc: 0.9002\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4715 - acc: 0.9012 - val_loss: 0.4729 - val_acc: 0.9000\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4651 - acc: 0.9026 - val_loss: 0.4724 - val_acc: 0.9001\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4600 - acc: 0.9030 - val_loss: 0.4709 - val_acc: 0.9003\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4514 - acc: 0.9044 - val_loss: 0.4615 - val_acc: 0.9027\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4468 - acc: 0.9052 - val_loss: 0.4604 - val_acc: 0.9023\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4421 - acc: 0.9056 - val_loss: 0.4573 - val_acc: 0.9039\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4352 - acc: 0.9070 - val_loss: 0.4507 - val_acc: 0.9044\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4318 - acc: 0.9073 - val_loss: 0.4600 - val_acc: 0.9030\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4265 - acc: 0.9083 - val_loss: 0.4484 - val_acc: 0.9047\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4213 - acc: 0.9091 - val_loss: 0.4484 - val_acc: 0.9053\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4165 - acc: 0.9103 - val_loss: 0.4500 - val_acc: 0.9043\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4120 - acc: 0.9106 - val_loss: 0.4453 - val_acc: 0.9064\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4076 - acc: 0.9112 - val_loss: 0.4433 - val_acc: 0.9065\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4028 - acc: 0.9120 - val_loss: 0.4381 - val_acc: 0.9073\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3982 - acc: 0.9130 - val_loss: 0.4391 - val_acc: 0.9065\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3953 - acc: 0.9135 - val_loss: 0.4461 - val_acc: 0.9079\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3915 - acc: 0.9139 - val_loss: 0.4367 - val_acc: 0.9070\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3863 - acc: 0.9151 - val_loss: 0.4392 - val_acc: 0.9078\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3824 - acc: 0.9157 - val_loss: 0.4355 - val_acc: 0.9086\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4039 - acc: 0.9118 - val_loss: 0.4381 - val_acc: 0.9088\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3786 - acc: 0.9161 - val_loss: 0.4357 - val_acc: 0.9072\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3721 - acc: 0.9172 - val_loss: 0.4337 - val_acc: 0.9088\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3692 - acc: 0.9174 - val_loss: 0.4320 - val_acc: 0.9095\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3650 - acc: 0.9185 - val_loss: 0.4341 - val_acc: 0.9094\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3607 - acc: 0.9190 - val_loss: 0.4357 - val_acc: 0.9097\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3603 - acc: 0.9194 - val_loss: 0.4373 - val_acc: 0.9095\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3550 - acc: 0.9203 - val_loss: 0.4372 - val_acc: 0.9106\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3520 - acc: 0.9206 - val_loss: 0.4315 - val_acc: 0.9090\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3492 - acc: 0.9212 - val_loss: 0.4354 - val_acc: 0.9088\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3464 - acc: 0.9212 - val_loss: 0.4391 - val_acc: 0.9095\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3441 - acc: 0.9218 - val_loss: 0.4339 - val_acc: 0.9097\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3418 - acc: 0.9219 - val_loss: 0.4417 - val_acc: 0.9098\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3387 - acc: 0.9229 - val_loss: 0.4354 - val_acc: 0.9100\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3356 - acc: 0.9232 - val_loss: 0.4412 - val_acc: 0.9095\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3326 - acc: 0.9239 - val_loss: 0.4408 - val_acc: 0.9106\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3310 - acc: 0.9243 - val_loss: 0.4427 - val_acc: 0.9107\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3266 - acc: 0.9250 - val_loss: 0.4412 - val_acc: 0.9106\n",
      "Epoch 52/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3241 - acc: 0.9253Restoring model weights from the end of the best epoch: 42.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3240 - acc: 0.9253 - val_loss: 0.4464 - val_acc: 0.9101\n",
      "Epoch 52: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.0097 - acc: 0.8466 - val_loss: 0.7287 - val_acc: 0.8692\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7816 - acc: 0.8638 - val_loss: 0.6762 - val_acc: 0.8725\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7217 - acc: 0.8676 - val_loss: 0.6404 - val_acc: 0.8772\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6781 - acc: 0.8719 - val_loss: 0.5986 - val_acc: 0.8831\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6370 - acc: 0.8781 - val_loss: 0.5601 - val_acc: 0.8883\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6032 - acc: 0.8823 - val_loss: 0.5321 - val_acc: 0.8921\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5794 - acc: 0.8855 - val_loss: 0.5167 - val_acc: 0.8952\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5560 - acc: 0.8887 - val_loss: 0.4999 - val_acc: 0.8982\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5424 - acc: 0.8912 - val_loss: 0.4915 - val_acc: 0.8988\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5284 - acc: 0.8932 - val_loss: 0.4781 - val_acc: 0.9020\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5165 - acc: 0.8950 - val_loss: 0.4748 - val_acc: 0.9015\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5063 - acc: 0.8963 - val_loss: 0.4652 - val_acc: 0.9037\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4972 - acc: 0.8977 - val_loss: 0.4669 - val_acc: 0.9027\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4902 - acc: 0.8986 - val_loss: 0.4565 - val_acc: 0.9049\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4969 - acc: 0.8966 - val_loss: 0.4574 - val_acc: 0.9034\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4801 - acc: 0.8996 - val_loss: 0.4525 - val_acc: 0.9052\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4700 - acc: 0.9014 - val_loss: 0.4442 - val_acc: 0.9074\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4632 - acc: 0.9024 - val_loss: 0.4380 - val_acc: 0.9077\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4566 - acc: 0.9034 - val_loss: 0.4351 - val_acc: 0.9089\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4530 - acc: 0.9037 - val_loss: 0.4336 - val_acc: 0.9080\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4459 - acc: 0.9051 - val_loss: 0.4356 - val_acc: 0.9090\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4408 - acc: 0.9056 - val_loss: 0.4235 - val_acc: 0.9102\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4351 - acc: 0.9066 - val_loss: 0.4272 - val_acc: 0.9097\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4316 - acc: 0.9072 - val_loss: 0.4213 - val_acc: 0.9109\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4250 - acc: 0.9082 - val_loss: 0.4242 - val_acc: 0.9112\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4228 - acc: 0.9086 - val_loss: 0.4206 - val_acc: 0.9105\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4181 - acc: 0.9092 - val_loss: 0.4207 - val_acc: 0.9105\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4120 - acc: 0.9101 - val_loss: 0.4125 - val_acc: 0.9130\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4066 - acc: 0.9106 - val_loss: 0.4213 - val_acc: 0.9111\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4040 - acc: 0.9113 - val_loss: 0.4149 - val_acc: 0.9129\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3995 - acc: 0.9119 - val_loss: 0.4166 - val_acc: 0.9127\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3971 - acc: 0.9124 - val_loss: 0.4158 - val_acc: 0.9132\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3914 - acc: 0.9132 - val_loss: 0.4158 - val_acc: 0.9131\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4220 - acc: 0.9085 - val_loss: 0.4132 - val_acc: 0.9130\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3873 - acc: 0.9141 - val_loss: 0.4088 - val_acc: 0.9143\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3789 - acc: 0.9158 - val_loss: 0.4090 - val_acc: 0.9138\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3761 - acc: 0.9161 - val_loss: 0.4121 - val_acc: 0.9138\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3743 - acc: 0.9165 - val_loss: 0.4091 - val_acc: 0.9147\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3722 - acc: 0.9166 - val_loss: 0.4198 - val_acc: 0.9138\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3668 - acc: 0.9178 - val_loss: 0.4105 - val_acc: 0.9152\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3631 - acc: 0.9182 - val_loss: 0.4172 - val_acc: 0.9146\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3623 - acc: 0.9185 - val_loss: 0.4093 - val_acc: 0.9156\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3587 - acc: 0.9188 - val_loss: 0.4104 - val_acc: 0.9151\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3553 - acc: 0.9197 - val_loss: 0.4116 - val_acc: 0.9149\n",
      "Epoch 45/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.9199Restoring model weights from the end of the best epoch: 35.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3538 - acc: 0.9199 - val_loss: 0.4117 - val_acc: 0.9154\n",
      "Epoch 45: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9839 - acc: 0.8486 - val_loss: 0.7474 - val_acc: 0.8647\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7694 - acc: 0.8651 - val_loss: 0.6930 - val_acc: 0.8699\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7015 - acc: 0.8698 - val_loss: 0.6455 - val_acc: 0.8761\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6579 - acc: 0.8751 - val_loss: 0.6014 - val_acc: 0.8810\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6149 - acc: 0.8810 - val_loss: 0.5646 - val_acc: 0.8879\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5801 - acc: 0.8860 - val_loss: 0.5447 - val_acc: 0.8905\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5576 - acc: 0.8895 - val_loss: 0.5198 - val_acc: 0.8948\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5389 - acc: 0.8922 - val_loss: 0.5115 - val_acc: 0.8961\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5226 - acc: 0.8945 - val_loss: 0.5012 - val_acc: 0.8964\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5097 - acc: 0.8962 - val_loss: 0.5053 - val_acc: 0.8960\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5002 - acc: 0.8977 - val_loss: 0.4833 - val_acc: 0.9011\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4901 - acc: 0.8992 - val_loss: 0.4835 - val_acc: 0.9007\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4810 - acc: 0.9003 - val_loss: 0.4708 - val_acc: 0.9023\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4727 - acc: 0.9015 - val_loss: 0.4735 - val_acc: 0.9017\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4645 - acc: 0.9028 - val_loss: 0.4620 - val_acc: 0.9040\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4572 - acc: 0.9037 - val_loss: 0.4558 - val_acc: 0.9049\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4513 - acc: 0.9050 - val_loss: 0.4560 - val_acc: 0.9059\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4451 - acc: 0.9054 - val_loss: 0.4542 - val_acc: 0.9057\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4365 - acc: 0.9070 - val_loss: 0.4518 - val_acc: 0.9048\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4314 - acc: 0.9076 - val_loss: 0.4454 - val_acc: 0.9069\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4260 - acc: 0.9086 - val_loss: 0.4474 - val_acc: 0.9066\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4216 - acc: 0.9090 - val_loss: 0.4443 - val_acc: 0.9059\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4168 - acc: 0.9099 - val_loss: 0.4432 - val_acc: 0.9083\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4109 - acc: 0.9109 - val_loss: 0.4371 - val_acc: 0.9088\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4062 - acc: 0.9113 - val_loss: 0.4429 - val_acc: 0.9071\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4012 - acc: 0.9123 - val_loss: 0.4354 - val_acc: 0.9091\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3954 - acc: 0.9131 - val_loss: 0.4381 - val_acc: 0.9085\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3891 - acc: 0.9143 - val_loss: 0.4353 - val_acc: 0.9100\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3870 - acc: 0.9150 - val_loss: 0.4284 - val_acc: 0.9108\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3818 - acc: 0.9159 - val_loss: 0.4342 - val_acc: 0.9105\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3786 - acc: 0.9161 - val_loss: 0.4327 - val_acc: 0.9105\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3742 - acc: 0.9169 - val_loss: 0.4291 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3694 - acc: 0.9176 - val_loss: 0.4314 - val_acc: 0.9105\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3655 - acc: 0.9187 - val_loss: 0.4296 - val_acc: 0.9110\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3609 - acc: 0.9192 - val_loss: 0.4338 - val_acc: 0.9117\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3570 - acc: 0.9199 - val_loss: 0.4320 - val_acc: 0.9112\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3515 - acc: 0.9206 - val_loss: 0.4361 - val_acc: 0.9121\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3488 - acc: 0.9216 - val_loss: 0.4354 - val_acc: 0.9112\n",
      "Epoch 39/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.9213Restoring model weights from the end of the best epoch: 29.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3478 - acc: 0.9213 - val_loss: 0.4341 - val_acc: 0.9119\n",
      "Epoch 39: early stopping\n",
      "[0.4264378845691681, 0.4208807647228241, 0.43149706721305847, 0.4087599813938141, 0.4283689856529236]\n",
      "[38, 43, 42, 35, 29]\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 1.0462 - acc: 0.8474 - val_loss: 0.7474 - val_acc: 0.8657\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7890 - acc: 0.8648 - val_loss: 0.6998 - val_acc: 0.8690\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7309 - acc: 0.8675 - val_loss: 0.6737 - val_acc: 0.8718\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6885 - acc: 0.8715 - val_loss: 0.6338 - val_acc: 0.8779\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6550 - acc: 0.8755 - val_loss: 0.5976 - val_acc: 0.8817\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6231 - acc: 0.8801 - val_loss: 0.5597 - val_acc: 0.8884\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5921 - acc: 0.8848 - val_loss: 0.5406 - val_acc: 0.8924\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5712 - acc: 0.8880 - val_loss: 0.5225 - val_acc: 0.8944\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5524 - acc: 0.8909 - val_loss: 0.5086 - val_acc: 0.8969\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5367 - acc: 0.8930 - val_loss: 0.5091 - val_acc: 0.8970\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5264 - acc: 0.8947 - val_loss: 0.4948 - val_acc: 0.8981\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5181 - acc: 0.8957 - val_loss: 0.4881 - val_acc: 0.8997\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5088 - acc: 0.8971 - val_loss: 0.4862 - val_acc: 0.8989\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5012 - acc: 0.8981 - val_loss: 0.4792 - val_acc: 0.9009\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4933 - acc: 0.8996 - val_loss: 0.4730 - val_acc: 0.9018\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4870 - acc: 0.9003 - val_loss: 0.4657 - val_acc: 0.9036\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4851 - acc: 0.9004 - val_loss: 0.4619 - val_acc: 0.9041\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4741 - acc: 0.9024 - val_loss: 0.4585 - val_acc: 0.9043\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4673 - acc: 0.9032 - val_loss: 0.4592 - val_acc: 0.9040\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4650 - acc: 0.9037 - val_loss: 0.4546 - val_acc: 0.9052\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4601 - acc: 0.9042 - val_loss: 0.4516 - val_acc: 0.9057\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4557 - acc: 0.9051 - val_loss: 0.4507 - val_acc: 0.9056\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4499 - acc: 0.9059 - val_loss: 0.4495 - val_acc: 0.9051\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4481 - acc: 0.9058 - val_loss: 0.4458 - val_acc: 0.9066\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4425 - acc: 0.9071 - val_loss: 0.4412 - val_acc: 0.9071\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4392 - acc: 0.9073 - val_loss: 0.4408 - val_acc: 0.9080\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4357 - acc: 0.9080 - val_loss: 0.4403 - val_acc: 0.9081\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4315 - acc: 0.9086 - val_loss: 0.4444 - val_acc: 0.9074\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4290 - acc: 0.9089 - val_loss: 0.4371 - val_acc: 0.9078\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4244 - acc: 0.9095 - val_loss: 0.4415 - val_acc: 0.9076\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4197 - acc: 0.9106 - val_loss: 0.4394 - val_acc: 0.9086\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4171 - acc: 0.9109 - val_loss: 0.4327 - val_acc: 0.9088\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4159 - acc: 0.9110 - val_loss: 0.4364 - val_acc: 0.9091\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4115 - acc: 0.9117 - val_loss: 0.4314 - val_acc: 0.9087\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4103 - acc: 0.9122 - val_loss: 0.4297 - val_acc: 0.9094\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4056 - acc: 0.9128 - val_loss: 0.4308 - val_acc: 0.9100\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4032 - acc: 0.9135 - val_loss: 0.4380 - val_acc: 0.9100\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3987 - acc: 0.9142 - val_loss: 0.4335 - val_acc: 0.9106\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3967 - acc: 0.9148 - val_loss: 0.4357 - val_acc: 0.9101\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3944 - acc: 0.9146 - val_loss: 0.4310 - val_acc: 0.9105\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3928 - acc: 0.9151 - val_loss: 0.4311 - val_acc: 0.9102\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3899 - acc: 0.9155 - val_loss: 0.4329 - val_acc: 0.9111\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3861 - acc: 0.9162 - val_loss: 0.4307 - val_acc: 0.9109\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3846 - acc: 0.9166 - val_loss: 0.4376 - val_acc: 0.9107\n",
      "Epoch 45/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.9171Restoring model weights from the end of the best epoch: 35.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3813 - acc: 0.9172 - val_loss: 0.4329 - val_acc: 0.9116\n",
      "Epoch 45: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 1.0585 - acc: 0.8465 - val_loss: 0.7556 - val_acc: 0.8636\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7873 - acc: 0.8650 - val_loss: 0.7092 - val_acc: 0.8670\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7306 - acc: 0.8677 - val_loss: 0.6686 - val_acc: 0.8702\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6937 - acc: 0.8707 - val_loss: 0.6391 - val_acc: 0.8772\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6582 - acc: 0.8757 - val_loss: 0.6067 - val_acc: 0.8799\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6232 - acc: 0.8799 - val_loss: 0.5756 - val_acc: 0.8824\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6020 - acc: 0.8822 - val_loss: 0.5554 - val_acc: 0.8872\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5803 - acc: 0.8853 - val_loss: 0.5368 - val_acc: 0.8902\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5612 - acc: 0.8887 - val_loss: 0.5259 - val_acc: 0.8917\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5454 - acc: 0.8912 - val_loss: 0.5135 - val_acc: 0.8957\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5336 - acc: 0.8931 - val_loss: 0.5095 - val_acc: 0.8943\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5237 - acc: 0.8946 - val_loss: 0.4944 - val_acc: 0.8977\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5184 - acc: 0.8952 - val_loss: 0.4919 - val_acc: 0.8972\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5086 - acc: 0.8969 - val_loss: 0.4875 - val_acc: 0.8989\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4997 - acc: 0.8981 - val_loss: 0.4923 - val_acc: 0.8978\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4944 - acc: 0.8985 - val_loss: 0.4836 - val_acc: 0.8995\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4866 - acc: 0.9001 - val_loss: 0.4728 - val_acc: 0.9009\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4825 - acc: 0.9006 - val_loss: 0.4683 - val_acc: 0.9019\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4764 - acc: 0.9016 - val_loss: 0.4702 - val_acc: 0.9025\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4718 - acc: 0.9023 - val_loss: 0.4630 - val_acc: 0.9028\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4789 - acc: 0.9008 - val_loss: 0.4764 - val_acc: 0.8992\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4670 - acc: 0.9030 - val_loss: 0.4575 - val_acc: 0.9038\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4572 - acc: 0.9044 - val_loss: 0.4596 - val_acc: 0.9028\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4547 - acc: 0.9050 - val_loss: 0.4570 - val_acc: 0.9036\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4502 - acc: 0.9055 - val_loss: 0.4539 - val_acc: 0.9039\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4450 - acc: 0.9066 - val_loss: 0.4496 - val_acc: 0.9057\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4428 - acc: 0.9062 - val_loss: 0.4471 - val_acc: 0.9056\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4377 - acc: 0.9075 - val_loss: 0.4487 - val_acc: 0.9047\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4353 - acc: 0.9082 - val_loss: 0.4507 - val_acc: 0.9051\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4315 - acc: 0.9085 - val_loss: 0.4456 - val_acc: 0.9050\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4282 - acc: 0.9092 - val_loss: 0.4453 - val_acc: 0.9075\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4244 - acc: 0.9100 - val_loss: 0.4398 - val_acc: 0.9069\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4205 - acc: 0.9102 - val_loss: 0.4430 - val_acc: 0.9066\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4190 - acc: 0.9105 - val_loss: 0.4448 - val_acc: 0.9073\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4160 - acc: 0.9110 - val_loss: 0.4367 - val_acc: 0.9077\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4132 - acc: 0.9114 - val_loss: 0.4354 - val_acc: 0.9085\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4087 - acc: 0.9124 - val_loss: 0.4484 - val_acc: 0.9069\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4047 - acc: 0.9132 - val_loss: 0.4379 - val_acc: 0.9085\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4038 - acc: 0.9136 - val_loss: 0.4383 - val_acc: 0.9093\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3996 - acc: 0.9140 - val_loss: 0.4360 - val_acc: 0.9088\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3979 - acc: 0.9144 - val_loss: 0.4341 - val_acc: 0.9094\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3928 - acc: 0.9151 - val_loss: 0.4388 - val_acc: 0.9088\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3913 - acc: 0.9156 - val_loss: 0.4383 - val_acc: 0.9093\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3897 - acc: 0.9154 - val_loss: 0.4365 - val_acc: 0.9098\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3876 - acc: 0.9165 - val_loss: 0.4415 - val_acc: 0.9091\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3841 - acc: 0.9168 - val_loss: 0.4338 - val_acc: 0.9107\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3802 - acc: 0.9175 - val_loss: 0.4350 - val_acc: 0.9097\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3796 - acc: 0.9178 - val_loss: 0.4352 - val_acc: 0.9097\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3761 - acc: 0.9182 - val_loss: 0.4395 - val_acc: 0.9088\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3743 - acc: 0.9188 - val_loss: 0.4368 - val_acc: 0.9104\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3727 - acc: 0.9189 - val_loss: 0.4324 - val_acc: 0.9100\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3702 - acc: 0.9195 - val_loss: 0.4339 - val_acc: 0.9109\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3693 - acc: 0.9198 - val_loss: 0.4319 - val_acc: 0.9109\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3656 - acc: 0.9199 - val_loss: 0.4379 - val_acc: 0.9116\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3604 - acc: 0.9209 - val_loss: 0.4399 - val_acc: 0.9111\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3575 - acc: 0.9217 - val_loss: 0.4389 - val_acc: 0.9114\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3579 - acc: 0.9220 - val_loss: 0.4321 - val_acc: 0.9117\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3547 - acc: 0.9221 - val_loss: 0.4422 - val_acc: 0.9121\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3517 - acc: 0.9226 - val_loss: 0.4395 - val_acc: 0.9099\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3495 - acc: 0.9231 - val_loss: 0.4375 - val_acc: 0.9112\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3490 - acc: 0.9227 - val_loss: 0.4399 - val_acc: 0.9114\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3446 - acc: 0.9239 - val_loss: 0.4431 - val_acc: 0.9117\n",
      "Epoch 63/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3434 - acc: 0.9241Restoring model weights from the end of the best epoch: 53.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3431 - acc: 0.9242 - val_loss: 0.4519 - val_acc: 0.9113\n",
      "Epoch 63: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 1.0468 - acc: 0.8479 - val_loss: 0.7652 - val_acc: 0.8609\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7970 - acc: 0.8647 - val_loss: 0.7296 - val_acc: 0.8650\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7422 - acc: 0.8674 - val_loss: 0.6867 - val_acc: 0.8686\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7017 - acc: 0.8703 - val_loss: 0.6571 - val_acc: 0.8728\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6660 - acc: 0.8741 - val_loss: 0.6172 - val_acc: 0.8770\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6331 - acc: 0.8793 - val_loss: 0.5889 - val_acc: 0.8826\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6060 - acc: 0.8828 - val_loss: 0.5714 - val_acc: 0.8854\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5855 - acc: 0.8855 - val_loss: 0.5514 - val_acc: 0.8880\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5676 - acc: 0.8881 - val_loss: 0.5377 - val_acc: 0.8907\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5547 - acc: 0.8899 - val_loss: 0.5305 - val_acc: 0.8917\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5419 - acc: 0.8918 - val_loss: 0.5203 - val_acc: 0.8934\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5324 - acc: 0.8936 - val_loss: 0.5190 - val_acc: 0.8932\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5244 - acc: 0.8948 - val_loss: 0.5065 - val_acc: 0.8958\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5165 - acc: 0.8956 - val_loss: 0.5010 - val_acc: 0.8969\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5091 - acc: 0.8971 - val_loss: 0.4957 - val_acc: 0.8970\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5034 - acc: 0.8978 - val_loss: 0.4901 - val_acc: 0.8983\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4973 - acc: 0.8987 - val_loss: 0.4896 - val_acc: 0.8985\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4977 - acc: 0.8982 - val_loss: 0.4934 - val_acc: 0.8965\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4881 - acc: 0.9001 - val_loss: 0.4783 - val_acc: 0.8997\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4798 - acc: 0.9014 - val_loss: 0.4777 - val_acc: 0.8995\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4763 - acc: 0.9019 - val_loss: 0.4717 - val_acc: 0.9002\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4727 - acc: 0.9027 - val_loss: 0.4763 - val_acc: 0.9016\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4684 - acc: 0.9033 - val_loss: 0.4705 - val_acc: 0.9006\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4653 - acc: 0.9038 - val_loss: 0.4698 - val_acc: 0.9015\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4605 - acc: 0.9043 - val_loss: 0.4657 - val_acc: 0.9027\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4574 - acc: 0.9048 - val_loss: 0.4631 - val_acc: 0.9031\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4552 - acc: 0.9050 - val_loss: 0.4633 - val_acc: 0.9031\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4523 - acc: 0.9056 - val_loss: 0.4580 - val_acc: 0.9044\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4480 - acc: 0.9065 - val_loss: 0.4613 - val_acc: 0.9038\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4457 - acc: 0.9069 - val_loss: 0.4592 - val_acc: 0.9044\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4414 - acc: 0.9073 - val_loss: 0.4660 - val_acc: 0.9032\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4386 - acc: 0.9079 - val_loss: 0.4496 - val_acc: 0.9064\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4331 - acc: 0.9087 - val_loss: 0.4517 - val_acc: 0.9052\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4325 - acc: 0.9087 - val_loss: 0.4515 - val_acc: 0.9053\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4295 - acc: 0.9090 - val_loss: 0.4505 - val_acc: 0.9067\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4261 - acc: 0.9102 - val_loss: 0.4497 - val_acc: 0.9065\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4261 - acc: 0.9101 - val_loss: 0.4455 - val_acc: 0.9067\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4225 - acc: 0.9104 - val_loss: 0.4431 - val_acc: 0.9073\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4198 - acc: 0.9112 - val_loss: 0.4498 - val_acc: 0.9070\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4165 - acc: 0.9113 - val_loss: 0.4459 - val_acc: 0.9079\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4134 - acc: 0.9119 - val_loss: 0.4466 - val_acc: 0.9070\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4116 - acc: 0.9123 - val_loss: 0.4457 - val_acc: 0.9067\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4089 - acc: 0.9127 - val_loss: 0.4467 - val_acc: 0.9070\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4070 - acc: 0.9129 - val_loss: 0.4451 - val_acc: 0.9074\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4049 - acc: 0.9134 - val_loss: 0.4407 - val_acc: 0.9079\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4015 - acc: 0.9141 - val_loss: 0.4392 - val_acc: 0.9083\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3992 - acc: 0.9144 - val_loss: 0.4397 - val_acc: 0.9088\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3985 - acc: 0.9146 - val_loss: 0.4434 - val_acc: 0.9083\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3968 - acc: 0.9148 - val_loss: 0.4421 - val_acc: 0.9080\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3957 - acc: 0.9154 - val_loss: 0.4430 - val_acc: 0.9080\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3911 - acc: 0.9160 - val_loss: 0.4436 - val_acc: 0.9098\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3894 - acc: 0.9161 - val_loss: 0.4453 - val_acc: 0.9083\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3885 - acc: 0.9166 - val_loss: 0.4387 - val_acc: 0.9084\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3870 - acc: 0.9168 - val_loss: 0.4386 - val_acc: 0.9098\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3835 - acc: 0.9176 - val_loss: 0.4392 - val_acc: 0.9095\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3838 - acc: 0.9174 - val_loss: 0.4395 - val_acc: 0.9094\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3809 - acc: 0.9177 - val_loss: 0.4389 - val_acc: 0.9093\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3775 - acc: 0.9181 - val_loss: 0.4466 - val_acc: 0.9084\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3765 - acc: 0.9185 - val_loss: 0.4438 - val_acc: 0.9094\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3760 - acc: 0.9185 - val_loss: 0.4390 - val_acc: 0.9098\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3726 - acc: 0.9191 - val_loss: 0.4399 - val_acc: 0.9091\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3701 - acc: 0.9194 - val_loss: 0.4424 - val_acc: 0.9104\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3696 - acc: 0.9195 - val_loss: 0.4457 - val_acc: 0.9101\n",
      "Epoch 64/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3659 - acc: 0.9200Restoring model weights from the end of the best epoch: 54.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3661 - acc: 0.9199 - val_loss: 0.4431 - val_acc: 0.9098\n",
      "Epoch 64: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 33ms/step - loss: 1.0621 - acc: 0.8452 - val_loss: 0.7295 - val_acc: 0.8685\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7990 - acc: 0.8636 - val_loss: 0.6838 - val_acc: 0.8728\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7413 - acc: 0.8663 - val_loss: 0.6420 - val_acc: 0.8760\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6960 - acc: 0.8702 - val_loss: 0.6082 - val_acc: 0.8810\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6584 - acc: 0.8754 - val_loss: 0.5739 - val_acc: 0.8874\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6261 - acc: 0.8795 - val_loss: 0.5431 - val_acc: 0.8910\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6011 - acc: 0.8825 - val_loss: 0.5276 - val_acc: 0.8947\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5803 - acc: 0.8862 - val_loss: 0.5095 - val_acc: 0.8970\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5645 - acc: 0.8888 - val_loss: 0.5064 - val_acc: 0.8976\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5513 - acc: 0.8904 - val_loss: 0.4924 - val_acc: 0.8999\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5392 - acc: 0.8922 - val_loss: 0.4831 - val_acc: 0.9016\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5311 - acc: 0.8934 - val_loss: 0.4757 - val_acc: 0.9025\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5212 - acc: 0.8950 - val_loss: 0.4691 - val_acc: 0.9022\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5150 - acc: 0.8960 - val_loss: 0.4625 - val_acc: 0.9037\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5065 - acc: 0.8974 - val_loss: 0.4584 - val_acc: 0.9045\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4998 - acc: 0.8984 - val_loss: 0.4569 - val_acc: 0.9053\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4970 - acc: 0.8984 - val_loss: 0.4536 - val_acc: 0.9059\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4905 - acc: 0.8995 - val_loss: 0.4528 - val_acc: 0.9055\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4864 - acc: 0.9003 - val_loss: 0.4575 - val_acc: 0.9044\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4804 - acc: 0.9012 - val_loss: 0.4465 - val_acc: 0.9066\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4770 - acc: 0.9015 - val_loss: 0.4511 - val_acc: 0.9052\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4710 - acc: 0.9025 - val_loss: 0.4431 - val_acc: 0.9073\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4669 - acc: 0.9030 - val_loss: 0.4409 - val_acc: 0.9079\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4623 - acc: 0.9037 - val_loss: 0.4344 - val_acc: 0.9085\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4594 - acc: 0.9043 - val_loss: 0.4368 - val_acc: 0.9080\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4555 - acc: 0.9048 - val_loss: 0.4336 - val_acc: 0.9090\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4527 - acc: 0.9054 - val_loss: 0.4354 - val_acc: 0.9096\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4494 - acc: 0.9058 - val_loss: 0.4318 - val_acc: 0.9091\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4458 - acc: 0.9060 - val_loss: 0.4287 - val_acc: 0.9100\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4422 - acc: 0.9067 - val_loss: 0.4278 - val_acc: 0.9102\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4370 - acc: 0.9074 - val_loss: 0.4292 - val_acc: 0.9103\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4350 - acc: 0.9078 - val_loss: 0.4301 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4321 - acc: 0.9084 - val_loss: 0.4265 - val_acc: 0.9101\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4295 - acc: 0.9087 - val_loss: 0.4221 - val_acc: 0.9117\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4263 - acc: 0.9093 - val_loss: 0.4280 - val_acc: 0.9117\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4223 - acc: 0.9098 - val_loss: 0.4207 - val_acc: 0.9113\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4202 - acc: 0.9102 - val_loss: 0.4245 - val_acc: 0.9107\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4188 - acc: 0.9105 - val_loss: 0.4196 - val_acc: 0.9116\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4151 - acc: 0.9111 - val_loss: 0.4214 - val_acc: 0.9120\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4120 - acc: 0.9114 - val_loss: 0.4187 - val_acc: 0.9125\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4077 - acc: 0.9123 - val_loss: 0.4198 - val_acc: 0.9123\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4080 - acc: 0.9122 - val_loss: 0.4180 - val_acc: 0.9129\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4043 - acc: 0.9130 - val_loss: 0.4175 - val_acc: 0.9128\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4005 - acc: 0.9132 - val_loss: 0.4235 - val_acc: 0.9117\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3988 - acc: 0.9136 - val_loss: 0.4166 - val_acc: 0.9135\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3948 - acc: 0.9147 - val_loss: 0.4173 - val_acc: 0.9133\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3942 - acc: 0.9147 - val_loss: 0.4167 - val_acc: 0.9136\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3904 - acc: 0.9154 - val_loss: 0.4191 - val_acc: 0.9133\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3882 - acc: 0.9156 - val_loss: 0.4190 - val_acc: 0.9137\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3853 - acc: 0.9164 - val_loss: 0.4201 - val_acc: 0.9142\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3839 - acc: 0.9166 - val_loss: 0.4175 - val_acc: 0.9132\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3819 - acc: 0.9168 - val_loss: 0.4204 - val_acc: 0.9137\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3786 - acc: 0.9175 - val_loss: 0.4197 - val_acc: 0.9143\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3778 - acc: 0.9176 - val_loss: 0.4190 - val_acc: 0.9145\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3740 - acc: 0.9179 - val_loss: 0.4163 - val_acc: 0.9154\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3703 - acc: 0.9187 - val_loss: 0.4227 - val_acc: 0.9141\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3680 - acc: 0.9189 - val_loss: 0.4288 - val_acc: 0.9151\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3687 - acc: 0.9192 - val_loss: 0.4194 - val_acc: 0.9150\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3624 - acc: 0.9205 - val_loss: 0.4225 - val_acc: 0.9134\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3634 - acc: 0.9199 - val_loss: 0.4238 - val_acc: 0.9147\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3588 - acc: 0.9207 - val_loss: 0.4236 - val_acc: 0.9151\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3572 - acc: 0.9210 - val_loss: 0.4200 - val_acc: 0.9144\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3569 - acc: 0.9212 - val_loss: 0.4213 - val_acc: 0.9150\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3506 - acc: 0.9225 - val_loss: 0.4267 - val_acc: 0.9138\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3522 - acc: 0.9221Restoring model weights from the end of the best epoch: 55.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3522 - acc: 0.9221 - val_loss: 0.4198 - val_acc: 0.9149\n",
      "Epoch 65: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 1.0579 - acc: 0.8464 - val_loss: 0.7490 - val_acc: 0.8647\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8000 - acc: 0.8642 - val_loss: 0.7108 - val_acc: 0.8683\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7395 - acc: 0.8674 - val_loss: 0.6755 - val_acc: 0.8718\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6934 - acc: 0.8711 - val_loss: 0.6334 - val_acc: 0.8765\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6598 - acc: 0.8749 - val_loss: 0.6079 - val_acc: 0.8801\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6316 - acc: 0.8786 - val_loss: 0.5792 - val_acc: 0.8836\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6325 - acc: 0.8778 - val_loss: 0.5603 - val_acc: 0.8867\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5855 - acc: 0.8849 - val_loss: 0.5408 - val_acc: 0.8911\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5664 - acc: 0.8880 - val_loss: 0.5300 - val_acc: 0.8932\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5494 - acc: 0.8906 - val_loss: 0.5199 - val_acc: 0.8948\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5390 - acc: 0.8924 - val_loss: 0.5118 - val_acc: 0.8955\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5294 - acc: 0.8933 - val_loss: 0.4997 - val_acc: 0.8976\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5217 - acc: 0.8944 - val_loss: 0.4949 - val_acc: 0.8982\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5127 - acc: 0.8959 - val_loss: 0.4932 - val_acc: 0.8984\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5065 - acc: 0.8969 - val_loss: 0.4853 - val_acc: 0.9007\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4992 - acc: 0.8980 - val_loss: 0.4869 - val_acc: 0.8997\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4956 - acc: 0.8983 - val_loss: 0.4776 - val_acc: 0.9011\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4882 - acc: 0.8995 - val_loss: 0.4795 - val_acc: 0.9022\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4837 - acc: 0.9001 - val_loss: 0.4776 - val_acc: 0.9008\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4768 - acc: 0.9012 - val_loss: 0.4712 - val_acc: 0.9032\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4721 - acc: 0.9017 - val_loss: 0.4709 - val_acc: 0.9032\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4687 - acc: 0.9024 - val_loss: 0.4668 - val_acc: 0.9033\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4642 - acc: 0.9033 - val_loss: 0.4667 - val_acc: 0.9039\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4597 - acc: 0.9039 - val_loss: 0.4582 - val_acc: 0.9049\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4545 - acc: 0.9048 - val_loss: 0.4566 - val_acc: 0.9053\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4510 - acc: 0.9053 - val_loss: 0.4571 - val_acc: 0.9052\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6238 - acc: 0.8804 - val_loss: 0.4757 - val_acc: 0.9010\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4897 - acc: 0.8982 - val_loss: 0.4626 - val_acc: 0.9029\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4542 - acc: 0.9045 - val_loss: 0.4542 - val_acc: 0.9055\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4461 - acc: 0.9061 - val_loss: 0.4489 - val_acc: 0.9058\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4391 - acc: 0.9069 - val_loss: 0.4493 - val_acc: 0.9063\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4366 - acc: 0.9073 - val_loss: 0.4467 - val_acc: 0.9064\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4333 - acc: 0.9083 - val_loss: 0.4433 - val_acc: 0.9076\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4309 - acc: 0.9086 - val_loss: 0.4495 - val_acc: 0.9066\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4276 - acc: 0.9090 - val_loss: 0.4466 - val_acc: 0.9075\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4266 - acc: 0.9091 - val_loss: 0.4413 - val_acc: 0.9077\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4234 - acc: 0.9094 - val_loss: 0.4431 - val_acc: 0.9071\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4218 - acc: 0.9098 - val_loss: 0.4385 - val_acc: 0.9083\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4192 - acc: 0.9098 - val_loss: 0.4419 - val_acc: 0.9085\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4166 - acc: 0.9110 - val_loss: 0.4391 - val_acc: 0.9086\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4149 - acc: 0.9110 - val_loss: 0.4439 - val_acc: 0.9084\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4141 - acc: 0.9112 - val_loss: 0.4394 - val_acc: 0.9087\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4114 - acc: 0.9119 - val_loss: 0.4430 - val_acc: 0.9083\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4099 - acc: 0.9119 - val_loss: 0.4422 - val_acc: 0.9085\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4052 - acc: 0.9127 - val_loss: 0.4376 - val_acc: 0.9078\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4056 - acc: 0.9126 - val_loss: 0.4389 - val_acc: 0.9084\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4008 - acc: 0.9132 - val_loss: 0.4384 - val_acc: 0.9085\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5157 - acc: 0.8950 - val_loss: 0.4586 - val_acc: 0.9046\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4262 - acc: 0.9091 - val_loss: 0.4406 - val_acc: 0.9090\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4062 - acc: 0.9126 - val_loss: 0.4354 - val_acc: 0.9091\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3972 - acc: 0.9146 - val_loss: 0.4373 - val_acc: 0.9103\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3926 - acc: 0.9147 - val_loss: 0.4326 - val_acc: 0.9100\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3881 - acc: 0.9155 - val_loss: 0.4327 - val_acc: 0.9098\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3880 - acc: 0.9156 - val_loss: 0.4460 - val_acc: 0.9102\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3851 - acc: 0.9165 - val_loss: 0.4348 - val_acc: 0.9106\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3831 - acc: 0.9167 - val_loss: 0.4347 - val_acc: 0.9104\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3817 - acc: 0.9167 - val_loss: 0.4370 - val_acc: 0.9105\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3798 - acc: 0.9173 - val_loss: 0.4393 - val_acc: 0.9108\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3790 - acc: 0.9172 - val_loss: 0.4360 - val_acc: 0.9098\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3924 - acc: 0.9151 - val_loss: 0.4383 - val_acc: 0.9102\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3759 - acc: 0.9179 - val_loss: 0.4408 - val_acc: 0.9103\n",
      "Epoch 62/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.9184Restoring model weights from the end of the best epoch: 52.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3740 - acc: 0.9185 - val_loss: 0.4387 - val_acc: 0.9115\n",
      "Epoch 62: early stopping\n",
      "[0.42966583371162415, 0.43189582228660583, 0.4386266767978668, 0.41632378101348877, 0.4325978457927704]\n",
      "[35, 53, 54, 55, 52]\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 1.2234 - acc: 0.8410 - val_loss: 0.7756 - val_acc: 0.8635\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.8394 - acc: 0.8620 - val_loss: 0.7404 - val_acc: 0.8658\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7893 - acc: 0.8648 - val_loss: 0.7121 - val_acc: 0.8684\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7566 - acc: 0.8666 - val_loss: 0.6953 - val_acc: 0.8695\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7302 - acc: 0.8680 - val_loss: 0.6614 - val_acc: 0.8733\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.7013 - acc: 0.8710 - val_loss: 0.6427 - val_acc: 0.8757\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6795 - acc: 0.8731 - val_loss: 0.6276 - val_acc: 0.8774\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6624 - acc: 0.8752 - val_loss: 0.6084 - val_acc: 0.8800\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6457 - acc: 0.8776 - val_loss: 0.5935 - val_acc: 0.8828\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6265 - acc: 0.8809 - val_loss: 0.5897 - val_acc: 0.8836\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6135 - acc: 0.8825 - val_loss: 0.5647 - val_acc: 0.8880\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6015 - acc: 0.8843 - val_loss: 0.5570 - val_acc: 0.8895\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5903 - acc: 0.8854 - val_loss: 0.5464 - val_acc: 0.8906\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5848 - acc: 0.8862 - val_loss: 0.5492 - val_acc: 0.8891\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5758 - acc: 0.8876 - val_loss: 0.5356 - val_acc: 0.8914\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5668 - acc: 0.8890 - val_loss: 0.5252 - val_acc: 0.8929\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5610 - acc: 0.8897 - val_loss: 0.5237 - val_acc: 0.8936\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5664 - acc: 0.8885 - val_loss: 0.5356 - val_acc: 0.8909\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5531 - acc: 0.8908 - val_loss: 0.5125 - val_acc: 0.8952\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5466 - acc: 0.8919 - val_loss: 0.5103 - val_acc: 0.8962\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5414 - acc: 0.8925 - val_loss: 0.5105 - val_acc: 0.8964\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5392 - acc: 0.8930 - val_loss: 0.5033 - val_acc: 0.8974\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5342 - acc: 0.8937 - val_loss: 0.5030 - val_acc: 0.8972\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5307 - acc: 0.8942 - val_loss: 0.4998 - val_acc: 0.8975\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5292 - acc: 0.8944 - val_loss: 0.4989 - val_acc: 0.8983\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5246 - acc: 0.8952 - val_loss: 0.4959 - val_acc: 0.8985\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5219 - acc: 0.8953 - val_loss: 0.5084 - val_acc: 0.8947\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5187 - acc: 0.8962 - val_loss: 0.4948 - val_acc: 0.8987\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5174 - acc: 0.8961 - val_loss: 0.4931 - val_acc: 0.8994\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5131 - acc: 0.8969 - val_loss: 0.4934 - val_acc: 0.8981\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5137 - acc: 0.8963 - val_loss: 0.4933 - val_acc: 0.8989\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5085 - acc: 0.8975 - val_loss: 0.4898 - val_acc: 0.9002\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5075 - acc: 0.8976 - val_loss: 0.4869 - val_acc: 0.8995\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5029 - acc: 0.8983 - val_loss: 0.4845 - val_acc: 0.8998\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5024 - acc: 0.8986 - val_loss: 0.4819 - val_acc: 0.9002\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5019 - acc: 0.8980 - val_loss: 0.4828 - val_acc: 0.9002\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4989 - acc: 0.8987 - val_loss: 0.4826 - val_acc: 0.9007\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4964 - acc: 0.8993 - val_loss: 0.4806 - val_acc: 0.9013\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4945 - acc: 0.8998 - val_loss: 0.4851 - val_acc: 0.9004\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4938 - acc: 0.8995 - val_loss: 0.4778 - val_acc: 0.9011\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4903 - acc: 0.9004 - val_loss: 0.4772 - val_acc: 0.9020\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4903 - acc: 0.9004 - val_loss: 0.4758 - val_acc: 0.9019\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4882 - acc: 0.9008 - val_loss: 0.4752 - val_acc: 0.9022\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4845 - acc: 0.9013 - val_loss: 0.4731 - val_acc: 0.9021\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4839 - acc: 0.9016 - val_loss: 0.4785 - val_acc: 0.9018\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4826 - acc: 0.9016 - val_loss: 0.4772 - val_acc: 0.9024\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4833 - acc: 0.9015 - val_loss: 0.4760 - val_acc: 0.9020\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4795 - acc: 0.9021 - val_loss: 0.4715 - val_acc: 0.9022\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4781 - acc: 0.9023 - val_loss: 0.4706 - val_acc: 0.9030\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4758 - acc: 0.9027 - val_loss: 0.4679 - val_acc: 0.9036\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4755 - acc: 0.9029 - val_loss: 0.4687 - val_acc: 0.9034\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4724 - acc: 0.9036 - val_loss: 0.4705 - val_acc: 0.9036\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4697 - acc: 0.9038 - val_loss: 0.4699 - val_acc: 0.9042\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4676 - acc: 0.9040 - val_loss: 0.4716 - val_acc: 0.9040\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4672 - acc: 0.9042 - val_loss: 0.4668 - val_acc: 0.9034\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4659 - acc: 0.9044 - val_loss: 0.4691 - val_acc: 0.9046\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4650 - acc: 0.9047 - val_loss: 0.4695 - val_acc: 0.9044\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4623 - acc: 0.9050 - val_loss: 0.4656 - val_acc: 0.9045\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4624 - acc: 0.9049 - val_loss: 0.4688 - val_acc: 0.9045\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4603 - acc: 0.9053 - val_loss: 0.4640 - val_acc: 0.9048\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4590 - acc: 0.9055 - val_loss: 0.4655 - val_acc: 0.9041\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4590 - acc: 0.9055 - val_loss: 0.4648 - val_acc: 0.9046\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4547 - acc: 0.9058 - val_loss: 0.4716 - val_acc: 0.9044\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4560 - acc: 0.9063 - val_loss: 0.4639 - val_acc: 0.9061\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4528 - acc: 0.9069 - val_loss: 0.4642 - val_acc: 0.9046\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4525 - acc: 0.9066 - val_loss: 0.4635 - val_acc: 0.9051\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4537 - acc: 0.9063 - val_loss: 0.4690 - val_acc: 0.9044\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4511 - acc: 0.9070 - val_loss: 0.4623 - val_acc: 0.9060\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4475 - acc: 0.9071 - val_loss: 0.4674 - val_acc: 0.9061\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4534 - acc: 0.9069 - val_loss: 0.4700 - val_acc: 0.9043\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4498 - acc: 0.9073 - val_loss: 0.4689 - val_acc: 0.9047\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4452 - acc: 0.9078 - val_loss: 0.4623 - val_acc: 0.9060\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4438 - acc: 0.9082 - val_loss: 0.4702 - val_acc: 0.9064\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4434 - acc: 0.9081 - val_loss: 0.4738 - val_acc: 0.9062\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4434 - acc: 0.9082 - val_loss: 0.4638 - val_acc: 0.9058\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4411 - acc: 0.9085 - val_loss: 0.4669 - val_acc: 0.9057\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4415 - acc: 0.9082 - val_loss: 0.4622 - val_acc: 0.9061\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4383 - acc: 0.9090 - val_loss: 0.4747 - val_acc: 0.9057\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4388 - acc: 0.9091 - val_loss: 0.4644 - val_acc: 0.9059\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4371 - acc: 0.9095 - val_loss: 0.4659 - val_acc: 0.9060\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4340 - acc: 0.9095 - val_loss: 0.4620 - val_acc: 0.9058\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4360 - acc: 0.9093 - val_loss: 0.4722 - val_acc: 0.9051\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4353 - acc: 0.9096 - val_loss: 0.4651 - val_acc: 0.9062\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4332 - acc: 0.9099 - val_loss: 0.4638 - val_acc: 0.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4329 - acc: 0.9098 - val_loss: 0.4633 - val_acc: 0.9070\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4326 - acc: 0.9100 - val_loss: 0.4647 - val_acc: 0.9060\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4303 - acc: 0.9102 - val_loss: 0.4678 - val_acc: 0.9070\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4312 - acc: 0.9101 - val_loss: 0.4643 - val_acc: 0.9057\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4297 - acc: 0.9107 - val_loss: 0.4622 - val_acc: 0.9067\n",
      "Epoch 90/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4287 - acc: 0.9104 - val_loss: 0.4638 - val_acc: 0.9067\n",
      "Epoch 91/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4267 - acc: 0.9109Restoring model weights from the end of the best epoch: 81.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4267 - acc: 0.9109 - val_loss: 0.4669 - val_acc: 0.9069\n",
      "Epoch 91: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 1.2155 - acc: 0.8419 - val_loss: 0.7817 - val_acc: 0.8625\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8469 - acc: 0.8626 - val_loss: 0.7523 - val_acc: 0.8653\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7902 - acc: 0.8651 - val_loss: 0.7212 - val_acc: 0.8659\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7555 - acc: 0.8669 - val_loss: 0.6998 - val_acc: 0.8670\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7284 - acc: 0.8682 - val_loss: 0.6747 - val_acc: 0.8701\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7035 - acc: 0.8704 - val_loss: 0.6511 - val_acc: 0.8736\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6809 - acc: 0.8732 - val_loss: 0.6288 - val_acc: 0.8770\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6593 - acc: 0.8760 - val_loss: 0.6055 - val_acc: 0.8805\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6410 - acc: 0.8784 - val_loss: 0.5918 - val_acc: 0.8819\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6280 - acc: 0.8800 - val_loss: 0.5783 - val_acc: 0.8838\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6150 - acc: 0.8815 - val_loss: 0.5686 - val_acc: 0.8854\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6054 - acc: 0.8829 - val_loss: 0.5680 - val_acc: 0.8852\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5956 - acc: 0.8838 - val_loss: 0.5539 - val_acc: 0.8868\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5868 - acc: 0.8849 - val_loss: 0.5511 - val_acc: 0.8885\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5778 - acc: 0.8862 - val_loss: 0.5431 - val_acc: 0.8899\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5708 - acc: 0.8872 - val_loss: 0.5318 - val_acc: 0.8912\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5619 - acc: 0.8886 - val_loss: 0.5332 - val_acc: 0.8909\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5570 - acc: 0.8896 - val_loss: 0.5231 - val_acc: 0.8925\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5504 - acc: 0.8906 - val_loss: 0.5191 - val_acc: 0.8934\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5461 - acc: 0.8915 - val_loss: 0.5172 - val_acc: 0.8946\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5415 - acc: 0.8922 - val_loss: 0.5106 - val_acc: 0.8953\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5362 - acc: 0.8930 - val_loss: 0.5120 - val_acc: 0.8948\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5326 - acc: 0.8935 - val_loss: 0.5051 - val_acc: 0.8971\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5277 - acc: 0.8947 - val_loss: 0.5046 - val_acc: 0.8962\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5263 - acc: 0.8950 - val_loss: 0.5029 - val_acc: 0.8962\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5234 - acc: 0.8954 - val_loss: 0.5051 - val_acc: 0.8966\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5174 - acc: 0.8961 - val_loss: 0.4980 - val_acc: 0.8975\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5155 - acc: 0.8965 - val_loss: 0.4947 - val_acc: 0.8986\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5135 - acc: 0.8968 - val_loss: 0.4935 - val_acc: 0.8983\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5092 - acc: 0.8976 - val_loss: 0.4939 - val_acc: 0.8981\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5066 - acc: 0.8980 - val_loss: 0.4919 - val_acc: 0.8993\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5049 - acc: 0.8985 - val_loss: 0.4873 - val_acc: 0.9004\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5048 - acc: 0.8985 - val_loss: 0.4924 - val_acc: 0.8995\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5001 - acc: 0.8995 - val_loss: 0.4889 - val_acc: 0.8999\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4972 - acc: 0.8998 - val_loss: 0.4844 - val_acc: 0.9012\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4955 - acc: 0.9002 - val_loss: 0.4866 - val_acc: 0.9000\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4938 - acc: 0.9003 - val_loss: 0.4799 - val_acc: 0.9021\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4898 - acc: 0.9008 - val_loss: 0.4818 - val_acc: 0.9011\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4886 - acc: 0.9013 - val_loss: 0.4808 - val_acc: 0.9017\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4861 - acc: 0.9016 - val_loss: 0.4779 - val_acc: 0.9019\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4857 - acc: 0.9019 - val_loss: 0.4811 - val_acc: 0.9011\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4830 - acc: 0.9020 - val_loss: 0.4791 - val_acc: 0.9019\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4825 - acc: 0.9021 - val_loss: 0.4795 - val_acc: 0.9016\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4793 - acc: 0.9028 - val_loss: 0.4780 - val_acc: 0.9018\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4771 - acc: 0.9034 - val_loss: 0.4777 - val_acc: 0.9026\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4760 - acc: 0.9033 - val_loss: 0.4771 - val_acc: 0.9016\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4729 - acc: 0.9039 - val_loss: 0.4790 - val_acc: 0.9025\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4729 - acc: 0.9038 - val_loss: 0.4756 - val_acc: 0.9024\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4693 - acc: 0.9042 - val_loss: 0.4748 - val_acc: 0.9037\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4693 - acc: 0.9042 - val_loss: 0.4749 - val_acc: 0.9026\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4677 - acc: 0.9045 - val_loss: 0.4712 - val_acc: 0.9035\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4648 - acc: 0.9053 - val_loss: 0.4711 - val_acc: 0.9036\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4665 - acc: 0.9049 - val_loss: 0.4714 - val_acc: 0.9032\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4621 - acc: 0.9059 - val_loss: 0.4722 - val_acc: 0.9038\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4617 - acc: 0.9058 - val_loss: 0.4718 - val_acc: 0.9045\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4600 - acc: 0.9061 - val_loss: 0.4729 - val_acc: 0.9039\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4579 - acc: 0.9064 - val_loss: 0.4704 - val_acc: 0.9036\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4571 - acc: 0.9064 - val_loss: 0.4707 - val_acc: 0.9036\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4543 - acc: 0.9072 - val_loss: 0.4680 - val_acc: 0.9048\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4532 - acc: 0.9072 - val_loss: 0.4694 - val_acc: 0.9033\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4538 - acc: 0.9073 - val_loss: 0.4703 - val_acc: 0.9044\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4499 - acc: 0.9074 - val_loss: 0.4685 - val_acc: 0.9044\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4492 - acc: 0.9082 - val_loss: 0.4727 - val_acc: 0.9047\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4474 - acc: 0.9080 - val_loss: 0.4694 - val_acc: 0.9045\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4452 - acc: 0.9086 - val_loss: 0.4706 - val_acc: 0.9040\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4448 - acc: 0.9082 - val_loss: 0.4747 - val_acc: 0.9055\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4447 - acc: 0.9085 - val_loss: 0.4706 - val_acc: 0.9060\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4426 - acc: 0.9088 - val_loss: 0.4708 - val_acc: 0.9044\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.4407 - acc: 0.9094Restoring model weights from the end of the best epoch: 59.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4407 - acc: 0.9094 - val_loss: 0.4704 - val_acc: 0.9040\n",
      "Epoch 69: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 1.2058 - acc: 0.8422 - val_loss: 0.7830 - val_acc: 0.8606\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8377 - acc: 0.8628 - val_loss: 0.7590 - val_acc: 0.8634\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7905 - acc: 0.8653 - val_loss: 0.7257 - val_acc: 0.8661\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7542 - acc: 0.8670 - val_loss: 0.6999 - val_acc: 0.8671\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7282 - acc: 0.8684 - val_loss: 0.6833 - val_acc: 0.8682\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7098 - acc: 0.8699 - val_loss: 0.6582 - val_acc: 0.8719\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6881 - acc: 0.8721 - val_loss: 0.6369 - val_acc: 0.8749\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6682 - acc: 0.8745 - val_loss: 0.6219 - val_acc: 0.8770\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6508 - acc: 0.8768 - val_loss: 0.6074 - val_acc: 0.8812\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6343 - acc: 0.8791 - val_loss: 0.5951 - val_acc: 0.8814\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6221 - acc: 0.8810 - val_loss: 0.5850 - val_acc: 0.8826\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6101 - acc: 0.8824 - val_loss: 0.5690 - val_acc: 0.8843\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6005 - acc: 0.8835 - val_loss: 0.5650 - val_acc: 0.8851\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5909 - acc: 0.8849 - val_loss: 0.5630 - val_acc: 0.8854\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5839 - acc: 0.8857 - val_loss: 0.5527 - val_acc: 0.8870\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5742 - acc: 0.8869 - val_loss: 0.5547 - val_acc: 0.8864\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5728 - acc: 0.8868 - val_loss: 0.5398 - val_acc: 0.8897\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5632 - acc: 0.8884 - val_loss: 0.5337 - val_acc: 0.8910\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5578 - acc: 0.8895 - val_loss: 0.5348 - val_acc: 0.8916\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5528 - acc: 0.8903 - val_loss: 0.5277 - val_acc: 0.8923\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5487 - acc: 0.8910 - val_loss: 0.5285 - val_acc: 0.8922\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5439 - acc: 0.8916 - val_loss: 0.5220 - val_acc: 0.8932\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5390 - acc: 0.8924 - val_loss: 0.5159 - val_acc: 0.8937\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5345 - acc: 0.8932 - val_loss: 0.5165 - val_acc: 0.8948\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5312 - acc: 0.8938 - val_loss: 0.5099 - val_acc: 0.8953\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5292 - acc: 0.8943 - val_loss: 0.5154 - val_acc: 0.8937\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5262 - acc: 0.8943 - val_loss: 0.5075 - val_acc: 0.8953\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6377 - acc: 0.8782 - val_loss: 0.5569 - val_acc: 0.8870\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5576 - acc: 0.8890 - val_loss: 0.5190 - val_acc: 0.8932\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5346 - acc: 0.8932 - val_loss: 0.5091 - val_acc: 0.8951\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5244 - acc: 0.8949 - val_loss: 0.5061 - val_acc: 0.8953\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5199 - acc: 0.8958 - val_loss: 0.5057 - val_acc: 0.8957\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5166 - acc: 0.8962 - val_loss: 0.4991 - val_acc: 0.8971\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5154 - acc: 0.8961 - val_loss: 0.5011 - val_acc: 0.8958\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5121 - acc: 0.8970 - val_loss: 0.5056 - val_acc: 0.8957\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5094 - acc: 0.8972 - val_loss: 0.4954 - val_acc: 0.8969\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5067 - acc: 0.8979 - val_loss: 0.4951 - val_acc: 0.8972\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5050 - acc: 0.8978 - val_loss: 0.4989 - val_acc: 0.8971\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5021 - acc: 0.8986 - val_loss: 0.4924 - val_acc: 0.8982\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5023 - acc: 0.8985 - val_loss: 0.4903 - val_acc: 0.8978\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5173 - acc: 0.8961 - val_loss: 0.5008 - val_acc: 0.8966\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5044 - acc: 0.8981 - val_loss: 0.4933 - val_acc: 0.8975\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4987 - acc: 0.8991 - val_loss: 0.5067 - val_acc: 0.8969\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4985 - acc: 0.8990 - val_loss: 0.4924 - val_acc: 0.8982\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4966 - acc: 0.8991 - val_loss: 0.5002 - val_acc: 0.8984\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4949 - acc: 0.8995 - val_loss: 0.4884 - val_acc: 0.8985\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4943 - acc: 0.8994 - val_loss: 0.4876 - val_acc: 0.8987\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4920 - acc: 0.9000 - val_loss: 0.4899 - val_acc: 0.8989\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4909 - acc: 0.9002 - val_loss: 0.4901 - val_acc: 0.8983\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4893 - acc: 0.9003 - val_loss: 0.4875 - val_acc: 0.8995\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4897 - acc: 0.9004 - val_loss: 0.4846 - val_acc: 0.8995\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4872 - acc: 0.9006 - val_loss: 0.4850 - val_acc: 0.8994\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4883 - acc: 0.9004 - val_loss: 0.4904 - val_acc: 0.8997\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4854 - acc: 0.9011 - val_loss: 0.4845 - val_acc: 0.8985\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4890 - acc: 0.9004 - val_loss: 0.4834 - val_acc: 0.8999\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4835 - acc: 0.9014 - val_loss: 0.4883 - val_acc: 0.8994\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4815 - acc: 0.9017 - val_loss: 0.4834 - val_acc: 0.9001\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4804 - acc: 0.9018 - val_loss: 0.4819 - val_acc: 0.8995\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4788 - acc: 0.9023 - val_loss: 0.4837 - val_acc: 0.9001\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4767 - acc: 0.9023 - val_loss: 0.4798 - val_acc: 0.9005\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4775 - acc: 0.9025 - val_loss: 0.4802 - val_acc: 0.9003\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4747 - acc: 0.9026 - val_loss: 0.4836 - val_acc: 0.9001\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4749 - acc: 0.9026 - val_loss: 0.4826 - val_acc: 0.9007\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4712 - acc: 0.9036 - val_loss: 0.4815 - val_acc: 0.9003\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4725 - acc: 0.9032 - val_loss: 0.4798 - val_acc: 0.9007\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4724 - acc: 0.9031 - val_loss: 0.4805 - val_acc: 0.9002\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4707 - acc: 0.9033 - val_loss: 0.4822 - val_acc: 0.9007\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4714 - acc: 0.9033 - val_loss: 0.4806 - val_acc: 0.9015\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4680 - acc: 0.9038 - val_loss: 0.4791 - val_acc: 0.9021\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4644 - acc: 0.9045 - val_loss: 0.4815 - val_acc: 0.9009\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4649 - acc: 0.9043 - val_loss: 0.4780 - val_acc: 0.9017\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4648 - acc: 0.9045 - val_loss: 0.4797 - val_acc: 0.9013\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4636 - acc: 0.9045 - val_loss: 0.4847 - val_acc: 0.9003\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4631 - acc: 0.9048 - val_loss: 0.4804 - val_acc: 0.9010\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4617 - acc: 0.9046 - val_loss: 0.4773 - val_acc: 0.9017\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4601 - acc: 0.9053 - val_loss: 0.4745 - val_acc: 0.9017\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4588 - acc: 0.9055 - val_loss: 0.4782 - val_acc: 0.9018\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4580 - acc: 0.9057 - val_loss: 0.4796 - val_acc: 0.9019\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4567 - acc: 0.9058 - val_loss: 0.4786 - val_acc: 0.9020\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4565 - acc: 0.9059 - val_loss: 0.4775 - val_acc: 0.9009\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4545 - acc: 0.9063 - val_loss: 0.4769 - val_acc: 0.9019\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4556 - acc: 0.9062 - val_loss: 0.4745 - val_acc: 0.9023\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4551 - acc: 0.9060 - val_loss: 0.4770 - val_acc: 0.9022\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4548 - acc: 0.9061 - val_loss: 0.4779 - val_acc: 0.9019\n",
      "Epoch 85/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4500 - acc: 0.9067 - val_loss: 0.4733 - val_acc: 0.9021\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4513 - acc: 0.9063 - val_loss: 0.4769 - val_acc: 0.9026\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4512 - acc: 0.9065 - val_loss: 0.4761 - val_acc: 0.9029\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4495 - acc: 0.9072 - val_loss: 0.4787 - val_acc: 0.9023\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4491 - acc: 0.9070 - val_loss: 0.4719 - val_acc: 0.9026\n",
      "Epoch 90/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4474 - acc: 0.9072 - val_loss: 0.4737 - val_acc: 0.9033\n",
      "Epoch 91/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4455 - acc: 0.9078 - val_loss: 0.4763 - val_acc: 0.9031\n",
      "Epoch 92/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4447 - acc: 0.9080 - val_loss: 0.4765 - val_acc: 0.9036\n",
      "Epoch 93/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4435 - acc: 0.9081 - val_loss: 0.4718 - val_acc: 0.9034\n",
      "Epoch 94/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4448 - acc: 0.9076 - val_loss: 0.4773 - val_acc: 0.9032\n",
      "Epoch 95/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4422 - acc: 0.9079 - val_loss: 0.4751 - val_acc: 0.9026\n",
      "Epoch 96/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4407 - acc: 0.9083 - val_loss: 0.4767 - val_acc: 0.9037\n",
      "Epoch 97/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4398 - acc: 0.9085 - val_loss: 0.4760 - val_acc: 0.9039\n",
      "Epoch 98/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4386 - acc: 0.9089 - val_loss: 0.4767 - val_acc: 0.9028\n",
      "Epoch 99/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4374 - acc: 0.9090 - val_loss: 0.4763 - val_acc: 0.9035\n",
      "Epoch 100/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4385 - acc: 0.9088 - val_loss: 0.4696 - val_acc: 0.9030\n",
      "Epoch 101/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4377 - acc: 0.9088 - val_loss: 0.4732 - val_acc: 0.9035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4394 - acc: 0.9087 - val_loss: 0.4794 - val_acc: 0.9032\n",
      "Epoch 103/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4344 - acc: 0.9095 - val_loss: 0.4724 - val_acc: 0.9045\n",
      "Epoch 104/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4342 - acc: 0.9099 - val_loss: 0.4812 - val_acc: 0.9035\n",
      "Epoch 105/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4345 - acc: 0.9093 - val_loss: 0.4737 - val_acc: 0.9041\n",
      "Epoch 106/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4319 - acc: 0.9098 - val_loss: 0.4710 - val_acc: 0.9036\n",
      "Epoch 107/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4311 - acc: 0.9100 - val_loss: 0.4710 - val_acc: 0.9033\n",
      "Epoch 108/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4325 - acc: 0.9093 - val_loss: 0.4698 - val_acc: 0.9038\n",
      "Epoch 109/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4306 - acc: 0.9101 - val_loss: 0.4768 - val_acc: 0.9032\n",
      "Epoch 110/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4317 - acc: 0.9099Restoring model weights from the end of the best epoch: 100.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4318 - acc: 0.9099 - val_loss: 0.4704 - val_acc: 0.9034\n",
      "Epoch 110: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 1.2237 - acc: 0.8404 - val_loss: 0.7502 - val_acc: 0.8675\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8511 - acc: 0.8607 - val_loss: 0.7241 - val_acc: 0.8701\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7981 - acc: 0.8636 - val_loss: 0.6893 - val_acc: 0.8712\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7623 - acc: 0.8654 - val_loss: 0.6639 - val_acc: 0.8742\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7367 - acc: 0.8668 - val_loss: 0.6537 - val_acc: 0.8761\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7125 - acc: 0.8689 - val_loss: 0.6245 - val_acc: 0.8788\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6901 - acc: 0.8709 - val_loss: 0.6047 - val_acc: 0.8818\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6721 - acc: 0.8737 - val_loss: 0.5846 - val_acc: 0.8846\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6522 - acc: 0.8761 - val_loss: 0.5737 - val_acc: 0.8862\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6366 - acc: 0.8783 - val_loss: 0.5625 - val_acc: 0.8882\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6314 - acc: 0.8793 - val_loss: 0.6788 - val_acc: 0.8681\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6417 - acc: 0.8761 - val_loss: 0.5479 - val_acc: 0.8903\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6078 - acc: 0.8817 - val_loss: 0.5459 - val_acc: 0.8897\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5990 - acc: 0.8827 - val_loss: 0.5391 - val_acc: 0.8904\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5907 - acc: 0.8840 - val_loss: 0.5311 - val_acc: 0.8918\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5844 - acc: 0.8847 - val_loss: 0.5213 - val_acc: 0.8936\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5785 - acc: 0.8854 - val_loss: 0.5193 - val_acc: 0.8940\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5738 - acc: 0.8863 - val_loss: 0.5122 - val_acc: 0.8959\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5669 - acc: 0.8870 - val_loss: 0.5112 - val_acc: 0.8947\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5624 - acc: 0.8877 - val_loss: 0.5030 - val_acc: 0.8972\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5579 - acc: 0.8886 - val_loss: 0.4996 - val_acc: 0.8980\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5524 - acc: 0.8894 - val_loss: 0.4990 - val_acc: 0.8975\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5489 - acc: 0.8902 - val_loss: 0.4925 - val_acc: 0.8996\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5463 - acc: 0.8910 - val_loss: 0.4893 - val_acc: 0.8999\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5420 - acc: 0.8914 - val_loss: 0.4884 - val_acc: 0.8997\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5381 - acc: 0.8920 - val_loss: 0.4857 - val_acc: 0.9010\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5351 - acc: 0.8926 - val_loss: 0.4856 - val_acc: 0.9014\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5321 - acc: 0.8929 - val_loss: 0.4829 - val_acc: 0.9010\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5286 - acc: 0.8936 - val_loss: 0.4793 - val_acc: 0.9012\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5259 - acc: 0.8942 - val_loss: 0.4809 - val_acc: 0.9021\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5237 - acc: 0.8946 - val_loss: 0.4754 - val_acc: 0.9032\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5203 - acc: 0.8953 - val_loss: 0.4795 - val_acc: 0.9027\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5185 - acc: 0.8956 - val_loss: 0.4732 - val_acc: 0.9034\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5165 - acc: 0.8958 - val_loss: 0.4768 - val_acc: 0.9022\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5137 - acc: 0.8962 - val_loss: 0.4740 - val_acc: 0.9031\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5111 - acc: 0.8965 - val_loss: 0.4709 - val_acc: 0.9039\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5114 - acc: 0.8967 - val_loss: 0.4694 - val_acc: 0.9040\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5083 - acc: 0.8970 - val_loss: 0.4709 - val_acc: 0.9032\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5073 - acc: 0.8976 - val_loss: 0.4667 - val_acc: 0.9042\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5048 - acc: 0.8974 - val_loss: 0.4658 - val_acc: 0.9044\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5022 - acc: 0.8982 - val_loss: 0.4669 - val_acc: 0.9050\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4995 - acc: 0.8986 - val_loss: 0.4663 - val_acc: 0.9042\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4981 - acc: 0.8985 - val_loss: 0.4620 - val_acc: 0.9043\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4956 - acc: 0.8989 - val_loss: 0.4617 - val_acc: 0.9049\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4978 - acc: 0.8990 - val_loss: 0.4616 - val_acc: 0.9050\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4942 - acc: 0.8995 - val_loss: 0.4682 - val_acc: 0.9032\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4933 - acc: 0.8995 - val_loss: 0.4596 - val_acc: 0.9057\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4917 - acc: 0.8997 - val_loss: 0.4570 - val_acc: 0.9051\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4891 - acc: 0.9003 - val_loss: 0.4590 - val_acc: 0.9054\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4856 - acc: 0.9005 - val_loss: 0.4578 - val_acc: 0.9059\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4855 - acc: 0.9010 - val_loss: 0.4650 - val_acc: 0.9042\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4875 - acc: 0.9006 - val_loss: 0.4612 - val_acc: 0.9054\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4829 - acc: 0.9015 - val_loss: 0.4575 - val_acc: 0.9055\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4846 - acc: 0.9007 - val_loss: 0.4578 - val_acc: 0.9064\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4801 - acc: 0.9014 - val_loss: 0.4606 - val_acc: 0.9071\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4787 - acc: 0.9015 - val_loss: 0.4572 - val_acc: 0.9065\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4790 - acc: 0.9018 - val_loss: 0.4542 - val_acc: 0.9060\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4762 - acc: 0.9023 - val_loss: 0.4557 - val_acc: 0.9064\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4773 - acc: 0.9023 - val_loss: 0.4520 - val_acc: 0.9067\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4748 - acc: 0.9030 - val_loss: 0.4536 - val_acc: 0.9069\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4723 - acc: 0.9030 - val_loss: 0.4549 - val_acc: 0.9070\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4720 - acc: 0.9031 - val_loss: 0.4528 - val_acc: 0.9074\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4717 - acc: 0.9032 - val_loss: 0.4514 - val_acc: 0.9072\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4679 - acc: 0.9038 - val_loss: 0.4518 - val_acc: 0.9074\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4676 - acc: 0.9034 - val_loss: 0.4484 - val_acc: 0.9083\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4644 - acc: 0.9041 - val_loss: 0.4534 - val_acc: 0.9077\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4643 - acc: 0.9043 - val_loss: 0.4509 - val_acc: 0.9071\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4639 - acc: 0.9044 - val_loss: 0.4482 - val_acc: 0.9082\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4623 - acc: 0.9047 - val_loss: 0.4508 - val_acc: 0.9069\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4623 - acc: 0.9044 - val_loss: 0.4518 - val_acc: 0.9082\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4605 - acc: 0.9049 - val_loss: 0.4499 - val_acc: 0.9079\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4595 - acc: 0.9050 - val_loss: 0.4530 - val_acc: 0.9073\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4581 - acc: 0.9049 - val_loss: 0.4494 - val_acc: 0.9077\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4609 - acc: 0.9047 - val_loss: 0.4515 - val_acc: 0.9079\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4570 - acc: 0.9055 - val_loss: 0.4500 - val_acc: 0.9079\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4564 - acc: 0.9057 - val_loss: 0.4497 - val_acc: 0.9075\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4530 - acc: 0.9061 - val_loss: 0.4495 - val_acc: 0.9086\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4527 - acc: 0.9062 - val_loss: 0.4472 - val_acc: 0.9086\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4499 - acc: 0.9070 - val_loss: 0.4505 - val_acc: 0.9073\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4493 - acc: 0.9071 - val_loss: 0.4441 - val_acc: 0.9094\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4474 - acc: 0.9073 - val_loss: 0.4483 - val_acc: 0.9091\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4473 - acc: 0.9070 - val_loss: 0.4459 - val_acc: 0.9097\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4489 - acc: 0.9067 - val_loss: 0.4473 - val_acc: 0.9086\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4458 - acc: 0.9071 - val_loss: 0.4466 - val_acc: 0.9090\n",
      "Epoch 85/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4445 - acc: 0.9076 - val_loss: 0.4479 - val_acc: 0.9091\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4437 - acc: 0.9078 - val_loss: 0.4508 - val_acc: 0.9096\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4422 - acc: 0.9080 - val_loss: 0.4471 - val_acc: 0.9101\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4410 - acc: 0.9079 - val_loss: 0.4457 - val_acc: 0.9090\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4411 - acc: 0.9078 - val_loss: 0.4494 - val_acc: 0.9094\n",
      "Epoch 90/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.9083Restoring model weights from the end of the best epoch: 80.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4392 - acc: 0.9083 - val_loss: 0.4475 - val_acc: 0.9093\n",
      "Epoch 90: early stopping\n",
      "Current Latent Dim: 256\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.2066 - acc: 0.8418 - val_loss: 0.7711 - val_acc: 0.8641\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.8391 - acc: 0.8627 - val_loss: 0.7427 - val_acc: 0.8666\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7872 - acc: 0.8650 - val_loss: 0.7208 - val_acc: 0.8685\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7540 - acc: 0.8664 - val_loss: 0.6912 - val_acc: 0.8692\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7264 - acc: 0.8683 - val_loss: 0.6740 - val_acc: 0.8726\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6987 - acc: 0.8707 - val_loss: 0.6404 - val_acc: 0.8753\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6723 - acc: 0.8741 - val_loss: 0.6103 - val_acc: 0.8803\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6756 - acc: 0.8731 - val_loss: 0.6037 - val_acc: 0.8798\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6375 - acc: 0.8778 - val_loss: 0.5943 - val_acc: 0.8805\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6216 - acc: 0.8800 - val_loss: 0.5682 - val_acc: 0.8859\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6083 - acc: 0.8820 - val_loss: 0.5615 - val_acc: 0.8869\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5947 - acc: 0.8841 - val_loss: 0.5515 - val_acc: 0.8889\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5862 - acc: 0.8853 - val_loss: 0.5433 - val_acc: 0.8908\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5772 - acc: 0.8868 - val_loss: 0.5313 - val_acc: 0.8938\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5678 - acc: 0.8887 - val_loss: 0.5277 - val_acc: 0.8926\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5606 - acc: 0.8895 - val_loss: 0.5227 - val_acc: 0.8947\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5536 - acc: 0.8906 - val_loss: 0.5174 - val_acc: 0.8952\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5475 - acc: 0.8917 - val_loss: 0.5160 - val_acc: 0.8949\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5442 - acc: 0.8922 - val_loss: 0.5097 - val_acc: 0.8976\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5380 - acc: 0.8929 - val_loss: 0.5073 - val_acc: 0.8968\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5334 - acc: 0.8937 - val_loss: 0.5035 - val_acc: 0.8980\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5308 - acc: 0.8943 - val_loss: 0.5081 - val_acc: 0.8970\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5304 - acc: 0.8940 - val_loss: 0.5002 - val_acc: 0.8980\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5222 - acc: 0.8953 - val_loss: 0.5099 - val_acc: 0.8967\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5190 - acc: 0.8963 - val_loss: 0.4964 - val_acc: 0.8987\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5170 - acc: 0.8966 - val_loss: 0.4968 - val_acc: 0.8991\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5128 - acc: 0.8967 - val_loss: 0.4911 - val_acc: 0.8998\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5099 - acc: 0.8975 - val_loss: 0.4925 - val_acc: 0.8999\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5060 - acc: 0.8982 - val_loss: 0.4896 - val_acc: 0.8995\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5051 - acc: 0.8986 - val_loss: 0.4860 - val_acc: 0.9005\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5055 - acc: 0.8980 - val_loss: 0.4881 - val_acc: 0.9004\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5007 - acc: 0.8989 - val_loss: 0.4849 - val_acc: 0.9011\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4966 - acc: 0.8995 - val_loss: 0.4853 - val_acc: 0.9016\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4958 - acc: 0.8996 - val_loss: 0.4810 - val_acc: 0.9019\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4935 - acc: 0.8994 - val_loss: 0.4788 - val_acc: 0.9022\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4909 - acc: 0.9006 - val_loss: 0.4816 - val_acc: 0.9018\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4897 - acc: 0.9007 - val_loss: 0.4822 - val_acc: 0.9020\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4886 - acc: 0.9005 - val_loss: 0.4798 - val_acc: 0.9014\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4839 - acc: 0.9013 - val_loss: 0.4778 - val_acc: 0.9025\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4826 - acc: 0.9018 - val_loss: 0.4779 - val_acc: 0.9027\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4825 - acc: 0.9017 - val_loss: 0.4788 - val_acc: 0.9031\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4791 - acc: 0.9024 - val_loss: 0.4785 - val_acc: 0.9026\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4772 - acc: 0.9023 - val_loss: 0.4792 - val_acc: 0.9026\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4756 - acc: 0.9022 - val_loss: 0.4747 - val_acc: 0.9043\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4724 - acc: 0.9036 - val_loss: 0.4751 - val_acc: 0.9030\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4743 - acc: 0.9031 - val_loss: 0.4775 - val_acc: 0.9020\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4705 - acc: 0.9031 - val_loss: 0.4736 - val_acc: 0.9036\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4697 - acc: 0.9036 - val_loss: 0.4709 - val_acc: 0.9041\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4674 - acc: 0.9042 - val_loss: 0.4719 - val_acc: 0.9036\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4654 - acc: 0.9047 - val_loss: 0.4736 - val_acc: 0.9038\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4644 - acc: 0.9045 - val_loss: 0.4793 - val_acc: 0.9040\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4624 - acc: 0.9048 - val_loss: 0.4732 - val_acc: 0.9040\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4593 - acc: 0.9053 - val_loss: 0.4701 - val_acc: 0.9044\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4579 - acc: 0.9059 - val_loss: 0.4702 - val_acc: 0.9047\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4578 - acc: 0.9056 - val_loss: 0.4727 - val_acc: 0.9050\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4559 - acc: 0.9059 - val_loss: 0.4704 - val_acc: 0.9042\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4545 - acc: 0.9066 - val_loss: 0.4711 - val_acc: 0.9043\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4524 - acc: 0.9067 - val_loss: 0.4703 - val_acc: 0.9052\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4494 - acc: 0.9070 - val_loss: 0.4678 - val_acc: 0.9053\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4494 - acc: 0.9072 - val_loss: 0.4739 - val_acc: 0.9046\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4488 - acc: 0.9071 - val_loss: 0.4691 - val_acc: 0.9048\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4463 - acc: 0.9076 - val_loss: 0.4691 - val_acc: 0.9054\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4439 - acc: 0.9081 - val_loss: 0.4701 - val_acc: 0.9050\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4440 - acc: 0.9080 - val_loss: 0.4707 - val_acc: 0.9053\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4422 - acc: 0.9084 - val_loss: 0.4701 - val_acc: 0.9052\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4411 - acc: 0.9086 - val_loss: 0.4714 - val_acc: 0.9063\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4377 - acc: 0.9089 - val_loss: 0.4744 - val_acc: 0.9051\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4368 - acc: 0.9090 - val_loss: 0.4704 - val_acc: 0.9059\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.4368 - acc: 0.9093Restoring model weights from the end of the best epoch: 59.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4368 - acc: 0.9093 - val_loss: 0.4683 - val_acc: 0.9058\n",
      "Epoch 69: early stopping\n",
      "[0.46203532814979553, 0.4680040776729584, 0.4695829749107361, 0.44412967562675476, 0.4678005576133728]\n",
      "[81, 59, 100, 80, 59]\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9072 - acc: 0.8510 - val_loss: 0.7374 - val_acc: 0.8661\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7270 - acc: 0.8674 - val_loss: 0.6581 - val_acc: 0.8737\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6560 - acc: 0.8752 - val_loss: 0.5944 - val_acc: 0.8832\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5925 - acc: 0.8837 - val_loss: 0.5382 - val_acc: 0.8918\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5703 - acc: 0.8867 - val_loss: 0.5083 - val_acc: 0.8960\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5203 - acc: 0.8942 - val_loss: 0.4999 - val_acc: 0.8957\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4976 - acc: 0.8975 - val_loss: 0.4816 - val_acc: 0.8993\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4802 - acc: 0.8998 - val_loss: 0.4678 - val_acc: 0.9026\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4645 - acc: 0.9019 - val_loss: 0.4601 - val_acc: 0.9039\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4506 - acc: 0.9041 - val_loss: 0.4508 - val_acc: 0.9054\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4385 - acc: 0.9059 - val_loss: 0.4443 - val_acc: 0.9068\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4245 - acc: 0.9080 - val_loss: 0.4365 - val_acc: 0.9081\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4134 - acc: 0.9094 - val_loss: 0.4320 - val_acc: 0.9093\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4040 - acc: 0.9111 - val_loss: 0.4247 - val_acc: 0.9102\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3925 - acc: 0.9130 - val_loss: 0.4199 - val_acc: 0.9108\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3839 - acc: 0.9139 - val_loss: 0.4155 - val_acc: 0.9117\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3723 - acc: 0.9159 - val_loss: 0.4230 - val_acc: 0.9106\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3641 - acc: 0.9173 - val_loss: 0.4186 - val_acc: 0.9115\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3567 - acc: 0.9185 - val_loss: 0.4186 - val_acc: 0.9126\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3484 - acc: 0.9200 - val_loss: 0.4089 - val_acc: 0.9139\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3397 - acc: 0.9210 - val_loss: 0.4171 - val_acc: 0.9117\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3332 - acc: 0.9216 - val_loss: 0.4224 - val_acc: 0.9128\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3241 - acc: 0.9235 - val_loss: 0.4150 - val_acc: 0.9124\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3342 - acc: 0.9219 - val_loss: 0.4138 - val_acc: 0.9140\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3104 - acc: 0.9259 - val_loss: 0.4142 - val_acc: 0.9146\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3051 - acc: 0.9262 - val_loss: 0.4150 - val_acc: 0.9148\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2975 - acc: 0.9283 - val_loss: 0.4198 - val_acc: 0.9147\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2923 - acc: 0.9290 - val_loss: 0.4232 - val_acc: 0.9134\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2838 - acc: 0.9304 - val_loss: 0.4289 - val_acc: 0.9126\n",
      "Epoch 30/200\n",
      "188/191 [============================>.] - ETA: 0s - loss: 0.2776 - acc: 0.9313Restoring model weights from the end of the best epoch: 20.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2776 - acc: 0.9313 - val_loss: 0.4282 - val_acc: 0.9141\n",
      "Epoch 30: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 36ms/step - loss: 0.9121 - acc: 0.8523 - val_loss: 0.7354 - val_acc: 0.8663\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7257 - acc: 0.8674 - val_loss: 0.6756 - val_acc: 0.8703\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6729 - acc: 0.8725 - val_loss: 0.6303 - val_acc: 0.8753\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6241 - acc: 0.8791 - val_loss: 0.5765 - val_acc: 0.8844\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5831 - acc: 0.8849 - val_loss: 0.5424 - val_acc: 0.8902\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5428 - acc: 0.8910 - val_loss: 0.5228 - val_acc: 0.8934\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5192 - acc: 0.8942 - val_loss: 0.5036 - val_acc: 0.8962\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4985 - acc: 0.8972 - val_loss: 0.4883 - val_acc: 0.8982\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4832 - acc: 0.8993 - val_loss: 0.4746 - val_acc: 0.9004\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4675 - acc: 0.9017 - val_loss: 0.4670 - val_acc: 0.9016\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4545 - acc: 0.9038 - val_loss: 0.4585 - val_acc: 0.9037\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4426 - acc: 0.9051 - val_loss: 0.4521 - val_acc: 0.9043\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4315 - acc: 0.9068 - val_loss: 0.4505 - val_acc: 0.9049\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4225 - acc: 0.9081 - val_loss: 0.4420 - val_acc: 0.9056\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4145 - acc: 0.9092 - val_loss: 0.4386 - val_acc: 0.9065\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4027 - acc: 0.9110 - val_loss: 0.4352 - val_acc: 0.9068\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3937 - acc: 0.9121 - val_loss: 0.4358 - val_acc: 0.9058\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3843 - acc: 0.9134 - val_loss: 0.4301 - val_acc: 0.9085\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3766 - acc: 0.9149 - val_loss: 0.4341 - val_acc: 0.9082\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3698 - acc: 0.9158 - val_loss: 0.4260 - val_acc: 0.9103\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3592 - acc: 0.9175 - val_loss: 0.4299 - val_acc: 0.9091\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3526 - acc: 0.9187 - val_loss: 0.4246 - val_acc: 0.9104\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3450 - acc: 0.9197 - val_loss: 0.4218 - val_acc: 0.9099\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3390 - acc: 0.9207 - val_loss: 0.4225 - val_acc: 0.9106\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3314 - acc: 0.9221 - val_loss: 0.4198 - val_acc: 0.9110\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3243 - acc: 0.9231 - val_loss: 0.4195 - val_acc: 0.9125\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3195 - acc: 0.9241 - val_loss: 0.4253 - val_acc: 0.9114\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3101 - acc: 0.9255 - val_loss: 0.4238 - val_acc: 0.9123\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3043 - acc: 0.9265 - val_loss: 0.4294 - val_acc: 0.9117\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2972 - acc: 0.9275 - val_loss: 0.4318 - val_acc: 0.9120\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2931 - acc: 0.9285 - val_loss: 0.4325 - val_acc: 0.9120\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2861 - acc: 0.9297 - val_loss: 0.4343 - val_acc: 0.9110\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2804 - acc: 0.9307 - val_loss: 0.4407 - val_acc: 0.9121\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2728 - acc: 0.9319 - val_loss: 0.4436 - val_acc: 0.9123\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2664 - acc: 0.9337 - val_loss: 0.4422 - val_acc: 0.9111\n",
      "Epoch 36/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2622 - acc: 0.9341Restoring model weights from the end of the best epoch: 26.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2622 - acc: 0.9341 - val_loss: 0.4499 - val_acc: 0.9128\n",
      "Epoch 36: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9105 - acc: 0.8525 - val_loss: 0.7387 - val_acc: 0.8643\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7232 - acc: 0.8683 - val_loss: 0.6578 - val_acc: 0.8724\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6526 - acc: 0.8758 - val_loss: 0.5955 - val_acc: 0.8822\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.5872 - acc: 0.8853 - val_loss: 0.5428 - val_acc: 0.8901\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5429 - acc: 0.8923 - val_loss: 0.5183 - val_acc: 0.8947\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5138 - acc: 0.8959 - val_loss: 0.5076 - val_acc: 0.8951\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4900 - acc: 0.8994 - val_loss: 0.4897 - val_acc: 0.8982\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4710 - acc: 0.9018 - val_loss: 0.4718 - val_acc: 0.9001\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4567 - acc: 0.9038 - val_loss: 0.4606 - val_acc: 0.9023\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4404 - acc: 0.9059 - val_loss: 0.4505 - val_acc: 0.9031\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4285 - acc: 0.9078 - val_loss: 0.4471 - val_acc: 0.9048\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.9428 - acc: 0.8555 - val_loss: 0.6837 - val_acc: 0.8678\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5701 - acc: 0.8870 - val_loss: 0.4813 - val_acc: 0.8990\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4466 - acc: 0.9043 - val_loss: 0.4555 - val_acc: 0.9041\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4206 - acc: 0.9079 - val_loss: 0.4431 - val_acc: 0.9053\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4048 - acc: 0.9111 - val_loss: 0.4353 - val_acc: 0.9068\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3940 - acc: 0.9123 - val_loss: 0.4338 - val_acc: 0.9068\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3855 - acc: 0.9136 - val_loss: 0.4290 - val_acc: 0.9073\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3763 - acc: 0.9151 - val_loss: 0.4325 - val_acc: 0.9073\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3710 - acc: 0.9161 - val_loss: 0.4281 - val_acc: 0.9075\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3666 - acc: 0.9170 - val_loss: 0.4235 - val_acc: 0.9105\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3574 - acc: 0.9180 - val_loss: 0.4211 - val_acc: 0.9104\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3511 - acc: 0.9190 - val_loss: 0.4315 - val_acc: 0.9086\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3461 - acc: 0.9199 - val_loss: 0.4220 - val_acc: 0.9097\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3395 - acc: 0.9206 - val_loss: 0.4201 - val_acc: 0.9114\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3336 - acc: 0.9218 - val_loss: 0.4276 - val_acc: 0.9111\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3281 - acc: 0.9229 - val_loss: 0.4256 - val_acc: 0.9117\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3203 - acc: 0.9241 - val_loss: 0.4266 - val_acc: 0.9116\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3133 - acc: 0.9254 - val_loss: 0.4269 - val_acc: 0.9106\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3091 - acc: 0.9259 - val_loss: 0.4289 - val_acc: 0.9101\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3036 - acc: 0.9269 - val_loss: 0.4317 - val_acc: 0.9118\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2958 - acc: 0.9285 - val_loss: 0.4333 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2927 - acc: 0.9286 - val_loss: 0.4324 - val_acc: 0.9128\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2845 - acc: 0.9303 - val_loss: 0.4343 - val_acc: 0.9113\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2775 - acc: 0.9313Restoring model weights from the end of the best epoch: 25.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2775 - acc: 0.9313 - val_loss: 0.4382 - val_acc: 0.9121\n",
      "Epoch 35: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 0.9417 - acc: 0.8494 - val_loss: 0.7200 - val_acc: 0.8695\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7503 - acc: 0.8655 - val_loss: 0.6500 - val_acc: 0.8756\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6872 - acc: 0.8704 - val_loss: 0.6088 - val_acc: 0.8809\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6285 - acc: 0.8785 - val_loss: 0.5507 - val_acc: 0.8908\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5741 - acc: 0.8866 - val_loss: 0.5089 - val_acc: 0.8975\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5417 - acc: 0.8915 - val_loss: 0.4896 - val_acc: 0.8998\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5159 - acc: 0.8949 - val_loss: 0.4688 - val_acc: 0.9028\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4952 - acc: 0.8983 - val_loss: 0.4515 - val_acc: 0.9066\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4785 - acc: 0.9005 - val_loss: 0.4429 - val_acc: 0.9071\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4646 - acc: 0.9024 - val_loss: 0.4453 - val_acc: 0.9064\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4522 - acc: 0.9033 - val_loss: 0.4424 - val_acc: 0.9054\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4413 - acc: 0.9054 - val_loss: 0.4239 - val_acc: 0.9100\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4299 - acc: 0.9067 - val_loss: 0.4234 - val_acc: 0.9100\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4192 - acc: 0.9086 - val_loss: 0.4252 - val_acc: 0.9095\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4093 - acc: 0.9098 - val_loss: 0.4156 - val_acc: 0.9120\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3997 - acc: 0.9114 - val_loss: 0.4150 - val_acc: 0.9116\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3903 - acc: 0.9131 - val_loss: 0.4070 - val_acc: 0.9130\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3805 - acc: 0.9147 - val_loss: 0.4042 - val_acc: 0.9147\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3739 - acc: 0.9156 - val_loss: 0.4045 - val_acc: 0.9144\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3670 - acc: 0.9166 - val_loss: 0.4005 - val_acc: 0.9147\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3597 - acc: 0.9179 - val_loss: 0.4104 - val_acc: 0.9146\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3509 - acc: 0.9192 - val_loss: 0.3943 - val_acc: 0.9163\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3427 - acc: 0.9201 - val_loss: 0.3984 - val_acc: 0.9166\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3350 - acc: 0.9214 - val_loss: 0.3983 - val_acc: 0.9161\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3293 - acc: 0.9225 - val_loss: 0.4043 - val_acc: 0.9157\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3241 - acc: 0.9233 - val_loss: 0.4010 - val_acc: 0.9161\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3161 - acc: 0.9244 - val_loss: 0.4063 - val_acc: 0.9169\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3111 - acc: 0.9253 - val_loss: 0.4060 - val_acc: 0.9164\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3029 - acc: 0.9270 - val_loss: 0.4055 - val_acc: 0.9171\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2969 - acc: 0.9285 - val_loss: 0.4092 - val_acc: 0.9165\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2916 - acc: 0.9290 - val_loss: 0.4110 - val_acc: 0.9155\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2844 - acc: 0.9299Restoring model weights from the end of the best epoch: 22.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2844 - acc: 0.9299 - val_loss: 0.4136 - val_acc: 0.9152\n",
      "Epoch 32: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 0.9384 - acc: 0.8511 - val_loss: 0.7418 - val_acc: 0.8670\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7425 - acc: 0.8666 - val_loss: 0.6779 - val_acc: 0.8721\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6841 - acc: 0.8715 - val_loss: 0.6334 - val_acc: 0.8778\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6219 - acc: 0.8803 - val_loss: 0.5651 - val_acc: 0.8869\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5691 - acc: 0.8876 - val_loss: 0.5330 - val_acc: 0.8936\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5369 - acc: 0.8922 - val_loss: 0.5228 - val_acc: 0.8947\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5118 - acc: 0.8958 - val_loss: 0.4982 - val_acc: 0.8984\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4945 - acc: 0.8983 - val_loss: 0.4892 - val_acc: 0.8994\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4753 - acc: 0.9013 - val_loss: 0.4683 - val_acc: 0.9037\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4590 - acc: 0.9038 - val_loss: 0.4669 - val_acc: 0.9037\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4472 - acc: 0.9050 - val_loss: 0.4582 - val_acc: 0.9037\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4349 - acc: 0.9067 - val_loss: 0.4449 - val_acc: 0.9066\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4236 - acc: 0.9086 - val_loss: 0.4425 - val_acc: 0.9071\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4113 - acc: 0.9100 - val_loss: 0.4386 - val_acc: 0.9081\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4010 - acc: 0.9118 - val_loss: 0.4348 - val_acc: 0.9093\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3915 - acc: 0.9130 - val_loss: 0.4397 - val_acc: 0.9089\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3826 - acc: 0.9149 - val_loss: 0.4323 - val_acc: 0.9093\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3726 - acc: 0.9158 - val_loss: 0.4215 - val_acc: 0.9116\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3657 - acc: 0.9172 - val_loss: 0.4213 - val_acc: 0.9113\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3571 - acc: 0.9184 - val_loss: 0.4196 - val_acc: 0.9119\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3493 - acc: 0.9195 - val_loss: 0.4237 - val_acc: 0.9112\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3430 - acc: 0.9208 - val_loss: 0.4203 - val_acc: 0.9123\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3335 - acc: 0.9222 - val_loss: 0.4195 - val_acc: 0.9125\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3280 - acc: 0.9229 - val_loss: 0.4224 - val_acc: 0.9134\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3208 - acc: 0.9243 - val_loss: 0.4280 - val_acc: 0.9119\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3128 - acc: 0.9255 - val_loss: 0.4259 - val_acc: 0.9124\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3078 - acc: 0.9264 - val_loss: 0.4228 - val_acc: 0.9129\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3004 - acc: 0.9273 - val_loss: 0.4286 - val_acc: 0.9128\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2924 - acc: 0.9288 - val_loss: 0.4330 - val_acc: 0.9129\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2876 - acc: 0.9298 - val_loss: 0.4262 - val_acc: 0.9123\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2800 - acc: 0.9312 - val_loss: 0.4319 - val_acc: 0.9132\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2754 - acc: 0.9318 - val_loss: 0.4364 - val_acc: 0.9124\n",
      "Epoch 33/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2697 - acc: 0.9329Restoring model weights from the end of the best epoch: 23.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2698 - acc: 0.9328 - val_loss: 0.4370 - val_acc: 0.9138\n",
      "Epoch 33: early stopping\n",
      "[0.4088610112667084, 0.41948381066322327, 0.4200792610645294, 0.39430150389671326, 0.4195277988910675]\n",
      "[20, 26, 25, 22, 23]\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 37ms/step - loss: 0.9389 - acc: 0.8505 - val_loss: 0.7337 - val_acc: 0.8671\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7469 - acc: 0.8660 - val_loss: 0.6744 - val_acc: 0.8708\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6891 - acc: 0.8710 - val_loss: 0.6325 - val_acc: 0.8760\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6359 - acc: 0.8781 - val_loss: 0.5834 - val_acc: 0.8840\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5847 - acc: 0.8856 - val_loss: 0.5429 - val_acc: 0.8912\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5502 - acc: 0.8901 - val_loss: 0.5151 - val_acc: 0.8947\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5267 - acc: 0.8935 - val_loss: 0.4979 - val_acc: 0.8975\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5073 - acc: 0.8962 - val_loss: 0.4852 - val_acc: 0.8997\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6050 - acc: 0.8786 - val_loss: 0.4915 - val_acc: 0.8976\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4920 - acc: 0.8981 - val_loss: 0.4691 - val_acc: 0.9022\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4762 - acc: 0.9002 - val_loss: 0.4627 - val_acc: 0.9031\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4639 - acc: 0.9019 - val_loss: 0.4606 - val_acc: 0.9035\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4543 - acc: 0.9032 - val_loss: 0.4562 - val_acc: 0.9039\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4449 - acc: 0.9047 - val_loss: 0.4487 - val_acc: 0.9052\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4375 - acc: 0.9056 - val_loss: 0.4452 - val_acc: 0.9055\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4310 - acc: 0.9068 - val_loss: 0.4407 - val_acc: 0.9067\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4221 - acc: 0.9081 - val_loss: 0.4342 - val_acc: 0.9079\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4154 - acc: 0.9092 - val_loss: 0.4305 - val_acc: 0.9090\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4098 - acc: 0.9100 - val_loss: 0.4335 - val_acc: 0.9093\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4022 - acc: 0.9113 - val_loss: 0.4317 - val_acc: 0.9086\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3967 - acc: 0.9120 - val_loss: 0.4267 - val_acc: 0.9095\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3912 - acc: 0.9128 - val_loss: 0.4274 - val_acc: 0.9090\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3819 - acc: 0.9141 - val_loss: 0.4232 - val_acc: 0.9105\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3783 - acc: 0.9150 - val_loss: 0.4237 - val_acc: 0.9109\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3726 - acc: 0.9160 - val_loss: 0.4226 - val_acc: 0.9112\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3669 - acc: 0.9167 - val_loss: 0.4188 - val_acc: 0.9119\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3607 - acc: 0.9181 - val_loss: 0.4265 - val_acc: 0.9112\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3556 - acc: 0.9185 - val_loss: 0.4247 - val_acc: 0.9108\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3469 - acc: 0.9202 - val_loss: 0.4257 - val_acc: 0.9111\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3467 - acc: 0.9205 - val_loss: 0.4250 - val_acc: 0.9119\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3387 - acc: 0.9214 - val_loss: 0.4255 - val_acc: 0.9122\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3361 - acc: 0.9221 - val_loss: 0.4232 - val_acc: 0.9125\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3294 - acc: 0.9229 - val_loss: 0.4260 - val_acc: 0.9121\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3252 - acc: 0.9239 - val_loss: 0.4273 - val_acc: 0.9122\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3213 - acc: 0.9242 - val_loss: 0.4242 - val_acc: 0.9130\n",
      "Epoch 36/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.9255Restoring model weights from the end of the best epoch: 26.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3158 - acc: 0.9255 - val_loss: 0.4284 - val_acc: 0.9122\n",
      "Epoch 36: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 0.9372 - acc: 0.8514 - val_loss: 0.7554 - val_acc: 0.8635\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7391 - acc: 0.8667 - val_loss: 0.6692 - val_acc: 0.8711\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6708 - acc: 0.8737 - val_loss: 0.6112 - val_acc: 0.8800\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6114 - acc: 0.8818 - val_loss: 0.5654 - val_acc: 0.8861\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5694 - acc: 0.8879 - val_loss: 0.5281 - val_acc: 0.8928\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5404 - acc: 0.8925 - val_loss: 0.5137 - val_acc: 0.8942\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5271 - acc: 0.8935 - val_loss: 0.5013 - val_acc: 0.8967\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5030 - acc: 0.8972 - val_loss: 0.4845 - val_acc: 0.8986\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4872 - acc: 0.8998 - val_loss: 0.4769 - val_acc: 0.8995\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4745 - acc: 0.9008 - val_loss: 0.4691 - val_acc: 0.9013\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4630 - acc: 0.9030 - val_loss: 0.4602 - val_acc: 0.9025\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4539 - acc: 0.9039 - val_loss: 0.4506 - val_acc: 0.9044\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4423 - acc: 0.9054 - val_loss: 0.4492 - val_acc: 0.9045\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4322 - acc: 0.9073 - val_loss: 0.4463 - val_acc: 0.9059\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4222 - acc: 0.9084 - val_loss: 0.4366 - val_acc: 0.9075\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4143 - acc: 0.9098 - val_loss: 0.4371 - val_acc: 0.9071\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4063 - acc: 0.9109 - val_loss: 0.4360 - val_acc: 0.9077\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3985 - acc: 0.9123 - val_loss: 0.4234 - val_acc: 0.9097\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3909 - acc: 0.9136 - val_loss: 0.4320 - val_acc: 0.9099\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3821 - acc: 0.9152 - val_loss: 0.4255 - val_acc: 0.9106\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3763 - acc: 0.9158 - val_loss: 0.4235 - val_acc: 0.9108\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3699 - acc: 0.9173 - val_loss: 0.4185 - val_acc: 0.9107\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3625 - acc: 0.9182 - val_loss: 0.4196 - val_acc: 0.9122\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3535 - acc: 0.9194 - val_loss: 0.4209 - val_acc: 0.9115\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3482 - acc: 0.9202 - val_loss: 0.4157 - val_acc: 0.9131\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3421 - acc: 0.9218 - val_loss: 0.4191 - val_acc: 0.9121\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3363 - acc: 0.9224 - val_loss: 0.4222 - val_acc: 0.9121\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3308 - acc: 0.9233 - val_loss: 0.4212 - val_acc: 0.9132\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3249 - acc: 0.9244 - val_loss: 0.4187 - val_acc: 0.9128\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3154 - acc: 0.9263 - val_loss: 0.4227 - val_acc: 0.9125\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3111 - acc: 0.9265 - val_loss: 0.4246 - val_acc: 0.9136\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3073 - acc: 0.9271 - val_loss: 0.4278 - val_acc: 0.9134\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3009 - acc: 0.9282 - val_loss: 0.4266 - val_acc: 0.9137\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2966 - acc: 0.9292 - val_loss: 0.4286 - val_acc: 0.9140\n",
      "Epoch 35/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.9301Restoring model weights from the end of the best epoch: 25.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2920 - acc: 0.9301 - val_loss: 0.4339 - val_acc: 0.9135\n",
      "Epoch 35: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9273 - acc: 0.8514 - val_loss: 0.7421 - val_acc: 0.8646\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7347 - acc: 0.8671 - val_loss: 0.6679 - val_acc: 0.8726\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6694 - acc: 0.8736 - val_loss: 0.6255 - val_acc: 0.8771\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6118 - acc: 0.8813 - val_loss: 0.5704 - val_acc: 0.8841\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5693 - acc: 0.8876 - val_loss: 0.5368 - val_acc: 0.8902\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5401 - acc: 0.8918 - val_loss: 0.5195 - val_acc: 0.8925\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5191 - acc: 0.8948 - val_loss: 0.5007 - val_acc: 0.8960\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5011 - acc: 0.8971 - val_loss: 0.4877 - val_acc: 0.8978\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4875 - acc: 0.8991 - val_loss: 0.4779 - val_acc: 0.8999\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4740 - acc: 0.9011 - val_loss: 0.4800 - val_acc: 0.8989\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4631 - acc: 0.9029 - val_loss: 0.4681 - val_acc: 0.9009\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4650 - acc: 0.9023 - val_loss: 0.5242 - val_acc: 0.8888\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4554 - acc: 0.9028 - val_loss: 0.4543 - val_acc: 0.9024\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4340 - acc: 0.9065 - val_loss: 0.4430 - val_acc: 0.9052\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4238 - acc: 0.9082 - val_loss: 0.4491 - val_acc: 0.9047\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4158 - acc: 0.9096 - val_loss: 0.4397 - val_acc: 0.9070\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4070 - acc: 0.9112 - val_loss: 0.4420 - val_acc: 0.9071\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4011 - acc: 0.9116 - val_loss: 0.4322 - val_acc: 0.9078\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3924 - acc: 0.9130 - val_loss: 0.4292 - val_acc: 0.9087\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3864 - acc: 0.9141 - val_loss: 0.4335 - val_acc: 0.9071\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3804 - acc: 0.9152 - val_loss: 0.4316 - val_acc: 0.9080\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3727 - acc: 0.9165 - val_loss: 0.4292 - val_acc: 0.9088\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3668 - acc: 0.9169 - val_loss: 0.4279 - val_acc: 0.9101\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3594 - acc: 0.9183 - val_loss: 0.4383 - val_acc: 0.9086\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3556 - acc: 0.9192 - val_loss: 0.4309 - val_acc: 0.9085\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3489 - acc: 0.9201 - val_loss: 0.4263 - val_acc: 0.9094\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3430 - acc: 0.9211 - val_loss: 0.4240 - val_acc: 0.9109\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3361 - acc: 0.9227 - val_loss: 0.4298 - val_acc: 0.9105\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3318 - acc: 0.9227 - val_loss: 0.4284 - val_acc: 0.9107\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3248 - acc: 0.9240 - val_loss: 0.4299 - val_acc: 0.9110\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3201 - acc: 0.9252 - val_loss: 0.4304 - val_acc: 0.9113\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3155 - acc: 0.9256 - val_loss: 0.4285 - val_acc: 0.9120\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3090 - acc: 0.9267 - val_loss: 0.4338 - val_acc: 0.9112\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3010 - acc: 0.9285 - val_loss: 0.4396 - val_acc: 0.9097\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2972 - acc: 0.9288 - val_loss: 0.4403 - val_acc: 0.9120\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2932 - acc: 0.9297 - val_loss: 0.4341 - val_acc: 0.9120\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2879 - acc: 0.9301Restoring model weights from the end of the best epoch: 27.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2879 - acc: 0.9301 - val_loss: 0.4382 - val_acc: 0.9108\n",
      "Epoch 37: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9460 - acc: 0.8501 - val_loss: 0.7090 - val_acc: 0.8712\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7525 - acc: 0.8653 - val_loss: 0.6458 - val_acc: 0.8773\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6882 - acc: 0.8705 - val_loss: 0.5902 - val_acc: 0.8835\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6294 - acc: 0.8785 - val_loss: 0.5493 - val_acc: 0.8909\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5805 - acc: 0.8857 - val_loss: 0.5113 - val_acc: 0.8972\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5468 - acc: 0.8908 - val_loss: 0.4870 - val_acc: 0.9008\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5262 - acc: 0.8933 - val_loss: 0.4803 - val_acc: 0.9007\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5084 - acc: 0.8959 - val_loss: 0.4608 - val_acc: 0.9043\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4943 - acc: 0.8982 - val_loss: 0.4571 - val_acc: 0.9044\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4807 - acc: 0.9001 - val_loss: 0.4460 - val_acc: 0.9065\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4680 - acc: 0.9017 - val_loss: 0.4376 - val_acc: 0.9076\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4569 - acc: 0.9035 - val_loss: 0.4394 - val_acc: 0.9075\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.8547 - acc: 0.8633 - val_loss: 0.7277 - val_acc: 0.8678\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.7262 - acc: 0.8652 - val_loss: 0.6248 - val_acc: 0.8784\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5767 - acc: 0.8836 - val_loss: 0.4636 - val_acc: 0.9029\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4788 - acc: 0.8996 - val_loss: 0.4348 - val_acc: 0.9077\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4539 - acc: 0.9035 - val_loss: 0.4272 - val_acc: 0.9090\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4404 - acc: 0.9052 - val_loss: 0.4222 - val_acc: 0.9100\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4292 - acc: 0.9070 - val_loss: 0.4186 - val_acc: 0.9110\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4227 - acc: 0.9083 - val_loss: 0.4156 - val_acc: 0.9113\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4146 - acc: 0.9091 - val_loss: 0.4175 - val_acc: 0.9103\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4092 - acc: 0.9100 - val_loss: 0.4104 - val_acc: 0.9135\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4033 - acc: 0.9109 - val_loss: 0.4055 - val_acc: 0.9136\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3965 - acc: 0.9120 - val_loss: 0.4144 - val_acc: 0.9112\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3909 - acc: 0.9128 - val_loss: 0.4051 - val_acc: 0.9141\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3874 - acc: 0.9131 - val_loss: 0.4033 - val_acc: 0.9147\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3821 - acc: 0.9141 - val_loss: 0.4088 - val_acc: 0.9130\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3760 - acc: 0.9155 - val_loss: 0.4052 - val_acc: 0.9147\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3709 - acc: 0.9162 - val_loss: 0.4094 - val_acc: 0.9144\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3805 - acc: 0.9140 - val_loss: 0.4038 - val_acc: 0.9151\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3615 - acc: 0.9178 - val_loss: 0.4087 - val_acc: 0.9137\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3554 - acc: 0.9185 - val_loss: 0.4036 - val_acc: 0.9161\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3520 - acc: 0.9191 - val_loss: 0.4030 - val_acc: 0.9153\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3454 - acc: 0.9204 - val_loss: 0.4085 - val_acc: 0.9157\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3414 - acc: 0.9211 - val_loss: 0.4015 - val_acc: 0.9164\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3350 - acc: 0.9220 - val_loss: 0.4046 - val_acc: 0.9167\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3318 - acc: 0.9226 - val_loss: 0.4074 - val_acc: 0.9167\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3295 - acc: 0.9231 - val_loss: 0.4096 - val_acc: 0.9156\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3208 - acc: 0.9245 - val_loss: 0.4090 - val_acc: 0.9166\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3182 - acc: 0.9250 - val_loss: 0.4078 - val_acc: 0.9165\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3127 - acc: 0.9256 - val_loss: 0.4103 - val_acc: 0.9166\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3079 - acc: 0.9267 - val_loss: 0.4154 - val_acc: 0.9157\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3023 - acc: 0.9275 - val_loss: 0.4162 - val_acc: 0.9168\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.2972 - acc: 0.9282 - val_loss: 0.4179 - val_acc: 0.9161\n",
      "Epoch 45/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.9287Restoring model weights from the end of the best epoch: 35.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2951 - acc: 0.9287 - val_loss: 0.4160 - val_acc: 0.9170\n",
      "Epoch 45: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9318 - acc: 0.8517 - val_loss: 0.7321 - val_acc: 0.8663\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7362 - acc: 0.8670 - val_loss: 0.6617 - val_acc: 0.8732\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6635 - acc: 0.8744 - val_loss: 0.6074 - val_acc: 0.8799\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6105 - acc: 0.8807 - val_loss: 0.5575 - val_acc: 0.8892\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5659 - acc: 0.8882 - val_loss: 0.5262 - val_acc: 0.8931\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5347 - acc: 0.8931 - val_loss: 0.5024 - val_acc: 0.8979\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5129 - acc: 0.8962 - val_loss: 0.4943 - val_acc: 0.8990\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4940 - acc: 0.8988 - val_loss: 0.4903 - val_acc: 0.8994\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4787 - acc: 0.9007 - val_loss: 0.4734 - val_acc: 0.9026\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4656 - acc: 0.9022 - val_loss: 0.4638 - val_acc: 0.9043\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4532 - acc: 0.9042 - val_loss: 0.4603 - val_acc: 0.9039\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4408 - acc: 0.9060 - val_loss: 0.4477 - val_acc: 0.9059\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4322 - acc: 0.9075 - val_loss: 0.4493 - val_acc: 0.9045\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4230 - acc: 0.9088 - val_loss: 0.4435 - val_acc: 0.9072\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4119 - acc: 0.9107 - val_loss: 0.4378 - val_acc: 0.9080\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4064 - acc: 0.9114 - val_loss: 0.4592 - val_acc: 0.9018\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3967 - acc: 0.9128 - val_loss: 0.4310 - val_acc: 0.9097\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3873 - acc: 0.9146 - val_loss: 0.4283 - val_acc: 0.9105\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3786 - acc: 0.9158 - val_loss: 0.4252 - val_acc: 0.9106\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3711 - acc: 0.9165 - val_loss: 0.4242 - val_acc: 0.9120\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3669 - acc: 0.9175 - val_loss: 0.4236 - val_acc: 0.9117\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3573 - acc: 0.9191 - val_loss: 0.4226 - val_acc: 0.9118\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3512 - acc: 0.9201 - val_loss: 0.4281 - val_acc: 0.9113\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3452 - acc: 0.9212 - val_loss: 0.4253 - val_acc: 0.9113\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3388 - acc: 0.9221 - val_loss: 0.4233 - val_acc: 0.9131\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3327 - acc: 0.9233 - val_loss: 0.4257 - val_acc: 0.9139\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3275 - acc: 0.9240 - val_loss: 0.4187 - val_acc: 0.9130\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3180 - acc: 0.9253 - val_loss: 0.4308 - val_acc: 0.9125\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3150 - acc: 0.9263 - val_loss: 0.4335 - val_acc: 0.9126\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3099 - acc: 0.9268 - val_loss: 0.4285 - val_acc: 0.9131\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3025 - acc: 0.9282 - val_loss: 0.4283 - val_acc: 0.9135\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2983 - acc: 0.9291 - val_loss: 0.4333 - val_acc: 0.9127\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2933 - acc: 0.9294 - val_loss: 0.4381 - val_acc: 0.9127\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2853 - acc: 0.9313 - val_loss: 0.4367 - val_acc: 0.9122\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2801 - acc: 0.9321 - val_loss: 0.4382 - val_acc: 0.9120\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2769 - acc: 0.9328 - val_loss: 0.4431 - val_acc: 0.9136\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2713 - acc: 0.9337Restoring model weights from the end of the best epoch: 27.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2713 - acc: 0.9337 - val_loss: 0.4476 - val_acc: 0.9121\n",
      "Epoch 37: early stopping\n",
      "[0.41880184412002563, 0.4157028794288635, 0.4239782989025116, 0.40145760774612427, 0.41872838139533997]\n",
      "[26, 25, 27, 35, 27]\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9878 - acc: 0.8491 - val_loss: 0.7421 - val_acc: 0.8653\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7742 - acc: 0.8649 - val_loss: 0.6941 - val_acc: 0.8698\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7093 - acc: 0.8693 - val_loss: 0.6506 - val_acc: 0.8747\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6676 - acc: 0.8736 - val_loss: 0.6112 - val_acc: 0.8796\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6256 - acc: 0.8791 - val_loss: 0.5790 - val_acc: 0.8837\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5889 - acc: 0.8841 - val_loss: 0.5427 - val_acc: 0.8894\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5616 - acc: 0.8882 - val_loss: 0.5282 - val_acc: 0.8920\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5424 - acc: 0.8913 - val_loss: 0.5126 - val_acc: 0.8958\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5265 - acc: 0.8935 - val_loss: 0.4966 - val_acc: 0.8980\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5142 - acc: 0.8950 - val_loss: 0.4925 - val_acc: 0.8976\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5019 - acc: 0.8970 - val_loss: 0.4822 - val_acc: 0.8999\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4925 - acc: 0.8986 - val_loss: 0.4771 - val_acc: 0.9006\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4819 - acc: 0.9001 - val_loss: 0.4691 - val_acc: 0.9013\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4731 - acc: 0.9015 - val_loss: 0.4639 - val_acc: 0.9029\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4664 - acc: 0.9022 - val_loss: 0.4591 - val_acc: 0.9033\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4603 - acc: 0.9031 - val_loss: 0.4566 - val_acc: 0.9032\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4538 - acc: 0.9042 - val_loss: 0.4516 - val_acc: 0.9043\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4482 - acc: 0.9050 - val_loss: 0.4515 - val_acc: 0.9046\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4404 - acc: 0.9065 - val_loss: 0.4473 - val_acc: 0.9051\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4362 - acc: 0.9067 - val_loss: 0.4444 - val_acc: 0.9057\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4295 - acc: 0.9078 - val_loss: 0.4402 - val_acc: 0.9070\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4239 - acc: 0.9087 - val_loss: 0.4384 - val_acc: 0.9070\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4179 - acc: 0.9100 - val_loss: 0.4360 - val_acc: 0.9078\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4142 - acc: 0.9105 - val_loss: 0.4358 - val_acc: 0.9082\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4075 - acc: 0.9113 - val_loss: 0.4325 - val_acc: 0.9092\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4039 - acc: 0.9121 - val_loss: 0.4326 - val_acc: 0.9086\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3998 - acc: 0.9126 - val_loss: 0.4297 - val_acc: 0.9097\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3950 - acc: 0.9135 - val_loss: 0.4326 - val_acc: 0.9091\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3897 - acc: 0.9145 - val_loss: 0.4310 - val_acc: 0.9101\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3856 - acc: 0.9149 - val_loss: 0.4273 - val_acc: 0.9101\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3814 - acc: 0.9155 - val_loss: 0.4269 - val_acc: 0.9100\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3775 - acc: 0.9164 - val_loss: 0.4309 - val_acc: 0.9098\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3737 - acc: 0.9165 - val_loss: 0.4300 - val_acc: 0.9105\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3686 - acc: 0.9177 - val_loss: 0.4260 - val_acc: 0.9111\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3663 - acc: 0.9183 - val_loss: 0.4277 - val_acc: 0.9113\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3622 - acc: 0.9189 - val_loss: 0.4357 - val_acc: 0.9112\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3586 - acc: 0.9193 - val_loss: 0.4233 - val_acc: 0.9113\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3539 - acc: 0.9203 - val_loss: 0.4243 - val_acc: 0.9119\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3495 - acc: 0.9213 - val_loss: 0.4267 - val_acc: 0.9122\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3452 - acc: 0.9219 - val_loss: 0.4288 - val_acc: 0.9122\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3438 - acc: 0.9218 - val_loss: 0.4334 - val_acc: 0.9118\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3402 - acc: 0.9227 - val_loss: 0.4331 - val_acc: 0.9121\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3349 - acc: 0.9235 - val_loss: 0.4361 - val_acc: 0.9127\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3308 - acc: 0.9242 - val_loss: 0.4320 - val_acc: 0.9125\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3293 - acc: 0.9243 - val_loss: 0.4327 - val_acc: 0.9118\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3255 - acc: 0.9253 - val_loss: 0.4331 - val_acc: 0.9122\n",
      "Epoch 47/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3218 - acc: 0.9257Restoring model weights from the end of the best epoch: 37.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3218 - acc: 0.9257 - val_loss: 0.4331 - val_acc: 0.9117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 0.9889 - acc: 0.8498 - val_loss: 0.7458 - val_acc: 0.8647\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7663 - acc: 0.8654 - val_loss: 0.6912 - val_acc: 0.8683\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7023 - acc: 0.8700 - val_loss: 0.6431 - val_acc: 0.8745\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6547 - acc: 0.8758 - val_loss: 0.5979 - val_acc: 0.8816\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6096 - acc: 0.8825 - val_loss: 0.5604 - val_acc: 0.8868\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5738 - acc: 0.8877 - val_loss: 0.5314 - val_acc: 0.8924\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.5490 - acc: 0.8915 - val_loss: 0.5163 - val_acc: 0.8947\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5288 - acc: 0.8942 - val_loss: 0.4999 - val_acc: 0.8966\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5151 - acc: 0.8958 - val_loss: 0.4905 - val_acc: 0.8987\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5004 - acc: 0.8984 - val_loss: 0.4838 - val_acc: 0.8998\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4882 - acc: 0.9002 - val_loss: 0.4753 - val_acc: 0.9020\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4784 - acc: 0.9017 - val_loss: 0.4766 - val_acc: 0.8999\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4696 - acc: 0.9029 - val_loss: 0.4610 - val_acc: 0.9035\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4607 - acc: 0.9044 - val_loss: 0.4610 - val_acc: 0.9027\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4544 - acc: 0.9051 - val_loss: 0.4561 - val_acc: 0.9041\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4451 - acc: 0.9064 - val_loss: 0.4539 - val_acc: 0.9042\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4388 - acc: 0.9076 - val_loss: 0.4492 - val_acc: 0.9053\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4325 - acc: 0.9080 - val_loss: 0.4438 - val_acc: 0.9070\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4260 - acc: 0.9091 - val_loss: 0.4371 - val_acc: 0.9077\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4193 - acc: 0.9099 - val_loss: 0.4333 - val_acc: 0.9089\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4136 - acc: 0.9108 - val_loss: 0.4371 - val_acc: 0.9075\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4088 - acc: 0.9118 - val_loss: 0.4310 - val_acc: 0.9092\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4027 - acc: 0.9127 - val_loss: 0.4351 - val_acc: 0.9094\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3970 - acc: 0.9142 - val_loss: 0.4248 - val_acc: 0.9098\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3923 - acc: 0.9145 - val_loss: 0.4251 - val_acc: 0.9104\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3884 - acc: 0.9151 - val_loss: 0.4275 - val_acc: 0.9099\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3820 - acc: 0.9164 - val_loss: 0.4286 - val_acc: 0.9105\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3787 - acc: 0.9167 - val_loss: 0.4275 - val_acc: 0.9113\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3735 - acc: 0.9177 - val_loss: 0.4212 - val_acc: 0.9121\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3691 - acc: 0.9181 - val_loss: 0.4178 - val_acc: 0.9113\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3643 - acc: 0.9189 - val_loss: 0.4196 - val_acc: 0.9115\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3585 - acc: 0.9198 - val_loss: 0.4241 - val_acc: 0.9112\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3539 - acc: 0.9211 - val_loss: 0.4234 - val_acc: 0.9129\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3504 - acc: 0.9214 - val_loss: 0.4200 - val_acc: 0.9131\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3458 - acc: 0.9219 - val_loss: 0.4187 - val_acc: 0.9128\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3413 - acc: 0.9226 - val_loss: 0.4239 - val_acc: 0.9126\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3386 - acc: 0.9233 - val_loss: 0.4264 - val_acc: 0.9139\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3331 - acc: 0.9244 - val_loss: 0.4225 - val_acc: 0.9130\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3305 - acc: 0.9251 - val_loss: 0.4206 - val_acc: 0.9134\n",
      "Epoch 40/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3249 - acc: 0.9260Restoring model weights from the end of the best epoch: 30.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3250 - acc: 0.9261 - val_loss: 0.4263 - val_acc: 0.9124\n",
      "Epoch 40: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 0.9846 - acc: 0.8497 - val_loss: 0.7550 - val_acc: 0.8629\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7709 - acc: 0.8658 - val_loss: 0.7045 - val_acc: 0.8665\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7015 - acc: 0.8699 - val_loss: 0.6574 - val_acc: 0.8722\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6509 - acc: 0.8760 - val_loss: 0.6003 - val_acc: 0.8811\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6068 - acc: 0.8822 - val_loss: 0.5681 - val_acc: 0.8848\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5743 - acc: 0.8866 - val_loss: 0.5433 - val_acc: 0.8896\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5512 - acc: 0.8903 - val_loss: 0.5258 - val_acc: 0.8921\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5314 - acc: 0.8930 - val_loss: 0.5048 - val_acc: 0.8956\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5183 - acc: 0.8950 - val_loss: 0.4961 - val_acc: 0.8962\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5070 - acc: 0.8965 - val_loss: 0.4941 - val_acc: 0.8964\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4947 - acc: 0.8983 - val_loss: 0.4880 - val_acc: 0.8975\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4851 - acc: 0.8996 - val_loss: 0.4784 - val_acc: 0.8995\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4750 - acc: 0.9013 - val_loss: 0.4685 - val_acc: 0.9009\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4668 - acc: 0.9024 - val_loss: 0.4649 - val_acc: 0.9019\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4613 - acc: 0.9035 - val_loss: 0.4630 - val_acc: 0.9022\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4517 - acc: 0.9048 - val_loss: 0.4570 - val_acc: 0.9035\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4441 - acc: 0.9062 - val_loss: 0.4557 - val_acc: 0.9026\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4389 - acc: 0.9068 - val_loss: 0.4475 - val_acc: 0.9046\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4321 - acc: 0.9077 - val_loss: 0.4476 - val_acc: 0.9049\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4242 - acc: 0.9091 - val_loss: 0.4480 - val_acc: 0.9054\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4200 - acc: 0.9094 - val_loss: 0.4403 - val_acc: 0.9056\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4163 - acc: 0.9101 - val_loss: 0.4385 - val_acc: 0.9057\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4094 - acc: 0.9111 - val_loss: 0.4392 - val_acc: 0.9055\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4032 - acc: 0.9120 - val_loss: 0.4327 - val_acc: 0.9080\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4007 - acc: 0.9126 - val_loss: 0.4347 - val_acc: 0.9082\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3933 - acc: 0.9140 - val_loss: 0.4315 - val_acc: 0.9080\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3884 - acc: 0.9147 - val_loss: 0.4327 - val_acc: 0.9073\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3851 - acc: 0.9153 - val_loss: 0.4311 - val_acc: 0.9082\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3818 - acc: 0.9156 - val_loss: 0.4289 - val_acc: 0.9093\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3754 - acc: 0.9167 - val_loss: 0.4327 - val_acc: 0.9081\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3700 - acc: 0.9175 - val_loss: 0.4276 - val_acc: 0.9097\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3655 - acc: 0.9186 - val_loss: 0.4333 - val_acc: 0.9088\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3634 - acc: 0.9189 - val_loss: 0.4258 - val_acc: 0.9101\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3581 - acc: 0.9196 - val_loss: 0.4301 - val_acc: 0.9098\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3512 - acc: 0.9211 - val_loss: 0.4279 - val_acc: 0.9114\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3482 - acc: 0.9212 - val_loss: 0.4305 - val_acc: 0.9107\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3431 - acc: 0.9225 - val_loss: 0.4362 - val_acc: 0.9103\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3392 - acc: 0.9224 - val_loss: 0.4297 - val_acc: 0.9091\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3379 - acc: 0.9232 - val_loss: 0.4342 - val_acc: 0.9102\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3301 - acc: 0.9243 - val_loss: 0.4323 - val_acc: 0.9112\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3271 - acc: 0.9250 - val_loss: 0.4342 - val_acc: 0.9107\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3263 - acc: 0.9250 - val_loss: 0.4356 - val_acc: 0.9112\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3218 - acc: 0.9256Restoring model weights from the end of the best epoch: 33.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3218 - acc: 0.9256 - val_loss: 0.4412 - val_acc: 0.9106\n",
      "Epoch 43: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 37ms/step - loss: 1.0069 - acc: 0.8475 - val_loss: 0.7224 - val_acc: 0.8701\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7804 - acc: 0.8638 - val_loss: 0.6708 - val_acc: 0.8729\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7219 - acc: 0.8672 - val_loss: 0.6389 - val_acc: 0.8776\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6825 - acc: 0.8707 - val_loss: 0.6084 - val_acc: 0.8815\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6429 - acc: 0.8762 - val_loss: 0.5591 - val_acc: 0.8883\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6018 - acc: 0.8820 - val_loss: 0.5299 - val_acc: 0.8917\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5738 - acc: 0.8857 - val_loss: 0.5066 - val_acc: 0.8967\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5519 - acc: 0.8886 - val_loss: 0.4977 - val_acc: 0.8981\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5343 - acc: 0.8917 - val_loss: 0.4821 - val_acc: 0.9004\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5222 - acc: 0.8936 - val_loss: 0.4762 - val_acc: 0.9014\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5083 - acc: 0.8957 - val_loss: 0.4648 - val_acc: 0.9034\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4982 - acc: 0.8972 - val_loss: 0.4599 - val_acc: 0.9042\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4884 - acc: 0.8985 - val_loss: 0.4576 - val_acc: 0.9046\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4824 - acc: 0.8997 - val_loss: 0.4490 - val_acc: 0.9061\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4709 - acc: 0.9015 - val_loss: 0.4451 - val_acc: 0.9073\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4650 - acc: 0.9023 - val_loss: 0.4456 - val_acc: 0.9072\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4590 - acc: 0.9029 - val_loss: 0.4385 - val_acc: 0.9072\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4533 - acc: 0.9042 - val_loss: 0.4311 - val_acc: 0.9097\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4445 - acc: 0.9053 - val_loss: 0.4364 - val_acc: 0.9082\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4400 - acc: 0.9062 - val_loss: 0.4279 - val_acc: 0.9097\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4354 - acc: 0.9066 - val_loss: 0.4251 - val_acc: 0.9106\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4303 - acc: 0.9074 - val_loss: 0.4289 - val_acc: 0.9107\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4231 - acc: 0.9087 - val_loss: 0.4199 - val_acc: 0.9108\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4181 - acc: 0.9095 - val_loss: 0.4194 - val_acc: 0.9109\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4125 - acc: 0.9101 - val_loss: 0.4226 - val_acc: 0.9118\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4089 - acc: 0.9111 - val_loss: 0.4211 - val_acc: 0.9119\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4044 - acc: 0.9117 - val_loss: 0.4141 - val_acc: 0.9122\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4001 - acc: 0.9122 - val_loss: 0.4151 - val_acc: 0.9128\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3946 - acc: 0.9134 - val_loss: 0.4120 - val_acc: 0.9117\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3919 - acc: 0.9136 - val_loss: 0.4090 - val_acc: 0.9144\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3842 - acc: 0.9149 - val_loss: 0.4083 - val_acc: 0.9147\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3809 - acc: 0.9155 - val_loss: 0.4108 - val_acc: 0.9138\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3794 - acc: 0.9158 - val_loss: 0.4120 - val_acc: 0.9135\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3720 - acc: 0.9173 - val_loss: 0.4121 - val_acc: 0.9136\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3701 - acc: 0.9178 - val_loss: 0.4074 - val_acc: 0.9152\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3645 - acc: 0.9183 - val_loss: 0.4072 - val_acc: 0.9146\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3598 - acc: 0.9192 - val_loss: 0.4145 - val_acc: 0.9138\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3556 - acc: 0.9198 - val_loss: 0.4067 - val_acc: 0.9154\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3522 - acc: 0.9203 - val_loss: 0.4110 - val_acc: 0.9149\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3491 - acc: 0.9208 - val_loss: 0.4132 - val_acc: 0.9159\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3444 - acc: 0.9219 - val_loss: 0.4084 - val_acc: 0.9155\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3397 - acc: 0.9227 - val_loss: 0.4123 - val_acc: 0.9163\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3387 - acc: 0.9225 - val_loss: 0.4123 - val_acc: 0.9153\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3342 - acc: 0.9233 - val_loss: 0.4182 - val_acc: 0.9156\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3299 - acc: 0.9242 - val_loss: 0.4160 - val_acc: 0.9160\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3267 - acc: 0.9247 - val_loss: 0.4151 - val_acc: 0.9153\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3212 - acc: 0.9257 - val_loss: 0.4247 - val_acc: 0.9143\n",
      "Epoch 48/200\n",
      "190/191 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.9238Restoring model weights from the end of the best epoch: 38.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3294 - acc: 0.9239 - val_loss: 0.4161 - val_acc: 0.9164\n",
      "Epoch 48: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 13s 38ms/step - loss: 0.9849 - acc: 0.8496 - val_loss: 0.7443 - val_acc: 0.8659\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7668 - acc: 0.8651 - val_loss: 0.6877 - val_acc: 0.8700\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7086 - acc: 0.8686 - val_loss: 0.6586 - val_acc: 0.8732\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6721 - acc: 0.8724 - val_loss: 0.6247 - val_acc: 0.8782\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6299 - acc: 0.8783 - val_loss: 0.5720 - val_acc: 0.8853\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5873 - acc: 0.8846 - val_loss: 0.5496 - val_acc: 0.8893\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5606 - acc: 0.8887 - val_loss: 0.5326 - val_acc: 0.8916\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5393 - acc: 0.8918 - val_loss: 0.5159 - val_acc: 0.8951\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5240 - acc: 0.8946 - val_loss: 0.5008 - val_acc: 0.8979\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5109 - acc: 0.8961 - val_loss: 0.4926 - val_acc: 0.8989\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4991 - acc: 0.8978 - val_loss: 0.4859 - val_acc: 0.8994\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4887 - acc: 0.8995 - val_loss: 0.4762 - val_acc: 0.9022\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4806 - acc: 0.9008 - val_loss: 0.4794 - val_acc: 0.9013\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4717 - acc: 0.9021 - val_loss: 0.4690 - val_acc: 0.9029\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4633 - acc: 0.9033 - val_loss: 0.4662 - val_acc: 0.9021\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4563 - acc: 0.9042 - val_loss: 0.4568 - val_acc: 0.9047\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4594 - acc: 0.9030 - val_loss: 0.4589 - val_acc: 0.9035\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4445 - acc: 0.9060 - val_loss: 0.4521 - val_acc: 0.9059\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4375 - acc: 0.9070 - val_loss: 0.4525 - val_acc: 0.9049\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4304 - acc: 0.9080 - val_loss: 0.4450 - val_acc: 0.9069\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4271 - acc: 0.9084 - val_loss: 0.4415 - val_acc: 0.9068\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4214 - acc: 0.9092 - val_loss: 0.4379 - val_acc: 0.9079\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4147 - acc: 0.9101 - val_loss: 0.4401 - val_acc: 0.9080\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4125 - acc: 0.9104 - val_loss: 0.4387 - val_acc: 0.9079\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4060 - acc: 0.9117 - val_loss: 0.4368 - val_acc: 0.9081\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4001 - acc: 0.9126 - val_loss: 0.4381 - val_acc: 0.9085\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3958 - acc: 0.9131 - val_loss: 0.4315 - val_acc: 0.9093\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3932 - acc: 0.9136 - val_loss: 0.4326 - val_acc: 0.9092\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3874 - acc: 0.9147 - val_loss: 0.4280 - val_acc: 0.9097\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3835 - acc: 0.9151 - val_loss: 0.4341 - val_acc: 0.9100\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3802 - acc: 0.9157 - val_loss: 0.4319 - val_acc: 0.9100\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3742 - acc: 0.9168 - val_loss: 0.4322 - val_acc: 0.9100\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3720 - acc: 0.9173 - val_loss: 0.4292 - val_acc: 0.9114\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3669 - acc: 0.9182 - val_loss: 0.4356 - val_acc: 0.9088\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3647 - acc: 0.9184 - val_loss: 0.4325 - val_acc: 0.9102\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3606 - acc: 0.9190 - val_loss: 0.4346 - val_acc: 0.9100\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3558 - acc: 0.9197 - val_loss: 0.4328 - val_acc: 0.9102\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3501 - acc: 0.9207 - val_loss: 0.4293 - val_acc: 0.9118\n",
      "Epoch 39/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.9208Restoring model weights from the end of the best epoch: 29.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3493 - acc: 0.9209 - val_loss: 0.4332 - val_acc: 0.9116\n",
      "Epoch 39: early stopping\n",
      "[0.42331546545028687, 0.4177807569503784, 0.4257960915565491, 0.40671592950820923, 0.4280015528202057]\n",
      "[37, 30, 33, 38, 29]\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 11s 34ms/step - loss: 1.0408 - acc: 0.8478 - val_loss: 0.7475 - val_acc: 0.8654\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7975 - acc: 0.8645 - val_loss: 0.7113 - val_acc: 0.8669\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7392 - acc: 0.8672 - val_loss: 0.6716 - val_acc: 0.8710\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7010 - acc: 0.8700 - val_loss: 0.6455 - val_acc: 0.8750\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6656 - acc: 0.8745 - val_loss: 0.6100 - val_acc: 0.8811\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6299 - acc: 0.8795 - val_loss: 0.5846 - val_acc: 0.8837\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6042 - acc: 0.8829 - val_loss: 0.5598 - val_acc: 0.8883\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5816 - acc: 0.8859 - val_loss: 0.5409 - val_acc: 0.8905\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5661 - acc: 0.8886 - val_loss: 0.5233 - val_acc: 0.8946\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7830 - acc: 0.8604 - val_loss: 0.6145 - val_acc: 0.8774\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6022 - acc: 0.8816 - val_loss: 0.5447 - val_acc: 0.8898\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5617 - acc: 0.8883 - val_loss: 0.5292 - val_acc: 0.8925\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5467 - acc: 0.8907 - val_loss: 0.5136 - val_acc: 0.8955\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5353 - acc: 0.8926 - val_loss: 0.5074 - val_acc: 0.8959\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5263 - acc: 0.8938 - val_loss: 0.5068 - val_acc: 0.8960\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5202 - acc: 0.8946 - val_loss: 0.4960 - val_acc: 0.8971\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5134 - acc: 0.8958 - val_loss: 0.4926 - val_acc: 0.8983\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5091 - acc: 0.8963 - val_loss: 0.4899 - val_acc: 0.8992\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5062 - acc: 0.8962 - val_loss: 0.4893 - val_acc: 0.8978\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4990 - acc: 0.8977 - val_loss: 0.4837 - val_acc: 0.8992\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4938 - acc: 0.8984 - val_loss: 0.4786 - val_acc: 0.9000\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4912 - acc: 0.8985 - val_loss: 0.4765 - val_acc: 0.9004\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4863 - acc: 0.8992 - val_loss: 0.4716 - val_acc: 0.9015\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4844 - acc: 0.8997 - val_loss: 0.4710 - val_acc: 0.9020\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4802 - acc: 0.9006 - val_loss: 0.4687 - val_acc: 0.9021\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4724 - acc: 0.9015 - val_loss: 0.4681 - val_acc: 0.9021\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4716 - acc: 0.9018 - val_loss: 0.4636 - val_acc: 0.9026\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4678 - acc: 0.9021 - val_loss: 0.4626 - val_acc: 0.9029\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4686 - acc: 0.9023 - val_loss: 0.4612 - val_acc: 0.9029\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4600 - acc: 0.9032 - val_loss: 0.4650 - val_acc: 0.9028\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4578 - acc: 0.9037 - val_loss: 0.4614 - val_acc: 0.9040\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4543 - acc: 0.9042 - val_loss: 0.4541 - val_acc: 0.9039\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4503 - acc: 0.9046 - val_loss: 0.4590 - val_acc: 0.9049\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4472 - acc: 0.9057 - val_loss: 0.4537 - val_acc: 0.9055\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4432 - acc: 0.9065 - val_loss: 0.4503 - val_acc: 0.9061\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4416 - acc: 0.9067 - val_loss: 0.4515 - val_acc: 0.9057\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4383 - acc: 0.9073 - val_loss: 0.4537 - val_acc: 0.9054\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4337 - acc: 0.9079 - val_loss: 0.4523 - val_acc: 0.9058\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4310 - acc: 0.9084 - val_loss: 0.4481 - val_acc: 0.9073\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4290 - acc: 0.9088 - val_loss: 0.4439 - val_acc: 0.9079\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4278 - acc: 0.9086 - val_loss: 0.4466 - val_acc: 0.9074\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4240 - acc: 0.9095 - val_loss: 0.4436 - val_acc: 0.9074\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4208 - acc: 0.9099 - val_loss: 0.4478 - val_acc: 0.9085\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4187 - acc: 0.9104 - val_loss: 0.4455 - val_acc: 0.9073\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4150 - acc: 0.9111 - val_loss: 0.4561 - val_acc: 0.9065\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4125 - acc: 0.9115 - val_loss: 0.4423 - val_acc: 0.9085\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4100 - acc: 0.9123 - val_loss: 0.4469 - val_acc: 0.9079\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4086 - acc: 0.9121 - val_loss: 0.4433 - val_acc: 0.9093\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4060 - acc: 0.9127 - val_loss: 0.4423 - val_acc: 0.9093\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4022 - acc: 0.9132 - val_loss: 0.4420 - val_acc: 0.9101\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4015 - acc: 0.9132 - val_loss: 0.4403 - val_acc: 0.9086\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3966 - acc: 0.9142 - val_loss: 0.4418 - val_acc: 0.9091\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3948 - acc: 0.9141 - val_loss: 0.4436 - val_acc: 0.9100\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3950 - acc: 0.9145 - val_loss: 0.4439 - val_acc: 0.9096\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3897 - acc: 0.9155 - val_loss: 0.4443 - val_acc: 0.9103\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3873 - acc: 0.9160 - val_loss: 0.4428 - val_acc: 0.9097\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3859 - acc: 0.9159 - val_loss: 0.4453 - val_acc: 0.9099\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3848 - acc: 0.9162 - val_loss: 0.4383 - val_acc: 0.9098\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3796 - acc: 0.9173 - val_loss: 0.4382 - val_acc: 0.9103\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3787 - acc: 0.9175 - val_loss: 0.4450 - val_acc: 0.9102\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3774 - acc: 0.9173 - val_loss: 0.4416 - val_acc: 0.9108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3728 - acc: 0.9181 - val_loss: 0.4369 - val_acc: 0.9105\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3728 - acc: 0.9180 - val_loss: 0.4420 - val_acc: 0.9104\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3698 - acc: 0.9189 - val_loss: 0.4415 - val_acc: 0.9109\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3660 - acc: 0.9195 - val_loss: 0.4427 - val_acc: 0.9095\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3651 - acc: 0.9196 - val_loss: 0.4462 - val_acc: 0.9103\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3640 - acc: 0.9199 - val_loss: 0.4476 - val_acc: 0.9105\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3621 - acc: 0.9200 - val_loss: 0.4432 - val_acc: 0.9113\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3596 - acc: 0.9204 - val_loss: 0.4432 - val_acc: 0.9103\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3572 - acc: 0.9210 - val_loss: 0.4459 - val_acc: 0.9100\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3558 - acc: 0.9210 - val_loss: 0.4415 - val_acc: 0.9111\n",
      "Epoch 72/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3508 - acc: 0.9218Restoring model weights from the end of the best epoch: 62.\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3510 - acc: 0.9217 - val_loss: 0.4499 - val_acc: 0.9112\n",
      "Epoch 72: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.0445 - acc: 0.8479 - val_loss: 0.7547 - val_acc: 0.8638\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7896 - acc: 0.8649 - val_loss: 0.7111 - val_acc: 0.8663\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7310 - acc: 0.8679 - val_loss: 0.6728 - val_acc: 0.8709\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6935 - acc: 0.8706 - val_loss: 0.6408 - val_acc: 0.8738\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6627 - acc: 0.8742 - val_loss: 0.6152 - val_acc: 0.8787\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6318 - acc: 0.8788 - val_loss: 0.5801 - val_acc: 0.8849\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6005 - acc: 0.8837 - val_loss: 0.5510 - val_acc: 0.8898\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5792 - acc: 0.8868 - val_loss: 0.5360 - val_acc: 0.8919\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5576 - acc: 0.8901 - val_loss: 0.5243 - val_acc: 0.8935\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5454 - acc: 0.8921 - val_loss: 0.5115 - val_acc: 0.8950\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5320 - acc: 0.8941 - val_loss: 0.5080 - val_acc: 0.8953\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5248 - acc: 0.8946 - val_loss: 0.5009 - val_acc: 0.8959\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5142 - acc: 0.8961 - val_loss: 0.4891 - val_acc: 0.8987\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5057 - acc: 0.8977 - val_loss: 0.4917 - val_acc: 0.8982\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5001 - acc: 0.8986 - val_loss: 0.4814 - val_acc: 0.8991\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4915 - acc: 0.8999 - val_loss: 0.4738 - val_acc: 0.9016\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4861 - acc: 0.9005 - val_loss: 0.4718 - val_acc: 0.9019\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4799 - acc: 0.9013 - val_loss: 0.4687 - val_acc: 0.9019\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4783 - acc: 0.9017 - val_loss: 0.4674 - val_acc: 0.9026\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4693 - acc: 0.9028 - val_loss: 0.4624 - val_acc: 0.9027\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4627 - acc: 0.9038 - val_loss: 0.4594 - val_acc: 0.9039\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4577 - acc: 0.9049 - val_loss: 0.4591 - val_acc: 0.9045\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4537 - acc: 0.9058 - val_loss: 0.4557 - val_acc: 0.9043\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4493 - acc: 0.9061 - val_loss: 0.4530 - val_acc: 0.9049\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4462 - acc: 0.9066 - val_loss: 0.4466 - val_acc: 0.9066\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4398 - acc: 0.9077 - val_loss: 0.4495 - val_acc: 0.9049\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4376 - acc: 0.9081 - val_loss: 0.4436 - val_acc: 0.9067\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4322 - acc: 0.9090 - val_loss: 0.4428 - val_acc: 0.9070\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4287 - acc: 0.9096 - val_loss: 0.4461 - val_acc: 0.9057\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4249 - acc: 0.9102 - val_loss: 0.4422 - val_acc: 0.9074\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4210 - acc: 0.9107 - val_loss: 0.4398 - val_acc: 0.9077\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4161 - acc: 0.9115 - val_loss: 0.4354 - val_acc: 0.9089\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4137 - acc: 0.9121 - val_loss: 0.4359 - val_acc: 0.9080\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4092 - acc: 0.9125 - val_loss: 0.4360 - val_acc: 0.9083\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4064 - acc: 0.9134 - val_loss: 0.4361 - val_acc: 0.9091\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4031 - acc: 0.9137 - val_loss: 0.4390 - val_acc: 0.9087\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3977 - acc: 0.9145 - val_loss: 0.4387 - val_acc: 0.9081\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3960 - acc: 0.9149 - val_loss: 0.4373 - val_acc: 0.9099\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3917 - acc: 0.9159 - val_loss: 0.4333 - val_acc: 0.9110\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3886 - acc: 0.9161 - val_loss: 0.4324 - val_acc: 0.9107\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3858 - acc: 0.9167 - val_loss: 0.4348 - val_acc: 0.9108\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3820 - acc: 0.9177 - val_loss: 0.4332 - val_acc: 0.9112\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3807 - acc: 0.9177 - val_loss: 0.4328 - val_acc: 0.9111\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3765 - acc: 0.9185 - val_loss: 0.4511 - val_acc: 0.9097\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3740 - acc: 0.9186 - val_loss: 0.4398 - val_acc: 0.9112\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3689 - acc: 0.9197 - val_loss: 0.4327 - val_acc: 0.9112\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3654 - acc: 0.9201 - val_loss: 0.4375 - val_acc: 0.9124\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3641 - acc: 0.9204 - val_loss: 0.4421 - val_acc: 0.9106\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3619 - acc: 0.9212 - val_loss: 0.4357 - val_acc: 0.9127\n",
      "Epoch 50/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.9218Restoring model weights from the end of the best epoch: 40.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3560 - acc: 0.9219 - val_loss: 0.4344 - val_acc: 0.9119\n",
      "Epoch 50: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.0411 - acc: 0.8482 - val_loss: 0.7626 - val_acc: 0.8626\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7919 - acc: 0.8650 - val_loss: 0.7192 - val_acc: 0.8668\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7345 - acc: 0.8678 - val_loss: 0.6733 - val_acc: 0.8706\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6890 - acc: 0.8721 - val_loss: 0.6439 - val_acc: 0.8752\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6550 - acc: 0.8761 - val_loss: 0.6083 - val_acc: 0.8797\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6237 - acc: 0.8807 - val_loss: 0.5765 - val_acc: 0.8854\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6041 - acc: 0.8836 - val_loss: 0.5566 - val_acc: 0.8870\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5750 - acc: 0.8878 - val_loss: 0.5432 - val_acc: 0.8892\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5564 - acc: 0.8906 - val_loss: 0.5302 - val_acc: 0.8919\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5432 - acc: 0.8928 - val_loss: 0.5172 - val_acc: 0.8944\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5311 - acc: 0.8941 - val_loss: 0.5188 - val_acc: 0.8942\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5228 - acc: 0.8950 - val_loss: 0.5016 - val_acc: 0.8962\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5164 - acc: 0.8963 - val_loss: 0.4970 - val_acc: 0.8969\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5075 - acc: 0.8972 - val_loss: 0.4936 - val_acc: 0.8969\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5009 - acc: 0.8981 - val_loss: 0.4883 - val_acc: 0.8981\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4932 - acc: 0.8997 - val_loss: 0.4853 - val_acc: 0.8995\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4867 - acc: 0.9005 - val_loss: 0.4755 - val_acc: 0.9004\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4793 - acc: 0.9018 - val_loss: 0.4731 - val_acc: 0.9011\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4747 - acc: 0.9026 - val_loss: 0.4742 - val_acc: 0.9009\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4695 - acc: 0.9034 - val_loss: 0.4687 - val_acc: 0.9025\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4645 - acc: 0.9041 - val_loss: 0.4660 - val_acc: 0.9034\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4588 - acc: 0.9051 - val_loss: 0.4632 - val_acc: 0.9027\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4553 - acc: 0.9057 - val_loss: 0.4592 - val_acc: 0.9039\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4496 - acc: 0.9066 - val_loss: 0.4663 - val_acc: 0.9034\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4509 - acc: 0.9059 - val_loss: 0.4614 - val_acc: 0.9035\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4423 - acc: 0.9077 - val_loss: 0.4542 - val_acc: 0.9052\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4375 - acc: 0.9084 - val_loss: 0.4513 - val_acc: 0.9055\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4321 - acc: 0.9093 - val_loss: 0.4494 - val_acc: 0.9055\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4280 - acc: 0.9099 - val_loss: 0.4501 - val_acc: 0.9071\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4241 - acc: 0.9106 - val_loss: 0.4435 - val_acc: 0.9073\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4196 - acc: 0.9113 - val_loss: 0.4449 - val_acc: 0.9069\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4165 - acc: 0.9118 - val_loss: 0.4490 - val_acc: 0.9057\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4116 - acc: 0.9127 - val_loss: 0.4447 - val_acc: 0.9070\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4088 - acc: 0.9132 - val_loss: 0.4471 - val_acc: 0.9078\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4050 - acc: 0.9140 - val_loss: 0.4418 - val_acc: 0.9081\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4006 - acc: 0.9145 - val_loss: 0.4430 - val_acc: 0.9081\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3979 - acc: 0.9151 - val_loss: 0.4473 - val_acc: 0.9077\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3940 - acc: 0.9157 - val_loss: 0.4520 - val_acc: 0.9071\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3902 - acc: 0.9161 - val_loss: 0.4394 - val_acc: 0.9095\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3864 - acc: 0.9173 - val_loss: 0.4466 - val_acc: 0.9094\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3814 - acc: 0.9182 - val_loss: 0.4458 - val_acc: 0.9086\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3787 - acc: 0.9184 - val_loss: 0.4412 - val_acc: 0.9103\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3760 - acc: 0.9188 - val_loss: 0.4395 - val_acc: 0.9095\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3716 - acc: 0.9197 - val_loss: 0.4438 - val_acc: 0.9083\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3688 - acc: 0.9200 - val_loss: 0.4458 - val_acc: 0.9100\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3645 - acc: 0.9207 - val_loss: 0.4464 - val_acc: 0.9104\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3604 - acc: 0.9218 - val_loss: 0.4442 - val_acc: 0.9101\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3585 - acc: 0.9217 - val_loss: 0.4409 - val_acc: 0.9100\n",
      "Epoch 49/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3590 - acc: 0.9217Restoring model weights from the end of the best epoch: 39.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3583 - acc: 0.9218 - val_loss: 0.4479 - val_acc: 0.9105\n",
      "Epoch 49: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.0490 - acc: 0.8469 - val_loss: 0.7283 - val_acc: 0.8689\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7946 - acc: 0.8634 - val_loss: 0.6847 - val_acc: 0.8710\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7375 - acc: 0.8660 - val_loss: 0.6437 - val_acc: 0.8761\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6979 - acc: 0.8702 - val_loss: 0.6078 - val_acc: 0.8814\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6627 - acc: 0.8746 - val_loss: 0.5844 - val_acc: 0.8856\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6335 - acc: 0.8788 - val_loss: 0.5643 - val_acc: 0.8871\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6035 - acc: 0.8831 - val_loss: 0.5331 - val_acc: 0.8944\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5811 - acc: 0.8866 - val_loss: 0.5108 - val_acc: 0.8974\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5635 - acc: 0.8894 - val_loss: 0.5028 - val_acc: 0.8986\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5490 - acc: 0.8915 - val_loss: 0.4948 - val_acc: 0.9003\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5371 - acc: 0.8932 - val_loss: 0.4828 - val_acc: 0.9008\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5254 - acc: 0.8950 - val_loss: 0.4765 - val_acc: 0.9019\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5180 - acc: 0.8957 - val_loss: 0.4670 - val_acc: 0.9034\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5085 - acc: 0.8970 - val_loss: 0.4593 - val_acc: 0.9052\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5005 - acc: 0.8989 - val_loss: 0.4593 - val_acc: 0.9049\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4934 - acc: 0.8999 - val_loss: 0.4475 - val_acc: 0.9075\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4863 - acc: 0.9012 - val_loss: 0.4470 - val_acc: 0.9074\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4777 - acc: 0.9019 - val_loss: 0.4464 - val_acc: 0.9073\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4741 - acc: 0.9026 - val_loss: 0.4382 - val_acc: 0.9097\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4668 - acc: 0.9037 - val_loss: 0.4377 - val_acc: 0.9086\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4624 - acc: 0.9048 - val_loss: 0.4340 - val_acc: 0.9097\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4568 - acc: 0.9053 - val_loss: 0.4296 - val_acc: 0.9096\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4532 - acc: 0.9061 - val_loss: 0.4300 - val_acc: 0.9107\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4459 - acc: 0.9069 - val_loss: 0.4258 - val_acc: 0.9100\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4443 - acc: 0.9069 - val_loss: 0.4253 - val_acc: 0.9107\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4372 - acc: 0.9082 - val_loss: 0.4191 - val_acc: 0.9116\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4323 - acc: 0.9092 - val_loss: 0.4242 - val_acc: 0.9116\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4280 - acc: 0.9097 - val_loss: 0.4227 - val_acc: 0.9126\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4252 - acc: 0.9101 - val_loss: 0.4211 - val_acc: 0.9116\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4196 - acc: 0.9111 - val_loss: 0.4240 - val_acc: 0.9112\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4162 - acc: 0.9117 - val_loss: 0.4203 - val_acc: 0.9123\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4136 - acc: 0.9120 - val_loss: 0.4206 - val_acc: 0.9130\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4090 - acc: 0.9127 - val_loss: 0.4226 - val_acc: 0.9134\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4044 - acc: 0.9134 - val_loss: 0.4185 - val_acc: 0.9131\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4003 - acc: 0.9144 - val_loss: 0.4138 - val_acc: 0.9137\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3977 - acc: 0.9146 - val_loss: 0.4148 - val_acc: 0.9142\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3936 - acc: 0.9156 - val_loss: 0.4128 - val_acc: 0.9142\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3890 - acc: 0.9157 - val_loss: 0.4115 - val_acc: 0.9149\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3878 - acc: 0.9161 - val_loss: 0.4209 - val_acc: 0.9139\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3824 - acc: 0.9173 - val_loss: 0.4131 - val_acc: 0.9142\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3809 - acc: 0.9177 - val_loss: 0.4131 - val_acc: 0.9146\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3761 - acc: 0.9181 - val_loss: 0.4139 - val_acc: 0.9152\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3734 - acc: 0.9188 - val_loss: 0.4125 - val_acc: 0.9155\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3685 - acc: 0.9199 - val_loss: 0.4211 - val_acc: 0.9156\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3667 - acc: 0.9202 - val_loss: 0.4174 - val_acc: 0.9145\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3637 - acc: 0.9203 - val_loss: 0.4221 - val_acc: 0.9157\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3587 - acc: 0.9212 - val_loss: 0.4246 - val_acc: 0.9152\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3577 - acc: 0.9214Restoring model weights from the end of the best epoch: 38.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3577 - acc: 0.9214 - val_loss: 0.4188 - val_acc: 0.9152\n",
      "Epoch 48: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 1.0567 - acc: 0.8470 - val_loss: 0.7482 - val_acc: 0.8650\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7945 - acc: 0.8649 - val_loss: 0.7070 - val_acc: 0.8670\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7327 - acc: 0.8676 - val_loss: 0.6694 - val_acc: 0.8727\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6923 - acc: 0.8709 - val_loss: 0.6350 - val_acc: 0.8756\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6574 - acc: 0.8752 - val_loss: 0.5978 - val_acc: 0.8816\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6214 - acc: 0.8804 - val_loss: 0.5634 - val_acc: 0.8868\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5947 - acc: 0.8839 - val_loss: 0.5462 - val_acc: 0.8892\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5870 - acc: 0.8842 - val_loss: 0.5400 - val_acc: 0.8904\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5592 - acc: 0.8890 - val_loss: 0.5239 - val_acc: 0.8942\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5459 - acc: 0.8910 - val_loss: 0.5170 - val_acc: 0.8946\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5339 - acc: 0.8927 - val_loss: 0.5041 - val_acc: 0.8969\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5242 - acc: 0.8944 - val_loss: 0.4975 - val_acc: 0.8974\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5152 - acc: 0.8956 - val_loss: 0.4902 - val_acc: 0.8995\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5077 - acc: 0.8968 - val_loss: 0.4879 - val_acc: 0.8998\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5011 - acc: 0.8976 - val_loss: 0.4826 - val_acc: 0.9007\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4943 - acc: 0.8989 - val_loss: 0.4787 - val_acc: 0.9011\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4880 - acc: 0.8998 - val_loss: 0.4799 - val_acc: 0.8997\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4826 - acc: 0.9004 - val_loss: 0.4743 - val_acc: 0.9011\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4766 - acc: 0.9016 - val_loss: 0.4717 - val_acc: 0.9017\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4709 - acc: 0.9024 - val_loss: 0.4658 - val_acc: 0.9034\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4665 - acc: 0.9032 - val_loss: 0.4667 - val_acc: 0.9029\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4641 - acc: 0.9034 - val_loss: 0.4613 - val_acc: 0.9036\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4577 - acc: 0.9044 - val_loss: 0.4601 - val_acc: 0.9037\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4531 - acc: 0.9052 - val_loss: 0.4565 - val_acc: 0.9040\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4489 - acc: 0.9056 - val_loss: 0.4535 - val_acc: 0.9051\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4430 - acc: 0.9068 - val_loss: 0.4512 - val_acc: 0.9065\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4411 - acc: 0.9070 - val_loss: 0.4519 - val_acc: 0.9067\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4372 - acc: 0.9077 - val_loss: 0.4585 - val_acc: 0.9047\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4323 - acc: 0.9081 - val_loss: 0.4499 - val_acc: 0.9063\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4279 - acc: 0.9092 - val_loss: 0.4520 - val_acc: 0.9063\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4255 - acc: 0.9097 - val_loss: 0.4425 - val_acc: 0.9074\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4211 - acc: 0.9101 - val_loss: 0.4431 - val_acc: 0.9077\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4184 - acc: 0.9105 - val_loss: 0.4484 - val_acc: 0.9071\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4156 - acc: 0.9110 - val_loss: 0.4484 - val_acc: 0.9076\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4112 - acc: 0.9116 - val_loss: 0.4451 - val_acc: 0.9066\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4087 - acc: 0.9123 - val_loss: 0.4429 - val_acc: 0.9084\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4060 - acc: 0.9127 - val_loss: 0.4402 - val_acc: 0.9080\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4033 - acc: 0.9130 - val_loss: 0.4409 - val_acc: 0.9083\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3996 - acc: 0.9137 - val_loss: 0.4385 - val_acc: 0.9098\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3949 - acc: 0.9148 - val_loss: 0.4444 - val_acc: 0.9089\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3920 - acc: 0.9151 - val_loss: 0.4436 - val_acc: 0.9092\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3896 - acc: 0.9154 - val_loss: 0.4340 - val_acc: 0.9098\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3882 - acc: 0.9158 - val_loss: 0.4365 - val_acc: 0.9098\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3843 - acc: 0.9166 - val_loss: 0.4350 - val_acc: 0.9106\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3806 - acc: 0.9172 - val_loss: 0.4466 - val_acc: 0.9104\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3795 - acc: 0.9176 - val_loss: 0.4397 - val_acc: 0.9096\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3745 - acc: 0.9182 - val_loss: 0.4376 - val_acc: 0.9100\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3718 - acc: 0.9188 - val_loss: 0.4416 - val_acc: 0.9109\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3709 - acc: 0.9187 - val_loss: 0.4369 - val_acc: 0.9110\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3696 - acc: 0.9192 - val_loss: 0.4349 - val_acc: 0.9106\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.3647 - acc: 0.9198 - val_loss: 0.4382 - val_acc: 0.9106\n",
      "Epoch 52/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3631 - acc: 0.9206Restoring model weights from the end of the best epoch: 42.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3628 - acc: 0.9207 - val_loss: 0.4454 - val_acc: 0.9099\n",
      "Epoch 52: early stopping\n",
      "[0.4369122385978699, 0.4324318468570709, 0.43939173221588135, 0.41151800751686096, 0.4340335428714752]\n",
      "[62, 40, 39, 38, 42]\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 37ms/step - loss: 1.2201 - acc: 0.8425 - val_loss: 0.7723 - val_acc: 0.8635\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.8483 - acc: 0.8625 - val_loss: 0.7403 - val_acc: 0.8660\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7886 - acc: 0.8650 - val_loss: 0.7080 - val_acc: 0.8677\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7537 - acc: 0.8664 - val_loss: 0.7014 - val_acc: 0.8691\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7289 - acc: 0.8682 - val_loss: 0.6762 - val_acc: 0.8728\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7090 - acc: 0.8697 - val_loss: 0.6498 - val_acc: 0.8750\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.8539 - acc: 0.8604 - val_loss: 0.9469 - val_acc: 0.8469\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.9798 - acc: 0.8552 - val_loss: 0.7123 - val_acc: 0.8671\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7192 - acc: 0.8678 - val_loss: 0.6700 - val_acc: 0.8720\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6952 - acc: 0.8701 - val_loss: 0.6573 - val_acc: 0.8720\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6837 - acc: 0.8716 - val_loss: 0.6466 - val_acc: 0.8732\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6681 - acc: 0.8735 - val_loss: 0.6356 - val_acc: 0.8755\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6581 - acc: 0.8752 - val_loss: 0.6214 - val_acc: 0.8775\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6451 - acc: 0.8769 - val_loss: 0.6125 - val_acc: 0.8794\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6341 - acc: 0.8784 - val_loss: 0.6009 - val_acc: 0.8803\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6255 - acc: 0.8794 - val_loss: 0.6016 - val_acc: 0.8807\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6184 - acc: 0.8804 - val_loss: 0.5871 - val_acc: 0.8818\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6107 - acc: 0.8811 - val_loss: 0.5809 - val_acc: 0.8819\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6047 - acc: 0.8821 - val_loss: 0.5808 - val_acc: 0.8841\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5986 - acc: 0.8827 - val_loss: 0.5699 - val_acc: 0.8847\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5934 - acc: 0.8836 - val_loss: 0.5693 - val_acc: 0.8856\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5900 - acc: 0.8840 - val_loss: 0.5638 - val_acc: 0.8866\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5853 - acc: 0.8849 - val_loss: 0.5621 - val_acc: 0.8857\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5807 - acc: 0.8856 - val_loss: 0.5513 - val_acc: 0.8877\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5768 - acc: 0.8855 - val_loss: 0.5493 - val_acc: 0.8881\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5723 - acc: 0.8865 - val_loss: 0.5460 - val_acc: 0.8889\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5674 - acc: 0.8872 - val_loss: 0.5424 - val_acc: 0.8893\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5640 - acc: 0.8873 - val_loss: 0.5685 - val_acc: 0.8836\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5622 - acc: 0.8877 - val_loss: 0.5361 - val_acc: 0.8902\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5575 - acc: 0.8881 - val_loss: 0.5319 - val_acc: 0.8911\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5541 - acc: 0.8888 - val_loss: 0.5324 - val_acc: 0.8913\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5505 - acc: 0.8895 - val_loss: 0.5285 - val_acc: 0.8919\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5471 - acc: 0.8900 - val_loss: 0.5229 - val_acc: 0.8935\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5436 - acc: 0.8908 - val_loss: 0.5221 - val_acc: 0.8934\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5410 - acc: 0.8912 - val_loss: 0.5208 - val_acc: 0.8932\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5373 - acc: 0.8919 - val_loss: 0.5164 - val_acc: 0.8941\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5326 - acc: 0.8925 - val_loss: 0.5118 - val_acc: 0.8954\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5319 - acc: 0.8928 - val_loss: 0.5100 - val_acc: 0.8957\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5271 - acc: 0.8938 - val_loss: 0.5075 - val_acc: 0.8960\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5269 - acc: 0.8937 - val_loss: 0.5091 - val_acc: 0.8963\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5235 - acc: 0.8945 - val_loss: 0.5063 - val_acc: 0.8972\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5208 - acc: 0.8949 - val_loss: 0.5031 - val_acc: 0.8972\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5174 - acc: 0.8957 - val_loss: 0.4994 - val_acc: 0.8982\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5145 - acc: 0.8957 - val_loss: 0.4988 - val_acc: 0.8985\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5102 - acc: 0.8967 - val_loss: 0.4936 - val_acc: 0.8988\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5105 - acc: 0.8966 - val_loss: 0.4976 - val_acc: 0.8989\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5089 - acc: 0.8971 - val_loss: 0.4944 - val_acc: 0.8988\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5055 - acc: 0.8976 - val_loss: 0.4911 - val_acc: 0.8996\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5040 - acc: 0.8977 - val_loss: 0.4895 - val_acc: 0.9000\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5012 - acc: 0.8981 - val_loss: 0.4920 - val_acc: 0.8995\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4995 - acc: 0.8987 - val_loss: 0.4890 - val_acc: 0.9004\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4958 - acc: 0.8989 - val_loss: 0.4864 - val_acc: 0.9002\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4957 - acc: 0.8994 - val_loss: 0.4907 - val_acc: 0.8994\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4937 - acc: 0.8998 - val_loss: 0.4881 - val_acc: 0.9005\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4906 - acc: 0.9001 - val_loss: 0.4869 - val_acc: 0.9002\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4886 - acc: 0.9002 - val_loss: 0.4877 - val_acc: 0.9004\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4864 - acc: 0.9006 - val_loss: 0.4843 - val_acc: 0.9007\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4857 - acc: 0.9004 - val_loss: 0.4851 - val_acc: 0.9016\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4842 - acc: 0.9011 - val_loss: 0.4865 - val_acc: 0.9010\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4819 - acc: 0.9014 - val_loss: 0.4825 - val_acc: 0.9014\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4817 - acc: 0.9015 - val_loss: 0.4843 - val_acc: 0.9019\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4805 - acc: 0.9017 - val_loss: 0.4859 - val_acc: 0.9015\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4763 - acc: 0.9021 - val_loss: 0.4785 - val_acc: 0.9024\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4764 - acc: 0.9023 - val_loss: 0.4776 - val_acc: 0.9020\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4742 - acc: 0.9027 - val_loss: 0.4815 - val_acc: 0.9022\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4750 - acc: 0.9026 - val_loss: 0.4785 - val_acc: 0.9022\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4697 - acc: 0.9033 - val_loss: 0.4769 - val_acc: 0.9020\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4680 - acc: 0.9035 - val_loss: 0.4772 - val_acc: 0.9027\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4676 - acc: 0.9035 - val_loss: 0.4829 - val_acc: 0.9020\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4639 - acc: 0.9041 - val_loss: 0.4804 - val_acc: 0.9029\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4634 - acc: 0.9046 - val_loss: 0.4785 - val_acc: 0.9023\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4626 - acc: 0.9043 - val_loss: 0.4743 - val_acc: 0.9025\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4590 - acc: 0.9049 - val_loss: 0.4733 - val_acc: 0.9031\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4576 - acc: 0.9052 - val_loss: 0.4780 - val_acc: 0.9023\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4555 - acc: 0.9055 - val_loss: 0.4742 - val_acc: 0.9038\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4539 - acc: 0.9058 - val_loss: 0.4772 - val_acc: 0.9032\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4536 - acc: 0.9059 - val_loss: 0.4763 - val_acc: 0.9028\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4503 - acc: 0.9063 - val_loss: 0.4771 - val_acc: 0.9034\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4486 - acc: 0.9067 - val_loss: 0.4766 - val_acc: 0.9042\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4491 - acc: 0.9067 - val_loss: 0.4773 - val_acc: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4461 - acc: 0.9071 - val_loss: 0.4766 - val_acc: 0.9034\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4458 - acc: 0.9069 - val_loss: 0.4713 - val_acc: 0.9037\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4425 - acc: 0.9074 - val_loss: 0.4745 - val_acc: 0.9027\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4411 - acc: 0.9075 - val_loss: 0.4751 - val_acc: 0.9030\n",
      "Epoch 85/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4394 - acc: 0.9080 - val_loss: 0.4748 - val_acc: 0.9037\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4384 - acc: 0.9083 - val_loss: 0.4709 - val_acc: 0.9044\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4370 - acc: 0.9083 - val_loss: 0.4732 - val_acc: 0.9039\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4359 - acc: 0.9089 - val_loss: 0.4750 - val_acc: 0.9034\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4343 - acc: 0.9089 - val_loss: 0.4768 - val_acc: 0.9043\n",
      "Epoch 90/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4303 - acc: 0.9099 - val_loss: 0.4832 - val_acc: 0.9042\n",
      "Epoch 91/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4293 - acc: 0.9096 - val_loss: 0.4830 - val_acc: 0.9044\n",
      "Epoch 92/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4278 - acc: 0.9098 - val_loss: 0.4756 - val_acc: 0.9048\n",
      "Epoch 93/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4263 - acc: 0.9101 - val_loss: 0.4769 - val_acc: 0.9050\n",
      "Epoch 94/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4242 - acc: 0.9107 - val_loss: 0.4793 - val_acc: 0.9051\n",
      "Epoch 95/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4223 - acc: 0.9110 - val_loss: 0.4784 - val_acc: 0.9039\n",
      "Epoch 96/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4199 - acc: 0.9113Restoring model weights from the end of the best epoch: 86.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4199 - acc: 0.9113 - val_loss: 0.4771 - val_acc: 0.9050\n",
      "Epoch 96: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.2299 - acc: 0.8421 - val_loss: 0.7794 - val_acc: 0.8616\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8434 - acc: 0.8625 - val_loss: 0.7528 - val_acc: 0.8641\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7906 - acc: 0.8653 - val_loss: 0.7238 - val_acc: 0.8659\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.7581 - acc: 0.8666 - val_loss: 0.7011 - val_acc: 0.8682\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7340 - acc: 0.8677 - val_loss: 0.6838 - val_acc: 0.8697\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7114 - acc: 0.8695 - val_loss: 0.6629 - val_acc: 0.8718\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6874 - acc: 0.8719 - val_loss: 0.6361 - val_acc: 0.8751\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6618 - acc: 0.8755 - val_loss: 0.6108 - val_acc: 0.8789\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6446 - acc: 0.8779 - val_loss: 0.6058 - val_acc: 0.8800\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6301 - acc: 0.8796 - val_loss: 0.5946 - val_acc: 0.8812\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6182 - acc: 0.8812 - val_loss: 0.5801 - val_acc: 0.8832\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6081 - acc: 0.8824 - val_loss: 0.5741 - val_acc: 0.8843\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6006 - acc: 0.8831 - val_loss: 0.5637 - val_acc: 0.8871\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5917 - acc: 0.8847 - val_loss: 0.5547 - val_acc: 0.8887\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5844 - acc: 0.8854 - val_loss: 0.5471 - val_acc: 0.8884\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5774 - acc: 0.8863 - val_loss: 0.5431 - val_acc: 0.8898\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5694 - acc: 0.8874 - val_loss: 0.5424 - val_acc: 0.8902\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5642 - acc: 0.8881 - val_loss: 0.5343 - val_acc: 0.8914\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5586 - acc: 0.8891 - val_loss: 0.5301 - val_acc: 0.8920\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5540 - acc: 0.8895 - val_loss: 0.5246 - val_acc: 0.8936\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5470 - acc: 0.8915 - val_loss: 0.5155 - val_acc: 0.8956\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5440 - acc: 0.8917 - val_loss: 0.5135 - val_acc: 0.8952\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5388 - acc: 0.8926 - val_loss: 0.5144 - val_acc: 0.8955\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5348 - acc: 0.8931 - val_loss: 0.5129 - val_acc: 0.8955\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5306 - acc: 0.8940 - val_loss: 0.5089 - val_acc: 0.8954\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5273 - acc: 0.8945 - val_loss: 0.5107 - val_acc: 0.8967\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5218 - acc: 0.8954 - val_loss: 0.5027 - val_acc: 0.8972\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5202 - acc: 0.8959 - val_loss: 0.4978 - val_acc: 0.8985\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5164 - acc: 0.8964 - val_loss: 0.4985 - val_acc: 0.8983\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5151 - acc: 0.8965 - val_loss: 0.4977 - val_acc: 0.8976\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5096 - acc: 0.8977 - val_loss: 0.4932 - val_acc: 0.8987\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5078 - acc: 0.8976 - val_loss: 0.4903 - val_acc: 0.8989\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5040 - acc: 0.8982 - val_loss: 0.4885 - val_acc: 0.8996\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5014 - acc: 0.8983 - val_loss: 0.4866 - val_acc: 0.8998\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5001 - acc: 0.8986 - val_loss: 0.4904 - val_acc: 0.8998\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4980 - acc: 0.8991 - val_loss: 0.4856 - val_acc: 0.8993\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4956 - acc: 0.8997 - val_loss: 0.4833 - val_acc: 0.8998\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4912 - acc: 0.9002 - val_loss: 0.4827 - val_acc: 0.9004\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4903 - acc: 0.9002 - val_loss: 0.4917 - val_acc: 0.9004\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4879 - acc: 0.9006 - val_loss: 0.4806 - val_acc: 0.9007\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4845 - acc: 0.9013 - val_loss: 0.4790 - val_acc: 0.9017\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4838 - acc: 0.9015 - val_loss: 0.4809 - val_acc: 0.9008\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4838 - acc: 0.9015 - val_loss: 0.4820 - val_acc: 0.9011\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4794 - acc: 0.9021 - val_loss: 0.4766 - val_acc: 0.9018\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4795 - acc: 0.9022 - val_loss: 0.4755 - val_acc: 0.9019\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4766 - acc: 0.9026 - val_loss: 0.4862 - val_acc: 0.9009\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4744 - acc: 0.9031 - val_loss: 0.4765 - val_acc: 0.9014\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4716 - acc: 0.9035 - val_loss: 0.4744 - val_acc: 0.9025\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4707 - acc: 0.9033 - val_loss: 0.4766 - val_acc: 0.9009\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4682 - acc: 0.9040 - val_loss: 0.4735 - val_acc: 0.9025\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4661 - acc: 0.9044 - val_loss: 0.4729 - val_acc: 0.9019\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4651 - acc: 0.9040 - val_loss: 0.4733 - val_acc: 0.9022\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4646 - acc: 0.9048 - val_loss: 0.4730 - val_acc: 0.9035\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4611 - acc: 0.9050 - val_loss: 0.4703 - val_acc: 0.9029\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4602 - acc: 0.9053 - val_loss: 0.4710 - val_acc: 0.9029\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4577 - acc: 0.9057 - val_loss: 0.4737 - val_acc: 0.9031\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4542 - acc: 0.9061 - val_loss: 0.4684 - val_acc: 0.9032\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4543 - acc: 0.9061 - val_loss: 0.4692 - val_acc: 0.9038\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4525 - acc: 0.9068 - val_loss: 0.4747 - val_acc: 0.9033\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4502 - acc: 0.9070 - val_loss: 0.4708 - val_acc: 0.9036\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4482 - acc: 0.9072 - val_loss: 0.4715 - val_acc: 0.9031\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4454 - acc: 0.9074 - val_loss: 0.4677 - val_acc: 0.9043\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4453 - acc: 0.9076 - val_loss: 0.4702 - val_acc: 0.9036\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4425 - acc: 0.9079 - val_loss: 0.4713 - val_acc: 0.9033\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4429 - acc: 0.9081 - val_loss: 0.4693 - val_acc: 0.9051\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4389 - acc: 0.9088 - val_loss: 0.4680 - val_acc: 0.9047\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4369 - acc: 0.9090 - val_loss: 0.4754 - val_acc: 0.9043\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4354 - acc: 0.9095 - val_loss: 0.4726 - val_acc: 0.9040\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4343 - acc: 0.9091 - val_loss: 0.4790 - val_acc: 0.9053\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4321 - acc: 0.9097 - val_loss: 0.4691 - val_acc: 0.9046\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4300 - acc: 0.9098 - val_loss: 0.4714 - val_acc: 0.9048\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.4299 - acc: 0.9100Restoring model weights from the end of the best epoch: 62.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4299 - acc: 0.9100 - val_loss: 0.4723 - val_acc: 0.9034\n",
      "Epoch 72: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.1950 - acc: 0.8434 - val_loss: 0.7873 - val_acc: 0.8612\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.8361 - acc: 0.8631 - val_loss: 0.7558 - val_acc: 0.8641\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7830 - acc: 0.8657 - val_loss: 0.7144 - val_acc: 0.8667\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7487 - acc: 0.8673 - val_loss: 0.6884 - val_acc: 0.8682\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7229 - acc: 0.8687 - val_loss: 0.6695 - val_acc: 0.8702\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6998 - acc: 0.8709 - val_loss: 0.6482 - val_acc: 0.8722\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6722 - acc: 0.8741 - val_loss: 0.6157 - val_acc: 0.8775\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6512 - acc: 0.8769 - val_loss: 0.6067 - val_acc: 0.8788\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6350 - acc: 0.8791 - val_loss: 0.5968 - val_acc: 0.8814\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6223 - acc: 0.8806 - val_loss: 0.5855 - val_acc: 0.8822\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6101 - acc: 0.8821 - val_loss: 0.5719 - val_acc: 0.8842\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6002 - acc: 0.8834 - val_loss: 0.5698 - val_acc: 0.8851\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5903 - acc: 0.8850 - val_loss: 0.5644 - val_acc: 0.8859\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5815 - acc: 0.8861 - val_loss: 0.5491 - val_acc: 0.8882\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5753 - acc: 0.8870 - val_loss: 0.5411 - val_acc: 0.8903\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5667 - acc: 0.8889 - val_loss: 0.5368 - val_acc: 0.8902\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5592 - acc: 0.8902 - val_loss: 0.5321 - val_acc: 0.8930\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5540 - acc: 0.8908 - val_loss: 0.5240 - val_acc: 0.8939\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5493 - acc: 0.8915 - val_loss: 0.5219 - val_acc: 0.8933\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5443 - acc: 0.8920 - val_loss: 0.5287 - val_acc: 0.8936\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5387 - acc: 0.8933 - val_loss: 0.5173 - val_acc: 0.8939\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5369 - acc: 0.8935 - val_loss: 0.5153 - val_acc: 0.8948\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5316 - acc: 0.8943 - val_loss: 0.5128 - val_acc: 0.8949\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5297 - acc: 0.8948 - val_loss: 0.5111 - val_acc: 0.8955\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5271 - acc: 0.8952 - val_loss: 0.5033 - val_acc: 0.8970\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5213 - acc: 0.8961 - val_loss: 0.5046 - val_acc: 0.8959\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5216 - acc: 0.8960 - val_loss: 0.5005 - val_acc: 0.8974\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5197 - acc: 0.8962 - val_loss: 0.5022 - val_acc: 0.8973\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5144 - acc: 0.8974 - val_loss: 0.5023 - val_acc: 0.8970\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5126 - acc: 0.8974 - val_loss: 0.4981 - val_acc: 0.8972\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5095 - acc: 0.8981 - val_loss: 0.4958 - val_acc: 0.8976\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5065 - acc: 0.8986 - val_loss: 0.4952 - val_acc: 0.8976\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5048 - acc: 0.8985 - val_loss: 0.4921 - val_acc: 0.8987\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5012 - acc: 0.8992 - val_loss: 0.4894 - val_acc: 0.8993\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4995 - acc: 0.8996 - val_loss: 0.4901 - val_acc: 0.8987\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4987 - acc: 0.8996 - val_loss: 0.4907 - val_acc: 0.8995\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4961 - acc: 0.9003 - val_loss: 0.4904 - val_acc: 0.8994\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4950 - acc: 0.9005 - val_loss: 0.4994 - val_acc: 0.8988\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4924 - acc: 0.9009 - val_loss: 0.4851 - val_acc: 0.9003\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4915 - acc: 0.9005 - val_loss: 0.4854 - val_acc: 0.9005\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4871 - acc: 0.9015 - val_loss: 0.4848 - val_acc: 0.9008\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4850 - acc: 0.9015 - val_loss: 0.4871 - val_acc: 0.8998\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4856 - acc: 0.9015 - val_loss: 0.4834 - val_acc: 0.9012\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4831 - acc: 0.9022 - val_loss: 0.4851 - val_acc: 0.8998\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4789 - acc: 0.9026 - val_loss: 0.4854 - val_acc: 0.9004\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4793 - acc: 0.9027 - val_loss: 0.4808 - val_acc: 0.9012\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4808 - acc: 0.9026 - val_loss: 0.4812 - val_acc: 0.9008\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4749 - acc: 0.9034 - val_loss: 0.4798 - val_acc: 0.9003\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4733 - acc: 0.9038 - val_loss: 0.4819 - val_acc: 0.9004\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4741 - acc: 0.9030 - val_loss: 0.4792 - val_acc: 0.9018\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4770 - acc: 0.9028 - val_loss: 0.4852 - val_acc: 0.9014\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4714 - acc: 0.9036 - val_loss: 0.4786 - val_acc: 0.9024\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4692 - acc: 0.9043 - val_loss: 0.4820 - val_acc: 0.9017\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4689 - acc: 0.9040 - val_loss: 0.4838 - val_acc: 0.9009\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4651 - acc: 0.9047 - val_loss: 0.4769 - val_acc: 0.9017\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4630 - acc: 0.9048 - val_loss: 0.4804 - val_acc: 0.9028\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4610 - acc: 0.9056 - val_loss: 0.4793 - val_acc: 0.9026\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4607 - acc: 0.9053 - val_loss: 0.4828 - val_acc: 0.9004\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4602 - acc: 0.9054 - val_loss: 0.4752 - val_acc: 0.9021\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4607 - acc: 0.9056 - val_loss: 0.4798 - val_acc: 0.9016\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4576 - acc: 0.9058 - val_loss: 0.4794 - val_acc: 0.9028\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4554 - acc: 0.9063 - val_loss: 0.4779 - val_acc: 0.9026\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4573 - acc: 0.9063 - val_loss: 0.4769 - val_acc: 0.9021\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4529 - acc: 0.9069 - val_loss: 0.4782 - val_acc: 0.9020\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4511 - acc: 0.9071 - val_loss: 0.4778 - val_acc: 0.9026\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4494 - acc: 0.9073 - val_loss: 0.4768 - val_acc: 0.9023\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4468 - acc: 0.9075 - val_loss: 0.4748 - val_acc: 0.9022\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4467 - acc: 0.9074 - val_loss: 0.4818 - val_acc: 0.9019\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4490 - acc: 0.9075 - val_loss: 0.4777 - val_acc: 0.9031\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4463 - acc: 0.9078 - val_loss: 0.4783 - val_acc: 0.9031\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4431 - acc: 0.9084 - val_loss: 0.4761 - val_acc: 0.9039\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4416 - acc: 0.9082 - val_loss: 0.4789 - val_acc: 0.9034\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4403 - acc: 0.9088 - val_loss: 0.4759 - val_acc: 0.9035\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4419 - acc: 0.9084 - val_loss: 0.4726 - val_acc: 0.9034\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4392 - acc: 0.9089 - val_loss: 0.4782 - val_acc: 0.9023\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4444 - acc: 0.9079 - val_loss: 0.4765 - val_acc: 0.9035\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4368 - acc: 0.9092 - val_loss: 0.4735 - val_acc: 0.9034\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4363 - acc: 0.9090 - val_loss: 0.4756 - val_acc: 0.9037\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4349 - acc: 0.9095 - val_loss: 0.4804 - val_acc: 0.9039\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4332 - acc: 0.9095 - val_loss: 0.4750 - val_acc: 0.9034\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4315 - acc: 0.9100 - val_loss: 0.4755 - val_acc: 0.9038\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4306 - acc: 0.9101 - val_loss: 0.4726 - val_acc: 0.9038\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4287 - acc: 0.9106 - val_loss: 0.4799 - val_acc: 0.9042\n",
      "Epoch 84/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4283 - acc: 0.9103Restoring model weights from the end of the best epoch: 74.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4278 - acc: 0.9103 - val_loss: 0.4766 - val_acc: 0.9037\n",
      "Epoch 84: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.2147 - acc: 0.8408 - val_loss: 0.7556 - val_acc: 0.8677\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8500 - acc: 0.8605 - val_loss: 0.7261 - val_acc: 0.8684\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.8036 - acc: 0.8631 - val_loss: 0.7059 - val_acc: 0.8716\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7708 - acc: 0.8647 - val_loss: 0.6711 - val_acc: 0.8738\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7415 - acc: 0.8662 - val_loss: 0.6540 - val_acc: 0.8754\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7196 - acc: 0.8677 - val_loss: 0.6375 - val_acc: 0.8766\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7020 - acc: 0.8692 - val_loss: 0.6212 - val_acc: 0.8796\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6841 - acc: 0.8713 - val_loss: 0.6116 - val_acc: 0.8792\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6628 - acc: 0.8751 - val_loss: 0.5814 - val_acc: 0.8852\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6450 - acc: 0.8773 - val_loss: 0.5701 - val_acc: 0.8866\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6333 - acc: 0.8790 - val_loss: 0.5613 - val_acc: 0.8881\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6186 - acc: 0.8808 - val_loss: 0.5531 - val_acc: 0.8897\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6098 - acc: 0.8819 - val_loss: 0.5475 - val_acc: 0.8899\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6029 - acc: 0.8824 - val_loss: 0.5347 - val_acc: 0.8905\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5943 - acc: 0.8835 - val_loss: 0.5383 - val_acc: 0.8909\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5854 - acc: 0.8846 - val_loss: 0.5239 - val_acc: 0.8934\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5791 - acc: 0.8850 - val_loss: 0.5242 - val_acc: 0.8929\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5726 - acc: 0.8859 - val_loss: 0.5164 - val_acc: 0.8941\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5685 - acc: 0.8868 - val_loss: 0.5094 - val_acc: 0.8953\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5633 - acc: 0.8871 - val_loss: 0.5047 - val_acc: 0.8956\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5565 - acc: 0.8882 - val_loss: 0.5005 - val_acc: 0.8971\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5545 - acc: 0.8885 - val_loss: 0.5033 - val_acc: 0.8962\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5497 - acc: 0.8894 - val_loss: 0.4915 - val_acc: 0.8983\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5443 - acc: 0.8899 - val_loss: 0.4912 - val_acc: 0.8992\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5421 - acc: 0.8906 - val_loss: 0.4914 - val_acc: 0.8973\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5372 - acc: 0.8915 - val_loss: 0.4882 - val_acc: 0.8994\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5340 - acc: 0.8921 - val_loss: 0.4807 - val_acc: 0.9008\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5292 - acc: 0.8928 - val_loss: 0.4841 - val_acc: 0.8993\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5274 - acc: 0.8932 - val_loss: 0.4843 - val_acc: 0.8999\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5251 - acc: 0.8934 - val_loss: 0.4752 - val_acc: 0.9014\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5215 - acc: 0.8944 - val_loss: 0.4738 - val_acc: 0.9030\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5173 - acc: 0.8948 - val_loss: 0.4739 - val_acc: 0.9026\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5144 - acc: 0.8956 - val_loss: 0.4714 - val_acc: 0.9033\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5136 - acc: 0.8955 - val_loss: 0.4717 - val_acc: 0.9024\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5111 - acc: 0.8965 - val_loss: 0.4742 - val_acc: 0.9035\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5104 - acc: 0.8964 - val_loss: 0.4688 - val_acc: 0.9036\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5047 - acc: 0.8974 - val_loss: 0.4689 - val_acc: 0.9031\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5031 - acc: 0.8979 - val_loss: 0.4636 - val_acc: 0.9046\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5030 - acc: 0.8975 - val_loss: 0.4646 - val_acc: 0.9044\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4998 - acc: 0.8986 - val_loss: 0.4640 - val_acc: 0.9049\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4981 - acc: 0.8985 - val_loss: 0.4635 - val_acc: 0.9054\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4950 - acc: 0.8995 - val_loss: 0.4624 - val_acc: 0.9052\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4931 - acc: 0.8993 - val_loss: 0.4608 - val_acc: 0.9054\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4903 - acc: 0.8999 - val_loss: 0.4627 - val_acc: 0.9057\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4889 - acc: 0.9005 - val_loss: 0.4613 - val_acc: 0.9052\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4883 - acc: 0.9002 - val_loss: 0.4590 - val_acc: 0.9055\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4844 - acc: 0.9008 - val_loss: 0.4612 - val_acc: 0.9059\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4855 - acc: 0.9010 - val_loss: 0.4615 - val_acc: 0.9057\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4813 - acc: 0.9011 - val_loss: 0.4575 - val_acc: 0.9069\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4816 - acc: 0.9015 - val_loss: 0.4600 - val_acc: 0.9058\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4777 - acc: 0.9023 - val_loss: 0.4547 - val_acc: 0.9070\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4777 - acc: 0.9022 - val_loss: 0.4559 - val_acc: 0.9062\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4739 - acc: 0.9026 - val_loss: 0.4636 - val_acc: 0.9047\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4729 - acc: 0.9027 - val_loss: 0.4553 - val_acc: 0.9062\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4720 - acc: 0.9032 - val_loss: 0.4659 - val_acc: 0.9061\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4690 - acc: 0.9031 - val_loss: 0.4549 - val_acc: 0.9069\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4676 - acc: 0.9037 - val_loss: 0.4518 - val_acc: 0.9074\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4681 - acc: 0.9036 - val_loss: 0.4562 - val_acc: 0.9070\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4639 - acc: 0.9045 - val_loss: 0.4563 - val_acc: 0.9070\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4650 - acc: 0.9042 - val_loss: 0.4510 - val_acc: 0.9081\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4624 - acc: 0.9048 - val_loss: 0.4552 - val_acc: 0.9072\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4588 - acc: 0.9055 - val_loss: 0.4517 - val_acc: 0.9075\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4590 - acc: 0.9050 - val_loss: 0.4499 - val_acc: 0.9077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4552 - acc: 0.9057 - val_loss: 0.4496 - val_acc: 0.9075\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4548 - acc: 0.9056 - val_loss: 0.4501 - val_acc: 0.9084\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4528 - acc: 0.9059 - val_loss: 0.4499 - val_acc: 0.9080\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4533 - acc: 0.9060 - val_loss: 0.4548 - val_acc: 0.9082\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4504 - acc: 0.9069 - val_loss: 0.4489 - val_acc: 0.9088\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4469 - acc: 0.9072 - val_loss: 0.4502 - val_acc: 0.9084\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4463 - acc: 0.9074 - val_loss: 0.4525 - val_acc: 0.9083\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4454 - acc: 0.9074 - val_loss: 0.4492 - val_acc: 0.9086\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4459 - acc: 0.9074 - val_loss: 0.4522 - val_acc: 0.9081\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4425 - acc: 0.9080 - val_loss: 0.4542 - val_acc: 0.9090\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4403 - acc: 0.9082 - val_loss: 0.4541 - val_acc: 0.9094\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4392 - acc: 0.9084 - val_loss: 0.4538 - val_acc: 0.9096\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4367 - acc: 0.9088 - val_loss: 0.4567 - val_acc: 0.9090\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4343 - acc: 0.9093 - val_loss: 0.4533 - val_acc: 0.9095\n",
      "Epoch 78/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4352 - acc: 0.9090Restoring model weights from the end of the best epoch: 68.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4352 - acc: 0.9089 - val_loss: 0.4565 - val_acc: 0.9095\n",
      "Epoch 78: early stopping\n",
      "Current Latent Dim: 512\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.2082 - acc: 0.8424 - val_loss: 0.7753 - val_acc: 0.8628\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.8387 - acc: 0.8626 - val_loss: 0.7383 - val_acc: 0.8654\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7875 - acc: 0.8650 - val_loss: 0.7165 - val_acc: 0.8663\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7539 - acc: 0.8666 - val_loss: 0.6943 - val_acc: 0.8696\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7277 - acc: 0.8681 - val_loss: 0.6653 - val_acc: 0.8733\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7058 - acc: 0.8697 - val_loss: 0.6449 - val_acc: 0.8744\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6866 - acc: 0.8713 - val_loss: 0.6416 - val_acc: 0.8737\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6710 - acc: 0.8734 - val_loss: 0.6164 - val_acc: 0.8781\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6526 - acc: 0.8763 - val_loss: 0.6015 - val_acc: 0.8816\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6333 - acc: 0.8792 - val_loss: 0.5825 - val_acc: 0.8839\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6185 - acc: 0.8811 - val_loss: 0.5731 - val_acc: 0.8856\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6067 - acc: 0.8826 - val_loss: 0.5641 - val_acc: 0.8870\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5984 - acc: 0.8837 - val_loss: 0.5544 - val_acc: 0.8883\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5890 - acc: 0.8850 - val_loss: 0.5528 - val_acc: 0.8887\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.8053 - acc: 0.8612 - val_loss: 0.6652 - val_acc: 0.8692\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6613 - acc: 0.8726 - val_loss: 0.5958 - val_acc: 0.8798\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.6166 - acc: 0.8800 - val_loss: 0.5726 - val_acc: 0.8848\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5984 - acc: 0.8827 - val_loss: 0.5578 - val_acc: 0.8873\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5853 - acc: 0.8841 - val_loss: 0.5481 - val_acc: 0.8891\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5783 - acc: 0.8856 - val_loss: 0.5424 - val_acc: 0.8901\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5711 - acc: 0.8866 - val_loss: 0.5413 - val_acc: 0.8903\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5641 - acc: 0.8879 - val_loss: 0.5310 - val_acc: 0.8925\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5618 - acc: 0.8885 - val_loss: 0.5272 - val_acc: 0.8934\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5558 - acc: 0.8894 - val_loss: 0.5243 - val_acc: 0.8939\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5516 - acc: 0.8902 - val_loss: 0.5232 - val_acc: 0.8944\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5487 - acc: 0.8906 - val_loss: 0.5226 - val_acc: 0.8943\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5461 - acc: 0.8909 - val_loss: 0.5170 - val_acc: 0.8944\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5428 - acc: 0.8916 - val_loss: 0.5120 - val_acc: 0.8968\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5371 - acc: 0.8925 - val_loss: 0.5115 - val_acc: 0.8965\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5364 - acc: 0.8929 - val_loss: 0.5126 - val_acc: 0.8960\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5415 - acc: 0.8920 - val_loss: 0.5563 - val_acc: 0.8887\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5424 - acc: 0.8914 - val_loss: 0.5156 - val_acc: 0.8957\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5314 - acc: 0.8935 - val_loss: 0.5071 - val_acc: 0.8968\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5259 - acc: 0.8945 - val_loss: 0.5031 - val_acc: 0.8979\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5241 - acc: 0.8945 - val_loss: 0.5080 - val_acc: 0.8973\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5227 - acc: 0.8948 - val_loss: 0.5042 - val_acc: 0.8971\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5227 - acc: 0.8952 - val_loss: 0.4996 - val_acc: 0.8977\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5202 - acc: 0.8958 - val_loss: 0.4998 - val_acc: 0.8980\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5191 - acc: 0.8956 - val_loss: 0.4979 - val_acc: 0.8988\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5202 - acc: 0.8955 - val_loss: 0.4988 - val_acc: 0.8989\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5154 - acc: 0.8965 - val_loss: 0.5024 - val_acc: 0.8975\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5120 - acc: 0.8966 - val_loss: 0.4961 - val_acc: 0.8985\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5106 - acc: 0.8970 - val_loss: 0.4946 - val_acc: 0.8994\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5083 - acc: 0.8971 - val_loss: 0.4949 - val_acc: 0.8988\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5066 - acc: 0.8976 - val_loss: 0.4960 - val_acc: 0.8982\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5054 - acc: 0.8976 - val_loss: 0.4932 - val_acc: 0.8997\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5044 - acc: 0.8978 - val_loss: 0.4941 - val_acc: 0.8997\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.5028 - acc: 0.8981 - val_loss: 0.4929 - val_acc: 0.9000\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4994 - acc: 0.8985 - val_loss: 0.4912 - val_acc: 0.8997\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5028 - acc: 0.8979 - val_loss: 0.4896 - val_acc: 0.9003\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4990 - acc: 0.8985 - val_loss: 0.4891 - val_acc: 0.9006\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4982 - acc: 0.8991 - val_loss: 0.4846 - val_acc: 0.9011\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4936 - acc: 0.8992 - val_loss: 0.4850 - val_acc: 0.9012\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4926 - acc: 0.8996 - val_loss: 0.4853 - val_acc: 0.9021\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4893 - acc: 0.9002 - val_loss: 0.4863 - val_acc: 0.9012\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4901 - acc: 0.8998 - val_loss: 0.4889 - val_acc: 0.9009\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4904 - acc: 0.8998 - val_loss: 0.4875 - val_acc: 0.9010\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4891 - acc: 0.8999 - val_loss: 0.4837 - val_acc: 0.9015\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4861 - acc: 0.9006 - val_loss: 0.4814 - val_acc: 0.9021\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4839 - acc: 0.9010 - val_loss: 0.4820 - val_acc: 0.9017\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4835 - acc: 0.9010 - val_loss: 0.4782 - val_acc: 0.9016\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4831 - acc: 0.9011 - val_loss: 0.4793 - val_acc: 0.9028\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4819 - acc: 0.9012 - val_loss: 0.4853 - val_acc: 0.9012\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4815 - acc: 0.9016 - val_loss: 0.4811 - val_acc: 0.9008\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4791 - acc: 0.9019 - val_loss: 0.4785 - val_acc: 0.9025\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4764 - acc: 0.9024 - val_loss: 0.4796 - val_acc: 0.9021\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4748 - acc: 0.9024 - val_loss: 0.4870 - val_acc: 0.9010\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4760 - acc: 0.9021 - val_loss: 0.4806 - val_acc: 0.9020\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4741 - acc: 0.9029 - val_loss: 0.4779 - val_acc: 0.9023\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4730 - acc: 0.9027 - val_loss: 0.4766 - val_acc: 0.9028\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4693 - acc: 0.9034 - val_loss: 0.4764 - val_acc: 0.9028\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4717 - acc: 0.9030 - val_loss: 0.4755 - val_acc: 0.9028\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4679 - acc: 0.9036 - val_loss: 0.4736 - val_acc: 0.9038\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4647 - acc: 0.9042 - val_loss: 0.4849 - val_acc: 0.9032\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4679 - acc: 0.9032 - val_loss: 0.4767 - val_acc: 0.9035\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4667 - acc: 0.9035 - val_loss: 0.4735 - val_acc: 0.9034\n",
      "Epoch 77/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4650 - acc: 0.9042 - val_loss: 0.4765 - val_acc: 0.9031\n",
      "Epoch 78/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4626 - acc: 0.9044 - val_loss: 0.4725 - val_acc: 0.9038\n",
      "Epoch 79/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4596 - acc: 0.9045 - val_loss: 0.4720 - val_acc: 0.9039\n",
      "Epoch 80/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4591 - acc: 0.9049 - val_loss: 0.4775 - val_acc: 0.9023\n",
      "Epoch 81/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4592 - acc: 0.9048 - val_loss: 0.4730 - val_acc: 0.9039\n",
      "Epoch 82/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4580 - acc: 0.9050 - val_loss: 0.4763 - val_acc: 0.9033\n",
      "Epoch 83/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4581 - acc: 0.9050 - val_loss: 0.4723 - val_acc: 0.9046\n",
      "Epoch 84/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4552 - acc: 0.9055 - val_loss: 0.4720 - val_acc: 0.9046\n",
      "Epoch 85/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4559 - acc: 0.9056 - val_loss: 0.4745 - val_acc: 0.9037\n",
      "Epoch 86/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4554 - acc: 0.9059 - val_loss: 0.4722 - val_acc: 0.9043\n",
      "Epoch 87/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4544 - acc: 0.9061 - val_loss: 0.4682 - val_acc: 0.9051\n",
      "Epoch 88/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4538 - acc: 0.9060 - val_loss: 0.4734 - val_acc: 0.9048\n",
      "Epoch 89/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4510 - acc: 0.9065 - val_loss: 0.4750 - val_acc: 0.9045\n",
      "Epoch 90/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4502 - acc: 0.9064 - val_loss: 0.4722 - val_acc: 0.9049\n",
      "Epoch 91/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4497 - acc: 0.9067 - val_loss: 0.4702 - val_acc: 0.9046\n",
      "Epoch 92/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4503 - acc: 0.9064 - val_loss: 0.4696 - val_acc: 0.9044\n",
      "Epoch 93/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4481 - acc: 0.9071 - val_loss: 0.4734 - val_acc: 0.9045\n",
      "Epoch 94/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4468 - acc: 0.9073 - val_loss: 0.4681 - val_acc: 0.9047\n",
      "Epoch 95/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4467 - acc: 0.9072 - val_loss: 0.4702 - val_acc: 0.9045\n",
      "Epoch 96/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4455 - acc: 0.9074 - val_loss: 0.4692 - val_acc: 0.9043\n",
      "Epoch 97/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4437 - acc: 0.9079 - val_loss: 0.4753 - val_acc: 0.9055\n",
      "Epoch 98/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4420 - acc: 0.9077 - val_loss: 0.4722 - val_acc: 0.9052\n",
      "Epoch 99/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4409 - acc: 0.9082 - val_loss: 0.4701 - val_acc: 0.9049\n",
      "Epoch 100/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4417 - acc: 0.9078 - val_loss: 0.4700 - val_acc: 0.9047\n",
      "Epoch 101/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4393 - acc: 0.9084 - val_loss: 0.4667 - val_acc: 0.9053\n",
      "Epoch 102/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4399 - acc: 0.9080 - val_loss: 0.4698 - val_acc: 0.9050\n",
      "Epoch 103/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4402 - acc: 0.9081 - val_loss: 0.4726 - val_acc: 0.9052\n",
      "Epoch 104/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4366 - acc: 0.9087 - val_loss: 0.4748 - val_acc: 0.9052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4361 - acc: 0.9086 - val_loss: 0.4719 - val_acc: 0.9058\n",
      "Epoch 106/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4322 - acc: 0.9094 - val_loss: 0.4726 - val_acc: 0.9056\n",
      "Epoch 107/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4329 - acc: 0.9092 - val_loss: 0.4732 - val_acc: 0.9054\n",
      "Epoch 108/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4325 - acc: 0.9095 - val_loss: 0.4715 - val_acc: 0.9057\n",
      "Epoch 109/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4337 - acc: 0.9091 - val_loss: 0.4702 - val_acc: 0.9052\n",
      "Epoch 110/200\n",
      "191/191 [==============================] - 3s 16ms/step - loss: 0.4333 - acc: 0.9091 - val_loss: 0.4722 - val_acc: 0.9046\n",
      "Epoch 111/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4326 - acc: 0.9096Restoring model weights from the end of the best epoch: 101.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4321 - acc: 0.9097 - val_loss: 0.4696 - val_acc: 0.9055\n",
      "Epoch 111: early stopping\n",
      "[0.47087183594703674, 0.46773046255111694, 0.47255939245224, 0.4489382207393646, 0.4666871428489685]\n",
      "[86, 62, 74, 68, 101]\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9119 - acc: 0.8503 - val_loss: 0.7389 - val_acc: 0.8661\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7423 - acc: 0.8667 - val_loss: 0.6693 - val_acc: 0.8725\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6603 - acc: 0.8755 - val_loss: 0.5935 - val_acc: 0.8834\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5907 - acc: 0.8851 - val_loss: 0.5348 - val_acc: 0.8929\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5465 - acc: 0.8912 - val_loss: 0.5188 - val_acc: 0.8953\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5172 - acc: 0.8952 - val_loss: 0.4939 - val_acc: 0.8986\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4952 - acc: 0.8984 - val_loss: 0.4748 - val_acc: 0.9017\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4754 - acc: 0.9008 - val_loss: 0.4619 - val_acc: 0.9036\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4589 - acc: 0.9034 - val_loss: 0.4557 - val_acc: 0.9049\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4446 - acc: 0.9053 - val_loss: 0.4539 - val_acc: 0.9042\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4302 - acc: 0.9074 - val_loss: 0.4401 - val_acc: 0.9074\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4161 - acc: 0.9093 - val_loss: 0.4375 - val_acc: 0.9076\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4112 - acc: 0.9102 - val_loss: 0.4314 - val_acc: 0.9071\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3951 - acc: 0.9127 - val_loss: 0.4211 - val_acc: 0.9104\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3812 - acc: 0.9147 - val_loss: 0.4170 - val_acc: 0.9114\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3708 - acc: 0.9161 - val_loss: 0.4131 - val_acc: 0.9123\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3611 - acc: 0.9177 - val_loss: 0.4145 - val_acc: 0.9125\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3535 - acc: 0.9190 - val_loss: 0.4125 - val_acc: 0.9119\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3408 - acc: 0.9210 - val_loss: 0.4148 - val_acc: 0.9124\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3349 - acc: 0.9222 - val_loss: 0.4114 - val_acc: 0.9134\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3257 - acc: 0.9235 - val_loss: 0.4120 - val_acc: 0.9141\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3158 - acc: 0.9250 - val_loss: 0.4180 - val_acc: 0.9132\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3086 - acc: 0.9258 - val_loss: 0.4258 - val_acc: 0.9129\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2995 - acc: 0.9277 - val_loss: 0.4195 - val_acc: 0.9135\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2921 - acc: 0.9291 - val_loss: 0.4270 - val_acc: 0.9141\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2844 - acc: 0.9302 - val_loss: 0.4274 - val_acc: 0.9143\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2801 - acc: 0.9311 - val_loss: 0.4266 - val_acc: 0.9133\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2681 - acc: 0.9332 - val_loss: 0.4406 - val_acc: 0.9137\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2592 - acc: 0.9351 - val_loss: 0.4390 - val_acc: 0.9128\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2523 - acc: 0.9363Restoring model weights from the end of the best epoch: 20.\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.2523 - acc: 0.9363 - val_loss: 0.4445 - val_acc: 0.9124\n",
      "Epoch 30: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 37ms/step - loss: 0.9114 - acc: 0.8515 - val_loss: 0.7478 - val_acc: 0.8633\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7410 - acc: 0.8669 - val_loss: 0.6784 - val_acc: 0.8706\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6729 - acc: 0.8735 - val_loss: 0.6196 - val_acc: 0.8784\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6091 - acc: 0.8821 - val_loss: 0.5569 - val_acc: 0.8874\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5590 - acc: 0.8882 - val_loss: 0.5233 - val_acc: 0.8933\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5318 - acc: 0.8925 - val_loss: 0.5115 - val_acc: 0.8940\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5072 - acc: 0.8964 - val_loss: 0.4925 - val_acc: 0.8976\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4903 - acc: 0.8989 - val_loss: 0.4797 - val_acc: 0.9005\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4733 - acc: 0.9014 - val_loss: 0.4701 - val_acc: 0.9013\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4578 - acc: 0.9034 - val_loss: 0.4609 - val_acc: 0.9030\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4443 - acc: 0.9053 - val_loss: 0.4514 - val_acc: 0.9051\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4342 - acc: 0.9069 - val_loss: 0.4538 - val_acc: 0.9039\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4202 - acc: 0.9087 - val_loss: 0.4352 - val_acc: 0.9072\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4100 - acc: 0.9101 - val_loss: 0.4331 - val_acc: 0.9076\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3991 - acc: 0.9119 - val_loss: 0.4310 - val_acc: 0.9082\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3878 - acc: 0.9135 - val_loss: 0.4253 - val_acc: 0.9090\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3789 - acc: 0.9148 - val_loss: 0.4214 - val_acc: 0.9091\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3695 - acc: 0.9164 - val_loss: 0.4200 - val_acc: 0.9114\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3595 - acc: 0.9181 - val_loss: 0.4257 - val_acc: 0.9095\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3489 - acc: 0.9198 - val_loss: 0.4207 - val_acc: 0.9107\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3406 - acc: 0.9212 - val_loss: 0.4157 - val_acc: 0.9118\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3334 - acc: 0.9220 - val_loss: 0.4187 - val_acc: 0.9124\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3244 - acc: 0.9238 - val_loss: 0.4181 - val_acc: 0.9127\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3164 - acc: 0.9253 - val_loss: 0.4179 - val_acc: 0.9114\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3081 - acc: 0.9264 - val_loss: 0.4244 - val_acc: 0.9132\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3002 - acc: 0.9279 - val_loss: 0.4266 - val_acc: 0.9122\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2904 - acc: 0.9297 - val_loss: 0.4263 - val_acc: 0.9132\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2859 - acc: 0.9301 - val_loss: 0.4322 - val_acc: 0.9126\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2783 - acc: 0.9314 - val_loss: 0.4325 - val_acc: 0.9117\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2674 - acc: 0.9337 - val_loss: 0.4301 - val_acc: 0.9127\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2645 - acc: 0.9336Restoring model weights from the end of the best epoch: 21.\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.2645 - acc: 0.9336 - val_loss: 0.4375 - val_acc: 0.9126\n",
      "Epoch 31: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 37ms/step - loss: 0.9278 - acc: 0.8514 - val_loss: 0.7528 - val_acc: 0.8621\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7527 - acc: 0.8663 - val_loss: 0.6930 - val_acc: 0.8701\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6849 - acc: 0.8726 - val_loss: 0.6638 - val_acc: 0.8707\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6225 - acc: 0.8807 - val_loss: 0.5869 - val_acc: 0.8838\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5652 - acc: 0.8880 - val_loss: 0.5355 - val_acc: 0.8918\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5300 - acc: 0.8938 - val_loss: 0.5181 - val_acc: 0.8939\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5067 - acc: 0.8969 - val_loss: 0.4965 - val_acc: 0.8970\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4877 - acc: 0.8994 - val_loss: 0.4832 - val_acc: 0.8990\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4696 - acc: 0.9020 - val_loss: 0.4762 - val_acc: 0.9011\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4560 - acc: 0.9042 - val_loss: 0.4574 - val_acc: 0.9031\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6418 - acc: 0.8795 - val_loss: 0.6992 - val_acc: 0.8681\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5566 - acc: 0.8862 - val_loss: 0.4877 - val_acc: 0.8976\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4593 - acc: 0.9025 - val_loss: 0.4560 - val_acc: 0.9030\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4362 - acc: 0.9061 - val_loss: 0.4468 - val_acc: 0.9047\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4214 - acc: 0.9084 - val_loss: 0.4449 - val_acc: 0.9056\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4109 - acc: 0.9102 - val_loss: 0.4414 - val_acc: 0.9059\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4025 - acc: 0.9112 - val_loss: 0.4360 - val_acc: 0.9064\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3929 - acc: 0.9125 - val_loss: 0.4391 - val_acc: 0.9048\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3884 - acc: 0.9134 - val_loss: 0.4337 - val_acc: 0.9071\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3811 - acc: 0.9147 - val_loss: 0.4337 - val_acc: 0.9067\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3738 - acc: 0.9154 - val_loss: 0.4364 - val_acc: 0.9056\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3679 - acc: 0.9163 - val_loss: 0.4294 - val_acc: 0.9084\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3603 - acc: 0.9175 - val_loss: 0.4251 - val_acc: 0.9092\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3536 - acc: 0.9186 - val_loss: 0.4254 - val_acc: 0.9096\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3491 - acc: 0.9194 - val_loss: 0.4236 - val_acc: 0.9094\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3401 - acc: 0.9210 - val_loss: 0.4308 - val_acc: 0.9094\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3322 - acc: 0.9220 - val_loss: 0.4264 - val_acc: 0.9093\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3282 - acc: 0.9229 - val_loss: 0.4255 - val_acc: 0.9109\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3228 - acc: 0.9233 - val_loss: 0.4258 - val_acc: 0.9108\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3136 - acc: 0.9249 - val_loss: 0.4329 - val_acc: 0.9087\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3082 - acc: 0.9258 - val_loss: 0.4278 - val_acc: 0.9108\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3011 - acc: 0.9274 - val_loss: 0.4390 - val_acc: 0.9088\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2940 - acc: 0.9284 - val_loss: 0.4336 - val_acc: 0.9113\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2863 - acc: 0.9298 - val_loss: 0.4371 - val_acc: 0.9113\n",
      "Epoch 35/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2796 - acc: 0.9312Restoring model weights from the end of the best epoch: 25.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2804 - acc: 0.9310 - val_loss: 0.4432 - val_acc: 0.9108\n",
      "Epoch 35: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9100 - acc: 0.8505 - val_loss: 0.7154 - val_acc: 0.8709\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7369 - acc: 0.8661 - val_loss: 0.6338 - val_acc: 0.8790\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6603 - acc: 0.8746 - val_loss: 0.5724 - val_acc: 0.8862\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5936 - acc: 0.8835 - val_loss: 0.5247 - val_acc: 0.8940\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5536 - acc: 0.8894 - val_loss: 0.4942 - val_acc: 0.8986\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5209 - acc: 0.8945 - val_loss: 0.4832 - val_acc: 0.9000\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4978 - acc: 0.8977 - val_loss: 0.4563 - val_acc: 0.9057\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4812 - acc: 0.9002 - val_loss: 0.4435 - val_acc: 0.9071\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4631 - acc: 0.9026 - val_loss: 0.4412 - val_acc: 0.9079\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4496 - acc: 0.9042 - val_loss: 0.4264 - val_acc: 0.9094\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4345 - acc: 0.9064 - val_loss: 0.4227 - val_acc: 0.9100\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4251 - acc: 0.9075 - val_loss: 0.4168 - val_acc: 0.9113\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4196 - acc: 0.9084 - val_loss: 0.5022 - val_acc: 0.8951\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4149 - acc: 0.9084 - val_loss: 0.4128 - val_acc: 0.9125\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3917 - acc: 0.9124 - val_loss: 0.4019 - val_acc: 0.9143\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3800 - acc: 0.9141 - val_loss: 0.4012 - val_acc: 0.9147\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3704 - acc: 0.9160 - val_loss: 0.4029 - val_acc: 0.9139\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3607 - acc: 0.9174 - val_loss: 0.4049 - val_acc: 0.9156\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3519 - acc: 0.9186 - val_loss: 0.3995 - val_acc: 0.9160\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3436 - acc: 0.9204 - val_loss: 0.4007 - val_acc: 0.9146\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3353 - acc: 0.9212 - val_loss: 0.3992 - val_acc: 0.9161\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3260 - acc: 0.9232 - val_loss: 0.3999 - val_acc: 0.9152\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3170 - acc: 0.9244 - val_loss: 0.3957 - val_acc: 0.9173\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3096 - acc: 0.9259 - val_loss: 0.4018 - val_acc: 0.9167\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3009 - acc: 0.9271 - val_loss: 0.4014 - val_acc: 0.9173\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.2941 - acc: 0.9285 - val_loss: 0.4037 - val_acc: 0.9168\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2851 - acc: 0.9300 - val_loss: 0.4065 - val_acc: 0.9173\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2775 - acc: 0.9315 - val_loss: 0.4107 - val_acc: 0.9171\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2687 - acc: 0.9332 - val_loss: 0.4115 - val_acc: 0.9177\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2625 - acc: 0.9341 - val_loss: 0.4223 - val_acc: 0.9150\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2556 - acc: 0.9357 - val_loss: 0.4222 - val_acc: 0.9177\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2463 - acc: 0.9374 - val_loss: 0.4251 - val_acc: 0.9168\n",
      "Epoch 33/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2407 - acc: 0.9383Restoring model weights from the end of the best epoch: 23.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2405 - acc: 0.9383 - val_loss: 0.4281 - val_acc: 0.9150\n",
      "Epoch 33: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.5\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9129 - acc: 0.8513 - val_loss: 0.7428 - val_acc: 0.8653\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7518 - acc: 0.8656 - val_loss: 0.6857 - val_acc: 0.8715\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6764 - acc: 0.8736 - val_loss: 0.6105 - val_acc: 0.8821\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6021 - acc: 0.8830 - val_loss: 0.5511 - val_acc: 0.8913\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5527 - acc: 0.8900 - val_loss: 0.5186 - val_acc: 0.8965\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5219 - acc: 0.8945 - val_loss: 0.5052 - val_acc: 0.8980\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4998 - acc: 0.8979 - val_loss: 0.4856 - val_acc: 0.9004\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4967 - acc: 0.8976 - val_loss: 0.5108 - val_acc: 0.8952\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4731 - acc: 0.9009 - val_loss: 0.4661 - val_acc: 0.9032\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4512 - acc: 0.9044 - val_loss: 0.4524 - val_acc: 0.9051\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4378 - acc: 0.9065 - val_loss: 0.4485 - val_acc: 0.9059\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4275 - acc: 0.9074 - val_loss: 0.4449 - val_acc: 0.9072\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4147 - acc: 0.9095 - val_loss: 0.4426 - val_acc: 0.9062\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4054 - acc: 0.9107 - val_loss: 0.4391 - val_acc: 0.9075\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3942 - acc: 0.9123 - val_loss: 0.4326 - val_acc: 0.9084\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3857 - acc: 0.9135 - val_loss: 0.4285 - val_acc: 0.9094\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3747 - acc: 0.9152 - val_loss: 0.4224 - val_acc: 0.9099\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3669 - acc: 0.9167 - val_loss: 0.4261 - val_acc: 0.9107\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3553 - acc: 0.9182 - val_loss: 0.4223 - val_acc: 0.9107\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3483 - acc: 0.9194 - val_loss: 0.4217 - val_acc: 0.9108\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3392 - acc: 0.9209 - val_loss: 0.4209 - val_acc: 0.9122\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3303 - acc: 0.9222 - val_loss: 0.4236 - val_acc: 0.9124\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3220 - acc: 0.9239 - val_loss: 0.4214 - val_acc: 0.9132\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3134 - acc: 0.9253 - val_loss: 0.4251 - val_acc: 0.9115\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3066 - acc: 0.9267 - val_loss: 0.4266 - val_acc: 0.9127\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2973 - acc: 0.9278 - val_loss: 0.4249 - val_acc: 0.9131\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.2893 - acc: 0.9292 - val_loss: 0.4308 - val_acc: 0.9127\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2838 - acc: 0.9306 - val_loss: 0.4273 - val_acc: 0.9128\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2748 - acc: 0.9319 - val_loss: 0.4302 - val_acc: 0.9135\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2679 - acc: 0.9335 - val_loss: 0.4359 - val_acc: 0.9131\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2591 - acc: 0.9351Restoring model weights from the end of the best epoch: 21.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2591 - acc: 0.9351 - val_loss: 0.4479 - val_acc: 0.9123\n",
      "Epoch 31: early stopping\n",
      "[0.41135546565055847, 0.4157479703426361, 0.42363405227661133, 0.3956533670425415, 0.42085331678390503]\n",
      "[20, 21, 25, 23, 21]\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 0.9393 - acc: 0.8507 - val_loss: 0.7359 - val_acc: 0.8668\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7491 - acc: 0.8663 - val_loss: 0.6823 - val_acc: 0.8711\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6913 - acc: 0.8705 - val_loss: 0.6373 - val_acc: 0.8762\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6384 - acc: 0.8779 - val_loss: 0.5814 - val_acc: 0.8846\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5872 - acc: 0.8854 - val_loss: 0.5485 - val_acc: 0.8902\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5511 - acc: 0.8910 - val_loss: 0.5141 - val_acc: 0.8964\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5265 - acc: 0.8942 - val_loss: 0.4976 - val_acc: 0.8979\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5062 - acc: 0.8972 - val_loss: 0.4787 - val_acc: 0.9011\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4907 - acc: 0.8995 - val_loss: 0.4697 - val_acc: 0.9013\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4766 - acc: 0.9015 - val_loss: 0.4593 - val_acc: 0.9040\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4622 - acc: 0.9033 - val_loss: 0.4589 - val_acc: 0.9042\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4526 - acc: 0.9050 - val_loss: 0.4473 - val_acc: 0.9063\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4408 - acc: 0.9064 - val_loss: 0.4457 - val_acc: 0.9068\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4316 - acc: 0.9076 - val_loss: 0.4393 - val_acc: 0.9079\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4223 - acc: 0.9092 - val_loss: 0.4318 - val_acc: 0.9082\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4121 - acc: 0.9107 - val_loss: 0.4322 - val_acc: 0.9092\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4024 - acc: 0.9121 - val_loss: 0.4231 - val_acc: 0.9101\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3948 - acc: 0.9136 - val_loss: 0.4265 - val_acc: 0.9102\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3868 - acc: 0.9148 - val_loss: 0.4177 - val_acc: 0.9120\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3815 - acc: 0.9151 - val_loss: 0.4175 - val_acc: 0.9121\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3709 - acc: 0.9173 - val_loss: 0.4240 - val_acc: 0.9125\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3639 - acc: 0.9183 - val_loss: 0.4130 - val_acc: 0.9125\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3559 - acc: 0.9195 - val_loss: 0.4171 - val_acc: 0.9125\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3479 - acc: 0.9210 - val_loss: 0.4152 - val_acc: 0.9128\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3433 - acc: 0.9213 - val_loss: 0.4144 - val_acc: 0.9145\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3339 - acc: 0.9228 - val_loss: 0.4131 - val_acc: 0.9143\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3292 - acc: 0.9238 - val_loss: 0.4125 - val_acc: 0.9133\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3235 - acc: 0.9248 - val_loss: 0.4141 - val_acc: 0.9140\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3155 - acc: 0.9261 - val_loss: 0.4149 - val_acc: 0.9151\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3084 - acc: 0.9270 - val_loss: 0.4169 - val_acc: 0.9141\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3023 - acc: 0.9284 - val_loss: 0.4257 - val_acc: 0.9151\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2965 - acc: 0.9292 - val_loss: 0.4266 - val_acc: 0.9143\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2907 - acc: 0.9302 - val_loss: 0.4202 - val_acc: 0.9141\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2843 - acc: 0.9313 - val_loss: 0.4234 - val_acc: 0.9154\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2771 - acc: 0.9328 - val_loss: 0.4331 - val_acc: 0.9136\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.2704 - acc: 0.9340 - val_loss: 0.4297 - val_acc: 0.9148\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2657 - acc: 0.9348Restoring model weights from the end of the best epoch: 27.\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.2657 - acc: 0.9348 - val_loss: 0.4342 - val_acc: 0.9138\n",
      "Epoch 37: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9342 - acc: 0.8509 - val_loss: 0.7488 - val_acc: 0.8640\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7549 - acc: 0.8661 - val_loss: 0.6864 - val_acc: 0.8700\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6897 - acc: 0.8711 - val_loss: 0.6387 - val_acc: 0.8764\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6299 - acc: 0.8792 - val_loss: 0.5754 - val_acc: 0.8856\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.5793 - acc: 0.8865 - val_loss: 0.5358 - val_acc: 0.8915\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5453 - acc: 0.8912 - val_loss: 0.5157 - val_acc: 0.8941\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5226 - acc: 0.8943 - val_loss: 0.5035 - val_acc: 0.8962\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5044 - acc: 0.8969 - val_loss: 0.4891 - val_acc: 0.8976\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4903 - acc: 0.8993 - val_loss: 0.4732 - val_acc: 0.9012\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4767 - acc: 0.9008 - val_loss: 0.4709 - val_acc: 0.9012\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4643 - acc: 0.9030 - val_loss: 0.4607 - val_acc: 0.9031\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4521 - acc: 0.9042 - val_loss: 0.4582 - val_acc: 0.9033\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4438 - acc: 0.9056 - val_loss: 0.4455 - val_acc: 0.9059\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4326 - acc: 0.9073 - val_loss: 0.4482 - val_acc: 0.9054\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4225 - acc: 0.9089 - val_loss: 0.4378 - val_acc: 0.9067\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4148 - acc: 0.9102 - val_loss: 0.4368 - val_acc: 0.9079\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4041 - acc: 0.9115 - val_loss: 0.4321 - val_acc: 0.9090\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3966 - acc: 0.9128 - val_loss: 0.4264 - val_acc: 0.9091\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3887 - acc: 0.9137 - val_loss: 0.4340 - val_acc: 0.9078\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3800 - acc: 0.9155 - val_loss: 0.4234 - val_acc: 0.9105\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3870 - acc: 0.9142 - val_loss: 0.4217 - val_acc: 0.9105\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3669 - acc: 0.9175 - val_loss: 0.4208 - val_acc: 0.9101\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3604 - acc: 0.9188 - val_loss: 0.4201 - val_acc: 0.9119\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3535 - acc: 0.9198 - val_loss: 0.4223 - val_acc: 0.9120\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3468 - acc: 0.9207 - val_loss: 0.4243 - val_acc: 0.9104\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3389 - acc: 0.9219 - val_loss: 0.4250 - val_acc: 0.9128\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3327 - acc: 0.9231 - val_loss: 0.4213 - val_acc: 0.9118\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3260 - acc: 0.9243 - val_loss: 0.4231 - val_acc: 0.9125\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3185 - acc: 0.9251 - val_loss: 0.4265 - val_acc: 0.9126\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3137 - acc: 0.9265 - val_loss: 0.4309 - val_acc: 0.9124\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3083 - acc: 0.9269 - val_loss: 0.4239 - val_acc: 0.9133\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3029 - acc: 0.9280 - val_loss: 0.4322 - val_acc: 0.9120\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2942 - acc: 0.9297Restoring model weights from the end of the best epoch: 23.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2942 - acc: 0.9297 - val_loss: 0.4300 - val_acc: 0.9123\n",
      "Epoch 33: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 0.9328 - acc: 0.8505 - val_loss: 0.7528 - val_acc: 0.8631\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7615 - acc: 0.8658 - val_loss: 0.7041 - val_acc: 0.8680\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6827 - acc: 0.8730 - val_loss: 0.6208 - val_acc: 0.8785\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6128 - acc: 0.8824 - val_loss: 0.5609 - val_acc: 0.8876\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5636 - acc: 0.8891 - val_loss: 0.5310 - val_acc: 0.8922\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5354 - acc: 0.8932 - val_loss: 0.5082 - val_acc: 0.8960\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5136 - acc: 0.8963 - val_loss: 0.4976 - val_acc: 0.8971\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.4948 - acc: 0.8991 - val_loss: 0.4925 - val_acc: 0.8969\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4792 - acc: 0.9011 - val_loss: 0.4714 - val_acc: 0.9014\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4674 - acc: 0.9027 - val_loss: 0.4745 - val_acc: 0.9001\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4555 - acc: 0.9042 - val_loss: 0.4580 - val_acc: 0.9026\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4459 - acc: 0.9055 - val_loss: 0.4580 - val_acc: 0.9031\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4336 - acc: 0.9072 - val_loss: 0.4497 - val_acc: 0.9043\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4265 - acc: 0.9081 - val_loss: 0.4493 - val_acc: 0.9043\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4172 - acc: 0.9096 - val_loss: 0.4490 - val_acc: 0.9036\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4095 - acc: 0.9106 - val_loss: 0.4349 - val_acc: 0.9068\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4007 - acc: 0.9121 - val_loss: 0.4412 - val_acc: 0.9052\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3924 - acc: 0.9131 - val_loss: 0.4292 - val_acc: 0.9080\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3849 - acc: 0.9141 - val_loss: 0.4237 - val_acc: 0.9091\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3763 - acc: 0.9159 - val_loss: 0.4254 - val_acc: 0.9087\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3695 - acc: 0.9168 - val_loss: 0.4292 - val_acc: 0.9088\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3636 - acc: 0.9179 - val_loss: 0.4250 - val_acc: 0.9099\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3547 - acc: 0.9193 - val_loss: 0.4227 - val_acc: 0.9105\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3482 - acc: 0.9205 - val_loss: 0.4209 - val_acc: 0.9108\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3409 - acc: 0.9215 - val_loss: 0.4255 - val_acc: 0.9108\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3327 - acc: 0.9229 - val_loss: 0.4219 - val_acc: 0.9120\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3286 - acc: 0.9234 - val_loss: 0.4420 - val_acc: 0.9097\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3225 - acc: 0.9245 - val_loss: 0.4235 - val_acc: 0.9114\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3156 - acc: 0.9256 - val_loss: 0.4286 - val_acc: 0.9112\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3095 - acc: 0.9267 - val_loss: 0.4338 - val_acc: 0.9122\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3040 - acc: 0.9275 - val_loss: 0.4320 - val_acc: 0.9118\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2997 - acc: 0.9283 - val_loss: 0.4307 - val_acc: 0.9116\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2913 - acc: 0.9302 - val_loss: 0.4419 - val_acc: 0.9110\n",
      "Epoch 34/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.9309Restoring model weights from the end of the best epoch: 24.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2869 - acc: 0.9307 - val_loss: 0.4420 - val_acc: 0.9108\n",
      "Epoch 34: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 0.9429 - acc: 0.8501 - val_loss: 0.7203 - val_acc: 0.8699\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7473 - acc: 0.8658 - val_loss: 0.6364 - val_acc: 0.8785\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6721 - acc: 0.8736 - val_loss: 0.5935 - val_acc: 0.8846\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6108 - acc: 0.8823 - val_loss: 0.5360 - val_acc: 0.8930\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5685 - acc: 0.8884 - val_loss: 0.5032 - val_acc: 0.8984\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5365 - acc: 0.8928 - val_loss: 0.4809 - val_acc: 0.9021\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5131 - acc: 0.8964 - val_loss: 0.4653 - val_acc: 0.9041\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4953 - acc: 0.8989 - val_loss: 0.4508 - val_acc: 0.9059\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4810 - acc: 0.9007 - val_loss: 0.4426 - val_acc: 0.9078\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4674 - acc: 0.9026 - val_loss: 0.4401 - val_acc: 0.9077\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4553 - acc: 0.9040 - val_loss: 0.4297 - val_acc: 0.9100\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4442 - acc: 0.9057 - val_loss: 0.4228 - val_acc: 0.9108\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4339 - acc: 0.9073 - val_loss: 0.4185 - val_acc: 0.9113\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4230 - acc: 0.9086 - val_loss: 0.4142 - val_acc: 0.9116\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4131 - acc: 0.9098 - val_loss: 0.4141 - val_acc: 0.9122\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4081 - acc: 0.9105 - val_loss: 0.4080 - val_acc: 0.9137\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3951 - acc: 0.9128 - val_loss: 0.4051 - val_acc: 0.9140\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3849 - acc: 0.9144 - val_loss: 0.4064 - val_acc: 0.9145\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3778 - acc: 0.9154 - val_loss: 0.4082 - val_acc: 0.9139\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3689 - acc: 0.9171 - val_loss: 0.4042 - val_acc: 0.9155\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3590 - acc: 0.9185 - val_loss: 0.4031 - val_acc: 0.9161\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3525 - acc: 0.9199 - val_loss: 0.3972 - val_acc: 0.9163\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3464 - acc: 0.9206 - val_loss: 0.3999 - val_acc: 0.9168\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3371 - acc: 0.9222 - val_loss: 0.4039 - val_acc: 0.9166\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3315 - acc: 0.9228 - val_loss: 0.4015 - val_acc: 0.9163\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3252 - acc: 0.9241 - val_loss: 0.4061 - val_acc: 0.9159\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3175 - acc: 0.9256 - val_loss: 0.4084 - val_acc: 0.9159\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3139 - acc: 0.9260 - val_loss: 0.4069 - val_acc: 0.9179\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3041 - acc: 0.9278 - val_loss: 0.4006 - val_acc: 0.9179\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2978 - acc: 0.9290 - val_loss: 0.4037 - val_acc: 0.9179\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2904 - acc: 0.9304 - val_loss: 0.4108 - val_acc: 0.9173\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.2819 - acc: 0.9314Restoring model weights from the end of the best epoch: 22.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2819 - acc: 0.9314 - val_loss: 0.4135 - val_acc: 0.9178\n",
      "Epoch 32: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.6\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 38ms/step - loss: 0.9382 - acc: 0.8501 - val_loss: 0.7413 - val_acc: 0.8656\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7508 - acc: 0.8666 - val_loss: 0.6779 - val_acc: 0.8712\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6918 - acc: 0.8707 - val_loss: 0.6397 - val_acc: 0.8760\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6423 - acc: 0.8769 - val_loss: 0.5870 - val_acc: 0.8823\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5904 - acc: 0.8843 - val_loss: 0.5433 - val_acc: 0.8919\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5530 - acc: 0.8897 - val_loss: 0.5178 - val_acc: 0.8954\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5277 - acc: 0.8937 - val_loss: 0.5105 - val_acc: 0.8969\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5085 - acc: 0.8966 - val_loss: 0.4902 - val_acc: 0.8996\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4915 - acc: 0.8992 - val_loss: 0.4817 - val_acc: 0.9017\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4748 - acc: 0.9015 - val_loss: 0.4696 - val_acc: 0.9033\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4630 - acc: 0.9031 - val_loss: 0.4637 - val_acc: 0.9047\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4525 - acc: 0.9046 - val_loss: 0.4594 - val_acc: 0.9045\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4399 - acc: 0.9062 - val_loss: 0.4483 - val_acc: 0.9071\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4304 - acc: 0.9077 - val_loss: 0.4449 - val_acc: 0.9069\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4199 - acc: 0.9089 - val_loss: 0.4411 - val_acc: 0.9078\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4120 - acc: 0.9102 - val_loss: 0.4376 - val_acc: 0.9085\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4016 - acc: 0.9121 - val_loss: 0.4380 - val_acc: 0.9092\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3961 - acc: 0.9127 - val_loss: 0.4324 - val_acc: 0.9091\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3866 - acc: 0.9142 - val_loss: 0.4262 - val_acc: 0.9106\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3792 - acc: 0.9154 - val_loss: 0.4227 - val_acc: 0.9111\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3724 - acc: 0.9165 - val_loss: 0.4250 - val_acc: 0.9100\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3636 - acc: 0.9179 - val_loss: 0.4219 - val_acc: 0.9118\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3580 - acc: 0.9190 - val_loss: 0.4237 - val_acc: 0.9109\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3489 - acc: 0.9204 - val_loss: 0.4249 - val_acc: 0.9117\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3435 - acc: 0.9210 - val_loss: 0.4234 - val_acc: 0.9126\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3367 - acc: 0.9222 - val_loss: 0.4237 - val_acc: 0.9121\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3303 - acc: 0.9232 - val_loss: 0.4254 - val_acc: 0.9126\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3225 - acc: 0.9246 - val_loss: 0.4272 - val_acc: 0.9137\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3183 - acc: 0.9254 - val_loss: 0.4347 - val_acc: 0.9131\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3086 - acc: 0.9269 - val_loss: 0.4307 - val_acc: 0.9129\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3022 - acc: 0.9284 - val_loss: 0.4333 - val_acc: 0.9118\n",
      "Epoch 32/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.2981 - acc: 0.9284Restoring model weights from the end of the best epoch: 22.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.2987 - acc: 0.9283 - val_loss: 0.4371 - val_acc: 0.9113\n",
      "Epoch 32: early stopping\n",
      "[0.4124666154384613, 0.42011868953704834, 0.4208827018737793, 0.3972456157207489, 0.42191022634506226]\n",
      "[27, 23, 24, 22, 22]\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 0.9736 - acc: 0.8494 - val_loss: 0.7496 - val_acc: 0.8644\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7716 - acc: 0.8653 - val_loss: 0.6898 - val_acc: 0.8712\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7115 - acc: 0.8690 - val_loss: 0.6518 - val_acc: 0.8742\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6671 - acc: 0.8739 - val_loss: 0.6074 - val_acc: 0.8813\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6180 - acc: 0.8811 - val_loss: 0.5644 - val_acc: 0.8867\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5838 - acc: 0.8856 - val_loss: 0.5402 - val_acc: 0.8906\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5575 - acc: 0.8891 - val_loss: 0.5231 - val_acc: 0.8934\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5369 - acc: 0.8923 - val_loss: 0.5080 - val_acc: 0.8959\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5204 - acc: 0.8947 - val_loss: 0.4965 - val_acc: 0.8980\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5081 - acc: 0.8965 - val_loss: 0.4852 - val_acc: 0.8991\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4947 - acc: 0.8986 - val_loss: 0.4769 - val_acc: 0.9017\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4847 - acc: 0.9001 - val_loss: 0.4641 - val_acc: 0.9036\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4764 - acc: 0.9014 - val_loss: 0.4613 - val_acc: 0.9035\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4676 - acc: 0.9027 - val_loss: 0.4620 - val_acc: 0.9037\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4582 - acc: 0.9042 - val_loss: 0.4529 - val_acc: 0.9054\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4727 - acc: 0.9018 - val_loss: 0.6076 - val_acc: 0.8817\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5098 - acc: 0.8952 - val_loss: 0.4550 - val_acc: 0.9043\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4475 - acc: 0.9057 - val_loss: 0.4454 - val_acc: 0.9065\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4347 - acc: 0.9073 - val_loss: 0.4382 - val_acc: 0.9071\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4281 - acc: 0.9085 - val_loss: 0.4407 - val_acc: 0.9063\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4239 - acc: 0.9092 - val_loss: 0.4362 - val_acc: 0.9076\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4164 - acc: 0.9104 - val_loss: 0.4332 - val_acc: 0.9081\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4121 - acc: 0.9109 - val_loss: 0.4327 - val_acc: 0.9094\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4059 - acc: 0.9118 - val_loss: 0.4297 - val_acc: 0.9102\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4020 - acc: 0.9125 - val_loss: 0.4277 - val_acc: 0.9093\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3964 - acc: 0.9130 - val_loss: 0.4296 - val_acc: 0.9098\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3924 - acc: 0.9141 - val_loss: 0.4279 - val_acc: 0.9100\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3866 - acc: 0.9147 - val_loss: 0.4244 - val_acc: 0.9096\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3816 - acc: 0.9152 - val_loss: 0.4268 - val_acc: 0.9108\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3787 - acc: 0.9164 - val_loss: 0.4219 - val_acc: 0.9116\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3728 - acc: 0.9167 - val_loss: 0.4275 - val_acc: 0.9110\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3700 - acc: 0.9176 - val_loss: 0.4231 - val_acc: 0.9112\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3636 - acc: 0.9186 - val_loss: 0.4255 - val_acc: 0.9108\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3604 - acc: 0.9197 - val_loss: 0.4191 - val_acc: 0.9124\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3550 - acc: 0.9203 - val_loss: 0.4320 - val_acc: 0.9116\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3485 - acc: 0.9212 - val_loss: 0.4270 - val_acc: 0.9109\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3451 - acc: 0.9214 - val_loss: 0.4311 - val_acc: 0.9123\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3406 - acc: 0.9227 - val_loss: 0.4205 - val_acc: 0.9136\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3345 - acc: 0.9237 - val_loss: 0.4242 - val_acc: 0.9118\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3336 - acc: 0.9236 - val_loss: 0.4301 - val_acc: 0.9131\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3260 - acc: 0.9252 - val_loss: 0.4298 - val_acc: 0.9127\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3234 - acc: 0.9255 - val_loss: 0.4262 - val_acc: 0.9123\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3178 - acc: 0.9264 - val_loss: 0.4381 - val_acc: 0.9124\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3135 - acc: 0.9273Restoring model weights from the end of the best epoch: 34.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3135 - acc: 0.9273 - val_loss: 0.4308 - val_acc: 0.9137\n",
      "Epoch 44: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 13s 38ms/step - loss: 0.9692 - acc: 0.8508 - val_loss: 0.7615 - val_acc: 0.8638\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7691 - acc: 0.8659 - val_loss: 0.6932 - val_acc: 0.8702\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7060 - acc: 0.8699 - val_loss: 0.6549 - val_acc: 0.8733\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6607 - acc: 0.8751 - val_loss: 0.5998 - val_acc: 0.8819\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6081 - acc: 0.8832 - val_loss: 0.5538 - val_acc: 0.8886\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5754 - acc: 0.8877 - val_loss: 0.5421 - val_acc: 0.8908\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5753 - acc: 0.8868 - val_loss: 0.5225 - val_acc: 0.8932\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5391 - acc: 0.8920 - val_loss: 0.5100 - val_acc: 0.8954\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5191 - acc: 0.8953 - val_loss: 0.4968 - val_acc: 0.8972\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5046 - acc: 0.8974 - val_loss: 0.4860 - val_acc: 0.8994\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4944 - acc: 0.8989 - val_loss: 0.4777 - val_acc: 0.9002\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4831 - acc: 0.9004 - val_loss: 0.4734 - val_acc: 0.9011\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4723 - acc: 0.9017 - val_loss: 0.4649 - val_acc: 0.9016\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4661 - acc: 0.9032 - val_loss: 0.4586 - val_acc: 0.9037\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4558 - acc: 0.9045 - val_loss: 0.4533 - val_acc: 0.9037\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4495 - acc: 0.9054 - val_loss: 0.4477 - val_acc: 0.9051\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4424 - acc: 0.9064 - val_loss: 0.4499 - val_acc: 0.9047\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4342 - acc: 0.9076 - val_loss: 0.4475 - val_acc: 0.9045\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4274 - acc: 0.9085 - val_loss: 0.4506 - val_acc: 0.9027\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4207 - acc: 0.9096 - val_loss: 0.4388 - val_acc: 0.9066\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4136 - acc: 0.9108 - val_loss: 0.4368 - val_acc: 0.9061\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4081 - acc: 0.9120 - val_loss: 0.4337 - val_acc: 0.9085\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4007 - acc: 0.9131 - val_loss: 0.4280 - val_acc: 0.9096\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3939 - acc: 0.9142 - val_loss: 0.4303 - val_acc: 0.9097\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3898 - acc: 0.9146 - val_loss: 0.4314 - val_acc: 0.9091\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3819 - acc: 0.9158 - val_loss: 0.4309 - val_acc: 0.9101\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3768 - acc: 0.9168 - val_loss: 0.4239 - val_acc: 0.9102\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3729 - acc: 0.9175 - val_loss: 0.4203 - val_acc: 0.9114\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3655 - acc: 0.9187 - val_loss: 0.4227 - val_acc: 0.9121\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3592 - acc: 0.9195 - val_loss: 0.4289 - val_acc: 0.9120\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3537 - acc: 0.9205 - val_loss: 0.4305 - val_acc: 0.9122\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3491 - acc: 0.9216 - val_loss: 0.4251 - val_acc: 0.9114\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3444 - acc: 0.9225 - val_loss: 0.4290 - val_acc: 0.9111\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3406 - acc: 0.9229 - val_loss: 0.4265 - val_acc: 0.9118\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3339 - acc: 0.9242 - val_loss: 0.4276 - val_acc: 0.9128\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3266 - acc: 0.9253 - val_loss: 0.4312 - val_acc: 0.9129\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3210 - acc: 0.9262 - val_loss: 0.4309 - val_acc: 0.9132\n",
      "Epoch 38/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3175 - acc: 0.9267Restoring model weights from the end of the best epoch: 28.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3176 - acc: 0.9267 - val_loss: 0.4345 - val_acc: 0.9132\n",
      "Epoch 38: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9753 - acc: 0.8497 - val_loss: 0.7544 - val_acc: 0.8625\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7654 - acc: 0.8660 - val_loss: 0.7036 - val_acc: 0.8670\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7036 - acc: 0.8697 - val_loss: 0.6595 - val_acc: 0.8723\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6515 - acc: 0.8762 - val_loss: 0.6046 - val_acc: 0.8805\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6085 - acc: 0.8826 - val_loss: 0.5667 - val_acc: 0.8876\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5730 - acc: 0.8877 - val_loss: 0.5358 - val_acc: 0.8914\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5472 - acc: 0.8916 - val_loss: 0.5192 - val_acc: 0.8938\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5315 - acc: 0.8938 - val_loss: 0.5058 - val_acc: 0.8959\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5101 - acc: 0.8965 - val_loss: 0.4933 - val_acc: 0.8972\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5008 - acc: 0.8981 - val_loss: 0.4934 - val_acc: 0.8966\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4882 - acc: 0.8998 - val_loss: 0.4783 - val_acc: 0.8999\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4774 - acc: 0.9013 - val_loss: 0.4752 - val_acc: 0.9014\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4685 - acc: 0.9029 - val_loss: 0.4744 - val_acc: 0.9011\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4599 - acc: 0.9042 - val_loss: 0.4595 - val_acc: 0.9035\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4512 - acc: 0.9057 - val_loss: 0.4592 - val_acc: 0.9033\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4442 - acc: 0.9064 - val_loss: 0.4508 - val_acc: 0.9049\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4367 - acc: 0.9077 - val_loss: 0.4477 - val_acc: 0.9056\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4296 - acc: 0.9086 - val_loss: 0.4404 - val_acc: 0.9066\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4239 - acc: 0.9097 - val_loss: 0.4404 - val_acc: 0.9067\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4178 - acc: 0.9104 - val_loss: 0.4403 - val_acc: 0.9059\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4103 - acc: 0.9116 - val_loss: 0.4385 - val_acc: 0.9071\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4053 - acc: 0.9125 - val_loss: 0.4360 - val_acc: 0.9066\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3987 - acc: 0.9132 - val_loss: 0.4343 - val_acc: 0.9082\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3933 - acc: 0.9144 - val_loss: 0.4333 - val_acc: 0.9089\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3880 - acc: 0.9150 - val_loss: 0.4344 - val_acc: 0.9082\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3803 - acc: 0.9162 - val_loss: 0.4318 - val_acc: 0.9092\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3747 - acc: 0.9171 - val_loss: 0.4338 - val_acc: 0.9079\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3704 - acc: 0.9179 - val_loss: 0.4349 - val_acc: 0.9093\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3668 - acc: 0.9186 - val_loss: 0.4273 - val_acc: 0.9110\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3600 - acc: 0.9201 - val_loss: 0.4245 - val_acc: 0.9117\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3539 - acc: 0.9209 - val_loss: 0.4257 - val_acc: 0.9110\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3501 - acc: 0.9214 - val_loss: 0.4316 - val_acc: 0.9112\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3444 - acc: 0.9226 - val_loss: 0.4271 - val_acc: 0.9123\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3380 - acc: 0.9236 - val_loss: 0.4387 - val_acc: 0.9099\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3353 - acc: 0.9241 - val_loss: 0.4313 - val_acc: 0.9117\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3301 - acc: 0.9249 - val_loss: 0.4313 - val_acc: 0.9115\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3258 - acc: 0.9255 - val_loss: 0.4360 - val_acc: 0.9125\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3193 - acc: 0.9266 - val_loss: 0.4322 - val_acc: 0.9119\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3160 - acc: 0.9273 - val_loss: 0.4499 - val_acc: 0.9113\n",
      "Epoch 40/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.9286Restoring model weights from the end of the best epoch: 30.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3093 - acc: 0.9285 - val_loss: 0.4401 - val_acc: 0.9117\n",
      "Epoch 40: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9705 - acc: 0.8486 - val_loss: 0.7196 - val_acc: 0.8699\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7738 - acc: 0.8642 - val_loss: 0.6586 - val_acc: 0.8754\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7165 - acc: 0.8673 - val_loss: 0.6290 - val_acc: 0.8783\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6701 - acc: 0.8728 - val_loss: 0.5771 - val_acc: 0.8858\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6203 - acc: 0.8800 - val_loss: 0.5495 - val_acc: 0.8905\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.5809 - acc: 0.8854 - val_loss: 0.5161 - val_acc: 0.8950\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5596 - acc: 0.8889 - val_loss: 0.4981 - val_acc: 0.8985\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5381 - acc: 0.8921 - val_loss: 0.4844 - val_acc: 0.9013\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5237 - acc: 0.8943 - val_loss: 0.4751 - val_acc: 0.9030\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5128 - acc: 0.8958 - val_loss: 0.4680 - val_acc: 0.9032\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4998 - acc: 0.8979 - val_loss: 0.4587 - val_acc: 0.9045\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4882 - acc: 0.8996 - val_loss: 0.4500 - val_acc: 0.9073\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4798 - acc: 0.9009 - val_loss: 0.4454 - val_acc: 0.9068\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4706 - acc: 0.9022 - val_loss: 0.4388 - val_acc: 0.9077\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4638 - acc: 0.9029 - val_loss: 0.4396 - val_acc: 0.9086\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4555 - acc: 0.9041 - val_loss: 0.4370 - val_acc: 0.9094\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4483 - acc: 0.9054 - val_loss: 0.4279 - val_acc: 0.9105\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4405 - acc: 0.9063 - val_loss: 0.4275 - val_acc: 0.9094\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4352 - acc: 0.9071 - val_loss: 0.4250 - val_acc: 0.9097\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4289 - acc: 0.9082 - val_loss: 0.4148 - val_acc: 0.9127\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4217 - acc: 0.9092 - val_loss: 0.4207 - val_acc: 0.9109\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4158 - acc: 0.9105 - val_loss: 0.4185 - val_acc: 0.9121\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4108 - acc: 0.9108 - val_loss: 0.4173 - val_acc: 0.9116\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4042 - acc: 0.9123 - val_loss: 0.4166 - val_acc: 0.9126\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3989 - acc: 0.9128 - val_loss: 0.4128 - val_acc: 0.9134\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3930 - acc: 0.9139 - val_loss: 0.4168 - val_acc: 0.9137\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3874 - acc: 0.9149 - val_loss: 0.4113 - val_acc: 0.9142\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3807 - acc: 0.9161 - val_loss: 0.4131 - val_acc: 0.9132\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3790 - acc: 0.9162 - val_loss: 0.4133 - val_acc: 0.9136\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3711 - acc: 0.9172 - val_loss: 0.4087 - val_acc: 0.9144\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3682 - acc: 0.9178 - val_loss: 0.4034 - val_acc: 0.9152\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3620 - acc: 0.9191 - val_loss: 0.4098 - val_acc: 0.9159\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3539 - acc: 0.9203 - val_loss: 0.4107 - val_acc: 0.9156\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3499 - acc: 0.9208 - val_loss: 0.4088 - val_acc: 0.9161\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3470 - acc: 0.9215 - val_loss: 0.4123 - val_acc: 0.9156\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3418 - acc: 0.9226 - val_loss: 0.4136 - val_acc: 0.9161\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3379 - acc: 0.9230 - val_loss: 0.4137 - val_acc: 0.9163\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3314 - acc: 0.9243 - val_loss: 0.4107 - val_acc: 0.9164\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3264 - acc: 0.9249 - val_loss: 0.4154 - val_acc: 0.9156\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3208 - acc: 0.9262 - val_loss: 0.4180 - val_acc: 0.9160\n",
      "Epoch 41/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.9266Restoring model weights from the end of the best epoch: 31.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3177 - acc: 0.9266 - val_loss: 0.4229 - val_acc: 0.9149\n",
      "Epoch 41: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.7\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 0.9679 - acc: 0.8500 - val_loss: 0.7457 - val_acc: 0.8648\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 21ms/step - loss: 0.7731 - acc: 0.8652 - val_loss: 0.7060 - val_acc: 0.8679\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7124 - acc: 0.8685 - val_loss: 0.6560 - val_acc: 0.8737\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6676 - acc: 0.8734 - val_loss: 0.6131 - val_acc: 0.8795\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6451 - acc: 0.8760 - val_loss: 0.5825 - val_acc: 0.8841\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5955 - acc: 0.8830 - val_loss: 0.5607 - val_acc: 0.8879\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5681 - acc: 0.8871 - val_loss: 0.5340 - val_acc: 0.8916\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5486 - acc: 0.8900 - val_loss: 0.5182 - val_acc: 0.8944\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5314 - acc: 0.8928 - val_loss: 0.5083 - val_acc: 0.8962\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5176 - acc: 0.8945 - val_loss: 0.4960 - val_acc: 0.8987\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5061 - acc: 0.8964 - val_loss: 0.4945 - val_acc: 0.8982\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4937 - acc: 0.8984 - val_loss: 0.4843 - val_acc: 0.9000\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4854 - acc: 0.8995 - val_loss: 0.4763 - val_acc: 0.9018\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4741 - acc: 0.9011 - val_loss: 0.4754 - val_acc: 0.9024\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4865 - acc: 0.8991 - val_loss: 0.4694 - val_acc: 0.9021\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4657 - acc: 0.9022 - val_loss: 0.4582 - val_acc: 0.9042\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4537 - acc: 0.9040 - val_loss: 0.4560 - val_acc: 0.9050\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4470 - acc: 0.9053 - val_loss: 0.4613 - val_acc: 0.9031\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4421 - acc: 0.9059 - val_loss: 0.4520 - val_acc: 0.9056\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4349 - acc: 0.9070 - val_loss: 0.4461 - val_acc: 0.9065\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4290 - acc: 0.9079 - val_loss: 0.4511 - val_acc: 0.9064\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4234 - acc: 0.9085 - val_loss: 0.4400 - val_acc: 0.9083\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4178 - acc: 0.9098 - val_loss: 0.4392 - val_acc: 0.9082\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4134 - acc: 0.9105 - val_loss: 0.4382 - val_acc: 0.9082\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4098 - acc: 0.9109 - val_loss: 0.4434 - val_acc: 0.9067\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4044 - acc: 0.9118 - val_loss: 0.4398 - val_acc: 0.9080\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4009 - acc: 0.9122 - val_loss: 0.4330 - val_acc: 0.9089\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3949 - acc: 0.9132 - val_loss: 0.4324 - val_acc: 0.9094\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3888 - acc: 0.9143 - val_loss: 0.4387 - val_acc: 0.9086\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3842 - acc: 0.9148 - val_loss: 0.4366 - val_acc: 0.9098\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3814 - acc: 0.9154 - val_loss: 0.4300 - val_acc: 0.9094\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3749 - acc: 0.9166 - val_loss: 0.4372 - val_acc: 0.9091\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3738 - acc: 0.9165 - val_loss: 0.4346 - val_acc: 0.9101\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4686 - acc: 0.9012 - val_loss: 0.4408 - val_acc: 0.9078\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3835 - acc: 0.9147 - val_loss: 0.4272 - val_acc: 0.9105\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3664 - acc: 0.9179 - val_loss: 0.4301 - val_acc: 0.9102\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3597 - acc: 0.9190 - val_loss: 0.4258 - val_acc: 0.9123\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3581 - acc: 0.9198 - val_loss: 0.4312 - val_acc: 0.9121\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3516 - acc: 0.9202 - val_loss: 0.4325 - val_acc: 0.9119\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3457 - acc: 0.9213 - val_loss: 0.4311 - val_acc: 0.9113\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3440 - acc: 0.9214 - val_loss: 0.4349 - val_acc: 0.9110\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3394 - acc: 0.9224 - val_loss: 0.4338 - val_acc: 0.9108\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3381 - acc: 0.9227 - val_loss: 0.4390 - val_acc: 0.9122\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3357 - acc: 0.9230 - val_loss: 0.4327 - val_acc: 0.9109\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3311 - acc: 0.9238 - val_loss: 0.4357 - val_acc: 0.9124\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3269 - acc: 0.9247 - val_loss: 0.4374 - val_acc: 0.9105\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3248 - acc: 0.9248Restoring model weights from the end of the best epoch: 37.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3248 - acc: 0.9248 - val_loss: 0.4411 - val_acc: 0.9117\n",
      "Epoch 47: early stopping\n",
      "[0.41911065578460693, 0.42026567459106445, 0.42449256777763367, 0.4034075438976288, 0.4258240759372711]\n",
      "[34, 28, 30, 31, 37]\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.0380 - acc: 0.8481 - val_loss: 0.7416 - val_acc: 0.8659\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7856 - acc: 0.8649 - val_loss: 0.6962 - val_acc: 0.8695\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7280 - acc: 0.8677 - val_loss: 0.6607 - val_acc: 0.8721\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6826 - acc: 0.8720 - val_loss: 0.6227 - val_acc: 0.8781\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6460 - acc: 0.8777 - val_loss: 0.5952 - val_acc: 0.8840\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6124 - acc: 0.8828 - val_loss: 0.5597 - val_acc: 0.8878\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5845 - acc: 0.8868 - val_loss: 0.5415 - val_acc: 0.8916\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5648 - acc: 0.8896 - val_loss: 0.5218 - val_acc: 0.8938\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5499 - acc: 0.8920 - val_loss: 0.5143 - val_acc: 0.8954\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5359 - acc: 0.8937 - val_loss: 0.4976 - val_acc: 0.8976\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5253 - acc: 0.8949 - val_loss: 0.4918 - val_acc: 0.8985\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5148 - acc: 0.8964 - val_loss: 0.4877 - val_acc: 0.8990\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5044 - acc: 0.8982 - val_loss: 0.4888 - val_acc: 0.8997\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4990 - acc: 0.8987 - val_loss: 0.4761 - val_acc: 0.9017\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4917 - acc: 0.8996 - val_loss: 0.4728 - val_acc: 0.9020\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4834 - acc: 0.9009 - val_loss: 0.4637 - val_acc: 0.9041\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4759 - acc: 0.9021 - val_loss: 0.4689 - val_acc: 0.9030\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4694 - acc: 0.9030 - val_loss: 0.4534 - val_acc: 0.9048\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4641 - acc: 0.9042 - val_loss: 0.4527 - val_acc: 0.9055\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4597 - acc: 0.9049 - val_loss: 0.4518 - val_acc: 0.9061\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4523 - acc: 0.9060 - val_loss: 0.4443 - val_acc: 0.9066\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4479 - acc: 0.9066 - val_loss: 0.4467 - val_acc: 0.9060\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4434 - acc: 0.9075 - val_loss: 0.4454 - val_acc: 0.9069\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4383 - acc: 0.9081 - val_loss: 0.4428 - val_acc: 0.9072\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4330 - acc: 0.9089 - val_loss: 0.4359 - val_acc: 0.9088\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4286 - acc: 0.9098 - val_loss: 0.4381 - val_acc: 0.9076\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4238 - acc: 0.9106 - val_loss: 0.4443 - val_acc: 0.9071\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4198 - acc: 0.9110 - val_loss: 0.4384 - val_acc: 0.9083\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4168 - acc: 0.9116 - val_loss: 0.4337 - val_acc: 0.9095\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4116 - acc: 0.9127 - val_loss: 0.4312 - val_acc: 0.9105\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4090 - acc: 0.9130 - val_loss: 0.4287 - val_acc: 0.9101\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4029 - acc: 0.9142 - val_loss: 0.4289 - val_acc: 0.9105\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3984 - acc: 0.9149 - val_loss: 0.4322 - val_acc: 0.9099\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3975 - acc: 0.9151 - val_loss: 0.4348 - val_acc: 0.9110\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3900 - acc: 0.9161 - val_loss: 0.4365 - val_acc: 0.9103\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3883 - acc: 0.9164 - val_loss: 0.4294 - val_acc: 0.9113\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3829 - acc: 0.9173 - val_loss: 0.4327 - val_acc: 0.9117\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3784 - acc: 0.9182 - val_loss: 0.4298 - val_acc: 0.9114\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3764 - acc: 0.9187 - val_loss: 0.4326 - val_acc: 0.9116\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3737 - acc: 0.9189 - val_loss: 0.4337 - val_acc: 0.9118\n",
      "Epoch 41/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3693 - acc: 0.9197Restoring model weights from the end of the best epoch: 31.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3690 - acc: 0.9197 - val_loss: 0.4369 - val_acc: 0.9120\n",
      "Epoch 41: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 35ms/step - loss: 1.0303 - acc: 0.8488 - val_loss: 0.7633 - val_acc: 0.8635\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7919 - acc: 0.8645 - val_loss: 0.7243 - val_acc: 0.8653\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7391 - acc: 0.8674 - val_loss: 0.6881 - val_acc: 0.8695\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6978 - acc: 0.8706 - val_loss: 0.6386 - val_acc: 0.8747\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6568 - acc: 0.8758 - val_loss: 0.6039 - val_acc: 0.8815\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.6217 - acc: 0.8808 - val_loss: 0.5727 - val_acc: 0.8859\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5952 - acc: 0.8843 - val_loss: 0.5524 - val_acc: 0.8881\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5726 - acc: 0.8878 - val_loss: 0.5334 - val_acc: 0.8922\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5559 - acc: 0.8901 - val_loss: 0.5172 - val_acc: 0.8948\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5411 - acc: 0.8924 - val_loss: 0.5106 - val_acc: 0.8959\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5297 - acc: 0.8941 - val_loss: 0.5029 - val_acc: 0.8957\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5181 - acc: 0.8960 - val_loss: 0.4889 - val_acc: 0.8984\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5079 - acc: 0.8975 - val_loss: 0.4839 - val_acc: 0.8995\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5005 - acc: 0.8986 - val_loss: 0.4826 - val_acc: 0.8996\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7752 - acc: 0.8649 - val_loss: 0.7657 - val_acc: 0.8618\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7657 - acc: 0.8638 - val_loss: 0.7396 - val_acc: 0.8640\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.7040 - acc: 0.8711 - val_loss: 0.6478 - val_acc: 0.8756\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6110 - acc: 0.8808 - val_loss: 0.5504 - val_acc: 0.8884\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5411 - acc: 0.8909 - val_loss: 0.5010 - val_acc: 0.8965\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5144 - acc: 0.8957 - val_loss: 0.4918 - val_acc: 0.8984\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4994 - acc: 0.8985 - val_loss: 0.4853 - val_acc: 0.8991\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4899 - acc: 0.8998 - val_loss: 0.4781 - val_acc: 0.9008\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4862 - acc: 0.9002 - val_loss: 0.4699 - val_acc: 0.9018\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4783 - acc: 0.9015 - val_loss: 0.4680 - val_acc: 0.9016\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4726 - acc: 0.9023 - val_loss: 0.4626 - val_acc: 0.9029\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4685 - acc: 0.9032 - val_loss: 0.4604 - val_acc: 0.9031\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4630 - acc: 0.9042 - val_loss: 0.4585 - val_acc: 0.9040\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4591 - acc: 0.9043 - val_loss: 0.4600 - val_acc: 0.9025\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4556 - acc: 0.9052 - val_loss: 0.4555 - val_acc: 0.9044\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4522 - acc: 0.9054 - val_loss: 0.4517 - val_acc: 0.9051\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4485 - acc: 0.9061 - val_loss: 0.4502 - val_acc: 0.9064\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4452 - acc: 0.9071 - val_loss: 0.4476 - val_acc: 0.9049\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4406 - acc: 0.9078 - val_loss: 0.4488 - val_acc: 0.9054\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4436 - acc: 0.9070 - val_loss: 0.4415 - val_acc: 0.9073\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4325 - acc: 0.9087 - val_loss: 0.4444 - val_acc: 0.9069\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4300 - acc: 0.9094 - val_loss: 0.4431 - val_acc: 0.9069\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4261 - acc: 0.9096 - val_loss: 0.4425 - val_acc: 0.9074\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4226 - acc: 0.9102 - val_loss: 0.4418 - val_acc: 0.9075\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4206 - acc: 0.9108 - val_loss: 0.4386 - val_acc: 0.9080\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4168 - acc: 0.9114 - val_loss: 0.4382 - val_acc: 0.9076\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4142 - acc: 0.9117 - val_loss: 0.4351 - val_acc: 0.9084\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4123 - acc: 0.9119 - val_loss: 0.4342 - val_acc: 0.9086\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4080 - acc: 0.9127 - val_loss: 0.4374 - val_acc: 0.9094\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4041 - acc: 0.9135 - val_loss: 0.4362 - val_acc: 0.9083\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4006 - acc: 0.9139 - val_loss: 0.4380 - val_acc: 0.9092\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3997 - acc: 0.9142 - val_loss: 0.4355 - val_acc: 0.9100\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3953 - acc: 0.9149 - val_loss: 0.4409 - val_acc: 0.9090\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3917 - acc: 0.9156 - val_loss: 0.4351 - val_acc: 0.9097\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3899 - acc: 0.9159 - val_loss: 0.4327 - val_acc: 0.9099\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3864 - acc: 0.9166 - val_loss: 0.4360 - val_acc: 0.9107\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3838 - acc: 0.9170 - val_loss: 0.4438 - val_acc: 0.9098\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3809 - acc: 0.9175 - val_loss: 0.4372 - val_acc: 0.9102\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3783 - acc: 0.9177 - val_loss: 0.4379 - val_acc: 0.9098\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3757 - acc: 0.9180 - val_loss: 0.4388 - val_acc: 0.9112\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3725 - acc: 0.9190 - val_loss: 0.4340 - val_acc: 0.9104\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3706 - acc: 0.9189 - val_loss: 0.4372 - val_acc: 0.9102\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3655 - acc: 0.9200 - val_loss: 0.4438 - val_acc: 0.9101\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3651 - acc: 0.9200 - val_loss: 0.4406 - val_acc: 0.9110\n",
      "Epoch 59/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3615 - acc: 0.9205Restoring model weights from the end of the best epoch: 49.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3614 - acc: 0.9205 - val_loss: 0.4425 - val_acc: 0.9100\n",
      "Epoch 59: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 1.0269 - acc: 0.8493 - val_loss: 0.7628 - val_acc: 0.8632\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7834 - acc: 0.8656 - val_loss: 0.7208 - val_acc: 0.8656\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7329 - acc: 0.8679 - val_loss: 0.6796 - val_acc: 0.8694\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6897 - acc: 0.8714 - val_loss: 0.6375 - val_acc: 0.8757\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6539 - acc: 0.8760 - val_loss: 0.6077 - val_acc: 0.8801\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6198 - acc: 0.8813 - val_loss: 0.5752 - val_acc: 0.8847\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5903 - acc: 0.8859 - val_loss: 0.5469 - val_acc: 0.8894\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5686 - acc: 0.8889 - val_loss: 0.5307 - val_acc: 0.8918\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5523 - acc: 0.8912 - val_loss: 0.5221 - val_acc: 0.8934\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5371 - acc: 0.8934 - val_loss: 0.5138 - val_acc: 0.8948\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5242 - acc: 0.8952 - val_loss: 0.4986 - val_acc: 0.8968\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5157 - acc: 0.8962 - val_loss: 0.4931 - val_acc: 0.8982\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5048 - acc: 0.8983 - val_loss: 0.4929 - val_acc: 0.8981\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4954 - acc: 0.8994 - val_loss: 0.4814 - val_acc: 0.8995\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4888 - acc: 0.9003 - val_loss: 0.4772 - val_acc: 0.9003\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4821 - acc: 0.9017 - val_loss: 0.4716 - val_acc: 0.9004\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4765 - acc: 0.9020 - val_loss: 0.4685 - val_acc: 0.9022\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4677 - acc: 0.9036 - val_loss: 0.4618 - val_acc: 0.9035\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4625 - acc: 0.9040 - val_loss: 0.4716 - val_acc: 0.9027\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4562 - acc: 0.9052 - val_loss: 0.4563 - val_acc: 0.9038\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4523 - acc: 0.9059 - val_loss: 0.4657 - val_acc: 0.9020\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4464 - acc: 0.9067 - val_loss: 0.4575 - val_acc: 0.9041\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4401 - acc: 0.9076 - val_loss: 0.4524 - val_acc: 0.9043\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4339 - acc: 0.9088 - val_loss: 0.4555 - val_acc: 0.9048\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4316 - acc: 0.9090 - val_loss: 0.4579 - val_acc: 0.9047\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4267 - acc: 0.9102 - val_loss: 0.4473 - val_acc: 0.9071\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4220 - acc: 0.9108 - val_loss: 0.4448 - val_acc: 0.9065\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4179 - acc: 0.9114 - val_loss: 0.4441 - val_acc: 0.9065\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4134 - acc: 0.9118 - val_loss: 0.4439 - val_acc: 0.9062\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4054 - acc: 0.9132 - val_loss: 0.4403 - val_acc: 0.9068\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4038 - acc: 0.9137 - val_loss: 0.4397 - val_acc: 0.9084\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3984 - acc: 0.9146 - val_loss: 0.4425 - val_acc: 0.9081\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3939 - acc: 0.9156 - val_loss: 0.4431 - val_acc: 0.9086\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3907 - acc: 0.9158 - val_loss: 0.4350 - val_acc: 0.9089\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3860 - acc: 0.9168 - val_loss: 0.4534 - val_acc: 0.9085\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3808 - acc: 0.9176 - val_loss: 0.4434 - val_acc: 0.9086\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3826 - acc: 0.9175 - val_loss: 0.4464 - val_acc: 0.9090\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3730 - acc: 0.9184 - val_loss: 0.4514 - val_acc: 0.9077\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3696 - acc: 0.9197 - val_loss: 0.4404 - val_acc: 0.9098\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3666 - acc: 0.9201 - val_loss: 0.4447 - val_acc: 0.9076\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3597 - acc: 0.9210 - val_loss: 0.4425 - val_acc: 0.9101\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3566 - acc: 0.9220 - val_loss: 0.4430 - val_acc: 0.9104\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3558 - acc: 0.9221 - val_loss: 0.4495 - val_acc: 0.9092\n",
      "Epoch 44/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.9230Restoring model weights from the end of the best epoch: 34.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3494 - acc: 0.9230 - val_loss: 0.4457 - val_acc: 0.9096\n",
      "Epoch 44: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 13s 38ms/step - loss: 1.0476 - acc: 0.8470 - val_loss: 0.7277 - val_acc: 0.8691\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7950 - acc: 0.8636 - val_loss: 0.6947 - val_acc: 0.8731\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7450 - acc: 0.8660 - val_loss: 0.6565 - val_acc: 0.8752\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7014 - acc: 0.8698 - val_loss: 0.6158 - val_acc: 0.8801\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6720 - acc: 0.8729 - val_loss: 0.5965 - val_acc: 0.8828\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6408 - acc: 0.8776 - val_loss: 0.5636 - val_acc: 0.8883\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6109 - acc: 0.8821 - val_loss: 0.5370 - val_acc: 0.8928\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5868 - acc: 0.8855 - val_loss: 0.5178 - val_acc: 0.8956\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5675 - acc: 0.8881 - val_loss: 0.5058 - val_acc: 0.8977\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5543 - acc: 0.8901 - val_loss: 0.4999 - val_acc: 0.8978\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5412 - acc: 0.8917 - val_loss: 0.4812 - val_acc: 0.9013\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5309 - acc: 0.8937 - val_loss: 0.4802 - val_acc: 0.9017\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5215 - acc: 0.8948 - val_loss: 0.4697 - val_acc: 0.9027\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5141 - acc: 0.8959 - val_loss: 0.4660 - val_acc: 0.9039\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5054 - acc: 0.8975 - val_loss: 0.4649 - val_acc: 0.9033\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4984 - acc: 0.8984 - val_loss: 0.4580 - val_acc: 0.9047\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4905 - acc: 0.8996 - val_loss: 0.4529 - val_acc: 0.9057\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4842 - acc: 0.9006 - val_loss: 0.4470 - val_acc: 0.9062\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4793 - acc: 0.9014 - val_loss: 0.4442 - val_acc: 0.9075\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4738 - acc: 0.9023 - val_loss: 0.4425 - val_acc: 0.9073\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4690 - acc: 0.9028 - val_loss: 0.4395 - val_acc: 0.9084\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4628 - acc: 0.9038 - val_loss: 0.4321 - val_acc: 0.9098\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4577 - acc: 0.9045 - val_loss: 0.4310 - val_acc: 0.9090\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4537 - acc: 0.9051 - val_loss: 0.4326 - val_acc: 0.9098\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4496 - acc: 0.9061 - val_loss: 0.4316 - val_acc: 0.9097\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4445 - acc: 0.9066 - val_loss: 0.4237 - val_acc: 0.9114\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4407 - acc: 0.9073 - val_loss: 0.4260 - val_acc: 0.9111\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4366 - acc: 0.9078 - val_loss: 0.4261 - val_acc: 0.9110\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4313 - acc: 0.9088 - val_loss: 0.4232 - val_acc: 0.9118\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4284 - acc: 0.9096 - val_loss: 0.4267 - val_acc: 0.9106\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4229 - acc: 0.9101 - val_loss: 0.4209 - val_acc: 0.9124\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4205 - acc: 0.9108 - val_loss: 0.4194 - val_acc: 0.9124\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4163 - acc: 0.9113 - val_loss: 0.4190 - val_acc: 0.9124\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4121 - acc: 0.9121 - val_loss: 0.4220 - val_acc: 0.9124\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4086 - acc: 0.9127 - val_loss: 0.4285 - val_acc: 0.9124\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4041 - acc: 0.9135 - val_loss: 0.4266 - val_acc: 0.9128\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4026 - acc: 0.9139 - val_loss: 0.4154 - val_acc: 0.9139\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3979 - acc: 0.9148 - val_loss: 0.4185 - val_acc: 0.9129\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3914 - acc: 0.9157 - val_loss: 0.4267 - val_acc: 0.9128\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3889 - acc: 0.9157 - val_loss: 0.4175 - val_acc: 0.9136\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3877 - acc: 0.9161 - val_loss: 0.4179 - val_acc: 0.9145\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3830 - acc: 0.9169 - val_loss: 0.4227 - val_acc: 0.9145\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3793 - acc: 0.9174 - val_loss: 0.4164 - val_acc: 0.9147\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3740 - acc: 0.9187 - val_loss: 0.4163 - val_acc: 0.9148\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3738 - acc: 0.9189 - val_loss: 0.4192 - val_acc: 0.9141\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3659 - acc: 0.9202 - val_loss: 0.4202 - val_acc: 0.9141\n",
      "Epoch 47/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.3660 - acc: 0.9198Restoring model weights from the end of the best epoch: 37.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3660 - acc: 0.9198 - val_loss: 0.4201 - val_acc: 0.9144\n",
      "Epoch 47: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.8\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 34ms/step - loss: 1.0229 - acc: 0.8491 - val_loss: 0.7497 - val_acc: 0.8646\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 4s 20ms/step - loss: 0.7828 - acc: 0.8653 - val_loss: 0.7026 - val_acc: 0.8694\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7216 - acc: 0.8685 - val_loss: 0.6588 - val_acc: 0.8738\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6749 - acc: 0.8733 - val_loss: 0.6153 - val_acc: 0.8799\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6420 - acc: 0.8774 - val_loss: 0.5878 - val_acc: 0.8845\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6097 - acc: 0.8820 - val_loss: 0.5539 - val_acc: 0.8894\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5806 - acc: 0.8868 - val_loss: 0.5325 - val_acc: 0.8931\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5622 - acc: 0.8895 - val_loss: 0.5225 - val_acc: 0.8943\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5457 - acc: 0.8920 - val_loss: 0.5063 - val_acc: 0.8966\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5313 - acc: 0.8943 - val_loss: 0.5051 - val_acc: 0.8955\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5184 - acc: 0.8957 - val_loss: 0.4882 - val_acc: 0.9000\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5106 - acc: 0.8971 - val_loss: 0.4867 - val_acc: 0.9002\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5017 - acc: 0.8984 - val_loss: 0.4794 - val_acc: 0.9018\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4931 - acc: 0.8998 - val_loss: 0.4783 - val_acc: 0.9026\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4854 - acc: 0.9011 - val_loss: 0.4716 - val_acc: 0.9032\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4780 - acc: 0.9022 - val_loss: 0.4679 - val_acc: 0.9043\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.4692 - acc: 0.9032 - val_loss: 0.4606 - val_acc: 0.9042\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4638 - acc: 0.9045 - val_loss: 0.4604 - val_acc: 0.9045\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.4578 - acc: 0.9049 - val_loss: 0.4560 - val_acc: 0.9062\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4507 - acc: 0.9063 - val_loss: 0.4519 - val_acc: 0.9062\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4474 - acc: 0.9070 - val_loss: 0.4510 - val_acc: 0.9064\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4414 - acc: 0.9077 - val_loss: 0.4464 - val_acc: 0.9073\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4353 - acc: 0.9090 - val_loss: 0.4449 - val_acc: 0.9076\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4297 - acc: 0.9097 - val_loss: 0.4493 - val_acc: 0.9077\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4273 - acc: 0.9100 - val_loss: 0.4435 - val_acc: 0.9079\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4217 - acc: 0.9108 - val_loss: 0.4385 - val_acc: 0.9091\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4168 - acc: 0.9116 - val_loss: 0.4392 - val_acc: 0.9087\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4144 - acc: 0.9122 - val_loss: 0.4365 - val_acc: 0.9088\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4080 - acc: 0.9131 - val_loss: 0.4410 - val_acc: 0.9086\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4044 - acc: 0.9137 - val_loss: 0.4486 - val_acc: 0.9098\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4001 - acc: 0.9141 - val_loss: 0.4382 - val_acc: 0.9089\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3951 - acc: 0.9150 - val_loss: 0.4387 - val_acc: 0.9090\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3913 - acc: 0.9156 - val_loss: 0.4410 - val_acc: 0.9092\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3869 - acc: 0.9167 - val_loss: 0.4396 - val_acc: 0.9101\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3815 - acc: 0.9173 - val_loss: 0.4376 - val_acc: 0.9101\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3787 - acc: 0.9179 - val_loss: 0.4444 - val_acc: 0.9094\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.3755 - acc: 0.9184 - val_loss: 0.4432 - val_acc: 0.9108\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.3720 - acc: 0.9190Restoring model weights from the end of the best epoch: 28.\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.3720 - acc: 0.9190 - val_loss: 0.4367 - val_acc: 0.9113\n",
      "Epoch 38: early stopping\n",
      "[0.4287463128566742, 0.43268272280693054, 0.4349914789199829, 0.41540294885635376, 0.4365358352661133]\n",
      "[31, 49, 34, 37, 28]\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 1/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 36ms/step - loss: 1.1740 - acc: 0.8436 - val_loss: 0.7725 - val_acc: 0.8635\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8381 - acc: 0.8620 - val_loss: 0.7412 - val_acc: 0.8665\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7895 - acc: 0.8650 - val_loss: 0.7242 - val_acc: 0.8665\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7603 - acc: 0.8662 - val_loss: 0.6956 - val_acc: 0.8704\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7330 - acc: 0.8680 - val_loss: 0.6672 - val_acc: 0.8731\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7035 - acc: 0.8707 - val_loss: 0.6427 - val_acc: 0.8756\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6964 - acc: 0.8712 - val_loss: 0.6321 - val_acc: 0.8767\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6639 - acc: 0.8751 - val_loss: 0.6115 - val_acc: 0.8800\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6421 - acc: 0.8786 - val_loss: 0.5911 - val_acc: 0.8825\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6264 - acc: 0.8805 - val_loss: 0.5833 - val_acc: 0.8847\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6131 - acc: 0.8822 - val_loss: 0.5733 - val_acc: 0.8855\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6050 - acc: 0.8832 - val_loss: 0.5589 - val_acc: 0.8874\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5945 - acc: 0.8846 - val_loss: 0.5524 - val_acc: 0.8888\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5850 - acc: 0.8855 - val_loss: 0.5434 - val_acc: 0.8904\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5774 - acc: 0.8869 - val_loss: 0.5343 - val_acc: 0.8920\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5709 - acc: 0.8876 - val_loss: 0.5364 - val_acc: 0.8914\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5661 - acc: 0.8886 - val_loss: 0.5365 - val_acc: 0.8917\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5583 - acc: 0.8900 - val_loss: 0.5259 - val_acc: 0.8931\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5543 - acc: 0.8905 - val_loss: 0.5197 - val_acc: 0.8951\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5498 - acc: 0.8910 - val_loss: 0.5185 - val_acc: 0.8954\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5594 - acc: 0.8900 - val_loss: 0.5147 - val_acc: 0.8955\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5412 - acc: 0.8929 - val_loss: 0.5063 - val_acc: 0.8965\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5352 - acc: 0.8938 - val_loss: 0.5069 - val_acc: 0.8967\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5336 - acc: 0.8938 - val_loss: 0.5050 - val_acc: 0.8972\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5273 - acc: 0.8951 - val_loss: 0.5034 - val_acc: 0.8982\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5268 - acc: 0.8948 - val_loss: 0.5015 - val_acc: 0.8981\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5237 - acc: 0.8956 - val_loss: 0.4983 - val_acc: 0.8979\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5196 - acc: 0.8961 - val_loss: 0.4976 - val_acc: 0.8984\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5167 - acc: 0.8965 - val_loss: 0.4968 - val_acc: 0.8988\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5143 - acc: 0.8966 - val_loss: 0.4977 - val_acc: 0.8986\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5126 - acc: 0.8969 - val_loss: 0.5020 - val_acc: 0.8989\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5080 - acc: 0.8979 - val_loss: 0.4937 - val_acc: 0.8987\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5072 - acc: 0.8979 - val_loss: 0.4924 - val_acc: 0.8991\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5037 - acc: 0.8981 - val_loss: 0.4983 - val_acc: 0.8995\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5018 - acc: 0.8990 - val_loss: 0.4891 - val_acc: 0.9007\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4997 - acc: 0.8990 - val_loss: 0.4900 - val_acc: 0.9004\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4963 - acc: 0.8995 - val_loss: 0.4972 - val_acc: 0.8998\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4948 - acc: 0.8996 - val_loss: 0.4816 - val_acc: 0.9014\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4905 - acc: 0.9006 - val_loss: 0.4828 - val_acc: 0.9010\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4915 - acc: 0.9001 - val_loss: 0.4815 - val_acc: 0.9019\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4892 - acc: 0.9004 - val_loss: 0.4839 - val_acc: 0.9008\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4880 - acc: 0.9009 - val_loss: 0.4824 - val_acc: 0.9011\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4847 - acc: 0.9016 - val_loss: 0.4802 - val_acc: 0.9006\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4820 - acc: 0.9018 - val_loss: 0.4771 - val_acc: 0.9023\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4804 - acc: 0.9020 - val_loss: 0.4764 - val_acc: 0.9025\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4769 - acc: 0.9026 - val_loss: 0.4758 - val_acc: 0.9023\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4765 - acc: 0.9028 - val_loss: 0.4830 - val_acc: 0.9026\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4734 - acc: 0.9034 - val_loss: 0.4723 - val_acc: 0.9033\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4722 - acc: 0.9035 - val_loss: 0.4768 - val_acc: 0.9020\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4686 - acc: 0.9041 - val_loss: 0.4718 - val_acc: 0.9031\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4705 - acc: 0.9037 - val_loss: 0.4812 - val_acc: 0.9024\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4646 - acc: 0.9044 - val_loss: 0.4709 - val_acc: 0.9044\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4617 - acc: 0.9050 - val_loss: 0.4709 - val_acc: 0.9035\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4599 - acc: 0.9052 - val_loss: 0.4747 - val_acc: 0.9032\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4593 - acc: 0.9053 - val_loss: 0.4707 - val_acc: 0.9042\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4569 - acc: 0.9060 - val_loss: 0.4672 - val_acc: 0.9045\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4547 - acc: 0.9063 - val_loss: 0.4691 - val_acc: 0.9050\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4520 - acc: 0.9069 - val_loss: 0.4687 - val_acc: 0.9049\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4513 - acc: 0.9066 - val_loss: 0.4694 - val_acc: 0.9042\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4504 - acc: 0.9069 - val_loss: 0.4718 - val_acc: 0.9052\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4484 - acc: 0.9077 - val_loss: 0.4671 - val_acc: 0.9049\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4444 - acc: 0.9075 - val_loss: 0.4736 - val_acc: 0.9051\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4435 - acc: 0.9079 - val_loss: 0.4740 - val_acc: 0.9050\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4418 - acc: 0.9083 - val_loss: 0.4714 - val_acc: 0.9052\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4408 - acc: 0.9085 - val_loss: 0.4696 - val_acc: 0.9050\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4377 - acc: 0.9090 - val_loss: 0.4711 - val_acc: 0.9060\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4356 - acc: 0.9091 - val_loss: 0.4671 - val_acc: 0.9058\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4351 - acc: 0.9092 - val_loss: 0.4686 - val_acc: 0.9058\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4314 - acc: 0.9101 - val_loss: 0.4709 - val_acc: 0.9056\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4311 - acc: 0.9101 - val_loss: 0.4741 - val_acc: 0.9057\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4277 - acc: 0.9109 - val_loss: 0.4711 - val_acc: 0.9057\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4271 - acc: 0.9104 - val_loss: 0.4698 - val_acc: 0.9063\n",
      "Epoch 73/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4241 - acc: 0.9114 - val_loss: 0.4709 - val_acc: 0.9063\n",
      "Epoch 74/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4225 - acc: 0.9115 - val_loss: 0.4758 - val_acc: 0.9057\n",
      "Epoch 75/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4230 - acc: 0.9116 - val_loss: 0.4691 - val_acc: 0.9055\n",
      "Epoch 76/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4194 - acc: 0.9120 - val_loss: 0.4673 - val_acc: 0.9063\n",
      "Epoch 77/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4168 - acc: 0.9125Restoring model weights from the end of the best epoch: 67.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4173 - acc: 0.9124 - val_loss: 0.4788 - val_acc: 0.9067\n",
      "Epoch 77: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 2/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 1.1774 - acc: 0.8444 - val_loss: 0.7832 - val_acc: 0.8617\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8335 - acc: 0.8627 - val_loss: 0.7465 - val_acc: 0.8641\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7864 - acc: 0.8654 - val_loss: 0.7154 - val_acc: 0.8670\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7507 - acc: 0.8670 - val_loss: 0.6830 - val_acc: 0.8702\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.7204 - acc: 0.8687 - val_loss: 0.6586 - val_acc: 0.8732\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6950 - acc: 0.8715 - val_loss: 0.6393 - val_acc: 0.8751\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6753 - acc: 0.8735 - val_loss: 0.6188 - val_acc: 0.8769\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6562 - acc: 0.8757 - val_loss: 0.6023 - val_acc: 0.8813\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6387 - acc: 0.8789 - val_loss: 0.5855 - val_acc: 0.8834\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6208 - acc: 0.8813 - val_loss: 0.5718 - val_acc: 0.8862\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6092 - acc: 0.8832 - val_loss: 0.5591 - val_acc: 0.8872\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6111 - acc: 0.8822 - val_loss: 0.5571 - val_acc: 0.8876\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5914 - acc: 0.8851 - val_loss: 0.5406 - val_acc: 0.8907\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5789 - acc: 0.8873 - val_loss: 0.5440 - val_acc: 0.8898\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5721 - acc: 0.8885 - val_loss: 0.5304 - val_acc: 0.8926\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5627 - acc: 0.8900 - val_loss: 0.5298 - val_acc: 0.8928\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5589 - acc: 0.8902 - val_loss: 0.5213 - val_acc: 0.8937\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5517 - acc: 0.8915 - val_loss: 0.5185 - val_acc: 0.8944\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5464 - acc: 0.8923 - val_loss: 0.5225 - val_acc: 0.8935\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5451 - acc: 0.8925 - val_loss: 0.5098 - val_acc: 0.8957\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5379 - acc: 0.8936 - val_loss: 0.5079 - val_acc: 0.8958\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5328 - acc: 0.8947 - val_loss: 0.5080 - val_acc: 0.8960\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5299 - acc: 0.8947 - val_loss: 0.5030 - val_acc: 0.8970\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5242 - acc: 0.8956 - val_loss: 0.5026 - val_acc: 0.8969\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5225 - acc: 0.8963 - val_loss: 0.4948 - val_acc: 0.8983\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5188 - acc: 0.8965 - val_loss: 0.4967 - val_acc: 0.8978\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5163 - acc: 0.8966 - val_loss: 0.5002 - val_acc: 0.8978\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5134 - acc: 0.8974 - val_loss: 0.5025 - val_acc: 0.8970\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5106 - acc: 0.8978 - val_loss: 0.4940 - val_acc: 0.8984\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5070 - acc: 0.8983 - val_loss: 0.4902 - val_acc: 0.8988\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5040 - acc: 0.8990 - val_loss: 0.4913 - val_acc: 0.8983\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5013 - acc: 0.8992 - val_loss: 0.4871 - val_acc: 0.8995\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4987 - acc: 0.8998 - val_loss: 0.4856 - val_acc: 0.9002\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4967 - acc: 0.9003 - val_loss: 0.4873 - val_acc: 0.9000\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4943 - acc: 0.9008 - val_loss: 0.4848 - val_acc: 0.8997\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4908 - acc: 0.9011 - val_loss: 0.4788 - val_acc: 0.9003\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4874 - acc: 0.9018 - val_loss: 0.4774 - val_acc: 0.9016\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4863 - acc: 0.9018 - val_loss: 0.4848 - val_acc: 0.9013\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4856 - acc: 0.9015 - val_loss: 0.4758 - val_acc: 0.9018\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4820 - acc: 0.9024 - val_loss: 0.4813 - val_acc: 0.9016\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4796 - acc: 0.9028 - val_loss: 0.4808 - val_acc: 0.9014\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4760 - acc: 0.9033 - val_loss: 0.4874 - val_acc: 0.9000\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4724 - acc: 0.9041 - val_loss: 0.4729 - val_acc: 0.9035\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4719 - acc: 0.9043 - val_loss: 0.4716 - val_acc: 0.9030\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4699 - acc: 0.9048 - val_loss: 0.4692 - val_acc: 0.9033\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4700 - acc: 0.9044 - val_loss: 0.4757 - val_acc: 0.9035\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4654 - acc: 0.9051 - val_loss: 0.4701 - val_acc: 0.9035\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4632 - acc: 0.9061 - val_loss: 0.4662 - val_acc: 0.9051\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4610 - acc: 0.9060 - val_loss: 0.4708 - val_acc: 0.9035\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4589 - acc: 0.9065 - val_loss: 0.4688 - val_acc: 0.9039\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4555 - acc: 0.9068 - val_loss: 0.4690 - val_acc: 0.9052\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4550 - acc: 0.9072 - val_loss: 0.4690 - val_acc: 0.9048\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4520 - acc: 0.9078 - val_loss: 0.4666 - val_acc: 0.9053\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4491 - acc: 0.9082 - val_loss: 0.4713 - val_acc: 0.9047\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4490 - acc: 0.9081 - val_loss: 0.4743 - val_acc: 0.9051\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4452 - acc: 0.9090 - val_loss: 0.4648 - val_acc: 0.9060\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4430 - acc: 0.9090 - val_loss: 0.4653 - val_acc: 0.9053\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4399 - acc: 0.9096 - val_loss: 0.4656 - val_acc: 0.9059\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4384 - acc: 0.9100 - val_loss: 0.4712 - val_acc: 0.9043\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4394 - acc: 0.9099 - val_loss: 0.4666 - val_acc: 0.9047\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4346 - acc: 0.9105 - val_loss: 0.4717 - val_acc: 0.9059\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4315 - acc: 0.9110 - val_loss: 0.4621 - val_acc: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4316 - acc: 0.9110 - val_loss: 0.4595 - val_acc: 0.9072\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4273 - acc: 0.9120 - val_loss: 0.4694 - val_acc: 0.9065\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4271 - acc: 0.9123 - val_loss: 0.4672 - val_acc: 0.9069\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4233 - acc: 0.9130 - val_loss: 0.4637 - val_acc: 0.9071\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4215 - acc: 0.9132 - val_loss: 0.4615 - val_acc: 0.9062\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4197 - acc: 0.9132 - val_loss: 0.4658 - val_acc: 0.9067\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4182 - acc: 0.9134 - val_loss: 0.4755 - val_acc: 0.9058\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4173 - acc: 0.9139 - val_loss: 0.4660 - val_acc: 0.9071\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4122 - acc: 0.9147 - val_loss: 0.4711 - val_acc: 0.9072\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4117 - acc: 0.9145 - val_loss: 0.4632 - val_acc: 0.9074\n",
      "Epoch 73/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4100 - acc: 0.9147Restoring model weights from the end of the best epoch: 63.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4096 - acc: 0.9148 - val_loss: 0.4748 - val_acc: 0.9081\n",
      "Epoch 73: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 3/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 11s 35ms/step - loss: 1.1856 - acc: 0.8440 - val_loss: 0.7900 - val_acc: 0.8606\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8396 - acc: 0.8629 - val_loss: 0.7551 - val_acc: 0.8628\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7895 - acc: 0.8656 - val_loss: 0.7395 - val_acc: 0.8636\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7568 - acc: 0.8668 - val_loss: 0.7016 - val_acc: 0.8669\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7285 - acc: 0.8685 - val_loss: 0.6817 - val_acc: 0.8695\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7044 - acc: 0.8704 - val_loss: 0.6533 - val_acc: 0.8726\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6825 - acc: 0.8731 - val_loss: 0.6316 - val_acc: 0.8764\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6696 - acc: 0.8746 - val_loss: 0.6251 - val_acc: 0.8762\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6460 - acc: 0.8776 - val_loss: 0.6041 - val_acc: 0.8793\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6291 - acc: 0.8803 - val_loss: 0.5940 - val_acc: 0.8816\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6188 - acc: 0.8812 - val_loss: 0.5855 - val_acc: 0.8821\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6044 - acc: 0.8834 - val_loss: 0.5693 - val_acc: 0.8849\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5966 - acc: 0.8842 - val_loss: 0.5627 - val_acc: 0.8857\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5897 - acc: 0.8849 - val_loss: 0.5598 - val_acc: 0.8858\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5804 - acc: 0.8862 - val_loss: 0.5497 - val_acc: 0.8880\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5748 - acc: 0.8871 - val_loss: 0.5423 - val_acc: 0.8899\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5680 - acc: 0.8878 - val_loss: 0.5371 - val_acc: 0.8905\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5623 - acc: 0.8893 - val_loss: 0.5336 - val_acc: 0.8917\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5569 - acc: 0.8899 - val_loss: 0.5323 - val_acc: 0.8911\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5545 - acc: 0.8901 - val_loss: 0.5405 - val_acc: 0.8912\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5497 - acc: 0.8910 - val_loss: 0.5264 - val_acc: 0.8915\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5426 - acc: 0.8923 - val_loss: 0.5264 - val_acc: 0.8933\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5387 - acc: 0.8928 - val_loss: 0.5241 - val_acc: 0.8929\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5399 - acc: 0.8927 - val_loss: 0.5138 - val_acc: 0.8949\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5336 - acc: 0.8938 - val_loss: 0.5126 - val_acc: 0.8954\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5282 - acc: 0.8948 - val_loss: 0.5175 - val_acc: 0.8936\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5274 - acc: 0.8946 - val_loss: 0.5092 - val_acc: 0.8952\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5219 - acc: 0.8957 - val_loss: 0.5045 - val_acc: 0.8963\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5181 - acc: 0.8960 - val_loss: 0.5050 - val_acc: 0.8965\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5186 - acc: 0.8962 - val_loss: 0.5052 - val_acc: 0.8956\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5137 - acc: 0.8969 - val_loss: 0.4993 - val_acc: 0.8970\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5104 - acc: 0.8975 - val_loss: 0.5048 - val_acc: 0.8958\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5093 - acc: 0.8977 - val_loss: 0.5052 - val_acc: 0.8962\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5077 - acc: 0.8977 - val_loss: 0.4993 - val_acc: 0.8975\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5038 - acc: 0.8982 - val_loss: 0.4965 - val_acc: 0.8970\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5026 - acc: 0.8984 - val_loss: 0.4976 - val_acc: 0.8975\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4999 - acc: 0.8993 - val_loss: 0.4953 - val_acc: 0.8977\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4980 - acc: 0.8992 - val_loss: 0.4947 - val_acc: 0.8978\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4967 - acc: 0.8995 - val_loss: 0.4972 - val_acc: 0.8974\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4947 - acc: 0.8997 - val_loss: 0.4939 - val_acc: 0.8984\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4933 - acc: 0.9003 - val_loss: 0.4927 - val_acc: 0.8979\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4883 - acc: 0.9008 - val_loss: 0.4963 - val_acc: 0.8989\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4876 - acc: 0.9005 - val_loss: 0.4895 - val_acc: 0.8988\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4845 - acc: 0.9013 - val_loss: 0.4874 - val_acc: 0.8991\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4830 - acc: 0.9015 - val_loss: 0.4859 - val_acc: 0.8997\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4803 - acc: 0.9019 - val_loss: 0.4881 - val_acc: 0.8993\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4785 - acc: 0.9024 - val_loss: 0.4870 - val_acc: 0.9002\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4796 - acc: 0.9023 - val_loss: 0.4829 - val_acc: 0.9002\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4746 - acc: 0.9026 - val_loss: 0.4886 - val_acc: 0.9003\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4747 - acc: 0.9030 - val_loss: 0.4848 - val_acc: 0.8997\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4711 - acc: 0.9034 - val_loss: 0.4863 - val_acc: 0.8984\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4717 - acc: 0.9031 - val_loss: 0.5277 - val_acc: 0.8927\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4708 - acc: 0.9036 - val_loss: 0.4822 - val_acc: 0.9011\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4657 - acc: 0.9042 - val_loss: 0.4816 - val_acc: 0.9005\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4646 - acc: 0.9044 - val_loss: 0.4807 - val_acc: 0.9006\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4603 - acc: 0.9050 - val_loss: 0.4796 - val_acc: 0.9015\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4607 - acc: 0.9051 - val_loss: 0.4828 - val_acc: 0.9015\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4576 - acc: 0.9058 - val_loss: 0.4795 - val_acc: 0.9017\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4565 - acc: 0.9054 - val_loss: 0.4845 - val_acc: 0.9010\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4534 - acc: 0.9064 - val_loss: 0.4836 - val_acc: 0.9008\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4523 - acc: 0.9061 - val_loss: 0.4784 - val_acc: 0.9012\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4503 - acc: 0.9063 - val_loss: 0.4780 - val_acc: 0.9024\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4501 - acc: 0.9066 - val_loss: 0.4852 - val_acc: 0.9016\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4477 - acc: 0.9073 - val_loss: 0.4811 - val_acc: 0.9018\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4456 - acc: 0.9075 - val_loss: 0.4800 - val_acc: 0.9008\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4442 - acc: 0.9076 - val_loss: 0.4813 - val_acc: 0.9033\n",
      "Epoch 67/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4433 - acc: 0.9077 - val_loss: 0.4786 - val_acc: 0.9019\n",
      "Epoch 68/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4398 - acc: 0.9085 - val_loss: 0.4868 - val_acc: 0.9020\n",
      "Epoch 69/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4421 - acc: 0.9082 - val_loss: 0.4787 - val_acc: 0.9033\n",
      "Epoch 70/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4358 - acc: 0.9089 - val_loss: 0.4790 - val_acc: 0.9014\n",
      "Epoch 71/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4341 - acc: 0.9091 - val_loss: 0.4789 - val_acc: 0.9017\n",
      "Epoch 72/200\n",
      "191/191 [==============================] - ETA: 0s - loss: 0.4335 - acc: 0.9092Restoring model weights from the end of the best epoch: 62.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4335 - acc: 0.9092 - val_loss: 0.4802 - val_acc: 0.9027\n",
      "Epoch 72: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 4/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 36ms/step - loss: 1.2086 - acc: 0.8409 - val_loss: 0.7515 - val_acc: 0.8677\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.8443 - acc: 0.8613 - val_loss: 0.7245 - val_acc: 0.8695\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8005 - acc: 0.8635 - val_loss: 0.7016 - val_acc: 0.8711\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7692 - acc: 0.8649 - val_loss: 0.6825 - val_acc: 0.8740\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7418 - acc: 0.8664 - val_loss: 0.6611 - val_acc: 0.8748\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7206 - acc: 0.8678 - val_loss: 0.6336 - val_acc: 0.8788\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6953 - acc: 0.8712 - val_loss: 0.6089 - val_acc: 0.8815\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6662 - acc: 0.8753 - val_loss: 0.5846 - val_acc: 0.8854\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.6461 - acc: 0.8778 - val_loss: 0.5741 - val_acc: 0.8872\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6318 - acc: 0.8795 - val_loss: 0.5589 - val_acc: 0.8896\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6186 - acc: 0.8817 - val_loss: 0.5490 - val_acc: 0.8910\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6081 - acc: 0.8826 - val_loss: 0.5394 - val_acc: 0.8925\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5978 - acc: 0.8841 - val_loss: 0.5344 - val_acc: 0.8930\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5912 - acc: 0.8852 - val_loss: 0.5270 - val_acc: 0.8947\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5817 - acc: 0.8859 - val_loss: 0.5183 - val_acc: 0.8959\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5780 - acc: 0.8864 - val_loss: 0.5143 - val_acc: 0.8957\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5682 - acc: 0.8876 - val_loss: 0.5107 - val_acc: 0.8961\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5614 - acc: 0.8893 - val_loss: 0.5036 - val_acc: 0.8982\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5595 - acc: 0.8896 - val_loss: 0.4972 - val_acc: 0.8989\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5511 - acc: 0.8910 - val_loss: 0.4970 - val_acc: 0.8993\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5454 - acc: 0.8919 - val_loss: 0.4916 - val_acc: 0.9007\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5394 - acc: 0.8928 - val_loss: 0.4850 - val_acc: 0.9018\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5371 - acc: 0.8935 - val_loss: 0.4843 - val_acc: 0.9019\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5313 - acc: 0.8944 - val_loss: 0.4802 - val_acc: 0.9021\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5263 - acc: 0.8951 - val_loss: 0.4800 - val_acc: 0.9031\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5237 - acc: 0.8956 - val_loss: 0.4767 - val_acc: 0.9026\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5218 - acc: 0.8961 - val_loss: 0.4762 - val_acc: 0.9032\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5164 - acc: 0.8966 - val_loss: 0.4772 - val_acc: 0.9027\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5133 - acc: 0.8969 - val_loss: 0.4739 - val_acc: 0.9039\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5104 - acc: 0.8979 - val_loss: 0.4710 - val_acc: 0.9041\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5072 - acc: 0.8980 - val_loss: 0.4665 - val_acc: 0.9048\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5037 - acc: 0.8986 - val_loss: 0.4645 - val_acc: 0.9049\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5015 - acc: 0.8990 - val_loss: 0.4625 - val_acc: 0.9051\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5103 - acc: 0.8978 - val_loss: 0.4754 - val_acc: 0.9030\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5000 - acc: 0.8994 - val_loss: 0.4608 - val_acc: 0.9050\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4925 - acc: 0.9005 - val_loss: 0.4590 - val_acc: 0.9053\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4887 - acc: 0.9013 - val_loss: 0.4620 - val_acc: 0.9066\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4866 - acc: 0.9017 - val_loss: 0.4562 - val_acc: 0.9062\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4833 - acc: 0.9018 - val_loss: 0.4557 - val_acc: 0.9063\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4812 - acc: 0.9025 - val_loss: 0.4569 - val_acc: 0.9063\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4813 - acc: 0.9024 - val_loss: 0.4565 - val_acc: 0.9063\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4777 - acc: 0.9030 - val_loss: 0.4530 - val_acc: 0.9072\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4760 - acc: 0.9031 - val_loss: 0.4558 - val_acc: 0.9066\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4734 - acc: 0.9035 - val_loss: 0.4531 - val_acc: 0.9068\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4720 - acc: 0.9039 - val_loss: 0.4514 - val_acc: 0.9075\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4675 - acc: 0.9046 - val_loss: 0.4531 - val_acc: 0.9078\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4657 - acc: 0.9048 - val_loss: 0.4527 - val_acc: 0.9076\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4642 - acc: 0.9049 - val_loss: 0.4519 - val_acc: 0.9079\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4625 - acc: 0.9054 - val_loss: 0.4500 - val_acc: 0.9082\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4567 - acc: 0.9062 - val_loss: 0.4568 - val_acc: 0.9070\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4560 - acc: 0.9065 - val_loss: 0.4597 - val_acc: 0.9079\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4540 - acc: 0.9067 - val_loss: 0.4505 - val_acc: 0.9088\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4512 - acc: 0.9075 - val_loss: 0.4486 - val_acc: 0.9086\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4490 - acc: 0.9077 - val_loss: 0.4511 - val_acc: 0.9088\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4461 - acc: 0.9080 - val_loss: 0.4528 - val_acc: 0.9085\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4451 - acc: 0.9082 - val_loss: 0.4525 - val_acc: 0.9094\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4417 - acc: 0.9088 - val_loss: 0.4558 - val_acc: 0.9093\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4387 - acc: 0.9093 - val_loss: 0.4532 - val_acc: 0.9090\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4352 - acc: 0.9099 - val_loss: 0.4517 - val_acc: 0.9095\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4333 - acc: 0.9101 - val_loss: 0.4534 - val_acc: 0.9088\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4316 - acc: 0.9103 - val_loss: 0.4527 - val_acc: 0.9080\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4298 - acc: 0.9110 - val_loss: 0.4499 - val_acc: 0.9100\n",
      "Epoch 63/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4253 - acc: 0.9116Restoring model weights from the end of the best epoch: 53.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4257 - acc: 0.9115 - val_loss: 0.4546 - val_acc: 0.9090\n",
      "Epoch 63: early stopping\n",
      "Current Latent Dim: 1024\n",
      "Current Dropout Rate:  0.9\n",
      "Current Fold: 5/5\n",
      "Current Learning Rate:  0.0002\n",
      "Current Learning Rate Multiplier:  1.0\n",
      "Embeddings loaded.\n",
      "Epoch 1/200\n",
      "191/191 [==============================] - 12s 37ms/step - loss: 1.1654 - acc: 0.8443 - val_loss: 0.7744 - val_acc: 0.8628\n",
      "Epoch 2/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.8352 - acc: 0.8627 - val_loss: 0.7399 - val_acc: 0.8657\n",
      "Epoch 3/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7841 - acc: 0.8652 - val_loss: 0.7040 - val_acc: 0.8683\n",
      "Epoch 4/200\n",
      "191/191 [==============================] - 4s 18ms/step - loss: 0.7489 - acc: 0.8666 - val_loss: 0.6800 - val_acc: 0.8701\n",
      "Epoch 5/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.7216 - acc: 0.8683 - val_loss: 0.6552 - val_acc: 0.8731\n",
      "Epoch 6/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6950 - acc: 0.8712 - val_loss: 0.6312 - val_acc: 0.8771\n",
      "Epoch 7/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6725 - acc: 0.8741 - val_loss: 0.6166 - val_acc: 0.8799\n",
      "Epoch 8/200\n",
      "191/191 [==============================] - 4s 19ms/step - loss: 0.6523 - acc: 0.8771 - val_loss: 0.5964 - val_acc: 0.8814\n",
      "Epoch 9/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6362 - acc: 0.8787 - val_loss: 0.5841 - val_acc: 0.8829\n",
      "Epoch 10/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6203 - acc: 0.8808 - val_loss: 0.5706 - val_acc: 0.8845\n",
      "Epoch 11/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6097 - acc: 0.8820 - val_loss: 0.5647 - val_acc: 0.8870\n",
      "Epoch 12/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5993 - acc: 0.8834 - val_loss: 0.5522 - val_acc: 0.8885\n",
      "Epoch 13/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.5899 - acc: 0.8845 - val_loss: 0.5509 - val_acc: 0.8892\n",
      "Epoch 14/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5820 - acc: 0.8859 - val_loss: 0.5411 - val_acc: 0.8908\n",
      "Epoch 15/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5729 - acc: 0.8873 - val_loss: 0.5386 - val_acc: 0.8905\n",
      "Epoch 16/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5671 - acc: 0.8882 - val_loss: 0.5302 - val_acc: 0.8925\n",
      "Epoch 17/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5608 - acc: 0.8892 - val_loss: 0.5238 - val_acc: 0.8937\n",
      "Epoch 18/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5542 - acc: 0.8903 - val_loss: 0.5291 - val_acc: 0.8926\n",
      "Epoch 19/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5508 - acc: 0.8908 - val_loss: 0.5166 - val_acc: 0.8947\n",
      "Epoch 20/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.6178 - acc: 0.8807 - val_loss: 0.5308 - val_acc: 0.8920\n",
      "Epoch 21/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5500 - acc: 0.8906 - val_loss: 0.5125 - val_acc: 0.8954\n",
      "Epoch 22/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5396 - acc: 0.8924 - val_loss: 0.5133 - val_acc: 0.8954\n",
      "Epoch 23/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5343 - acc: 0.8936 - val_loss: 0.5074 - val_acc: 0.8973\n",
      "Epoch 24/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5291 - acc: 0.8945 - val_loss: 0.5031 - val_acc: 0.8976\n",
      "Epoch 25/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5255 - acc: 0.8953 - val_loss: 0.5023 - val_acc: 0.8967\n",
      "Epoch 26/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5200 - acc: 0.8958 - val_loss: 0.4965 - val_acc: 0.8993\n",
      "Epoch 27/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5171 - acc: 0.8963 - val_loss: 0.4931 - val_acc: 0.8999\n",
      "Epoch 28/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5146 - acc: 0.8969 - val_loss: 0.5051 - val_acc: 0.8982\n",
      "Epoch 29/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5128 - acc: 0.8973 - val_loss: 0.4969 - val_acc: 0.8990\n",
      "Epoch 30/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5087 - acc: 0.8978 - val_loss: 0.4921 - val_acc: 0.8992\n",
      "Epoch 31/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5093 - acc: 0.8980 - val_loss: 0.4901 - val_acc: 0.9009\n",
      "Epoch 32/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5027 - acc: 0.8989 - val_loss: 0.4886 - val_acc: 0.8999\n",
      "Epoch 33/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.5017 - acc: 0.8992 - val_loss: 0.4889 - val_acc: 0.9011\n",
      "Epoch 34/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4999 - acc: 0.8990 - val_loss: 0.4858 - val_acc: 0.9010\n",
      "Epoch 35/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4989 - acc: 0.8994 - val_loss: 0.4904 - val_acc: 0.9005\n",
      "Epoch 36/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4956 - acc: 0.8999 - val_loss: 0.4922 - val_acc: 0.9004\n",
      "Epoch 37/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4923 - acc: 0.9006 - val_loss: 0.4841 - val_acc: 0.9019\n",
      "Epoch 38/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4902 - acc: 0.9007 - val_loss: 0.4806 - val_acc: 0.9020\n",
      "Epoch 39/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4878 - acc: 0.9012 - val_loss: 0.4808 - val_acc: 0.9029\n",
      "Epoch 40/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4861 - acc: 0.9015 - val_loss: 0.4786 - val_acc: 0.9019\n",
      "Epoch 41/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4833 - acc: 0.9019 - val_loss: 0.4826 - val_acc: 0.9024\n",
      "Epoch 42/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4817 - acc: 0.9025 - val_loss: 0.4765 - val_acc: 0.9033\n",
      "Epoch 43/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4818 - acc: 0.9021 - val_loss: 0.4746 - val_acc: 0.9029\n",
      "Epoch 44/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4774 - acc: 0.9031 - val_loss: 0.4755 - val_acc: 0.9033\n",
      "Epoch 45/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4746 - acc: 0.9031 - val_loss: 0.4734 - val_acc: 0.9037\n",
      "Epoch 46/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4744 - acc: 0.9032 - val_loss: 0.4773 - val_acc: 0.9037\n",
      "Epoch 47/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4721 - acc: 0.9037 - val_loss: 0.4734 - val_acc: 0.9039\n",
      "Epoch 48/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4688 - acc: 0.9040 - val_loss: 0.4740 - val_acc: 0.9038\n",
      "Epoch 49/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4665 - acc: 0.9043 - val_loss: 0.4721 - val_acc: 0.9041\n",
      "Epoch 50/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4635 - acc: 0.9051 - val_loss: 0.4757 - val_acc: 0.9039\n",
      "Epoch 51/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4647 - acc: 0.9050 - val_loss: 0.4764 - val_acc: 0.9038\n",
      "Epoch 52/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4614 - acc: 0.9054 - val_loss: 0.4724 - val_acc: 0.9050\n",
      "Epoch 53/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4603 - acc: 0.9058 - val_loss: 0.4718 - val_acc: 0.9048\n",
      "Epoch 54/200\n",
      "191/191 [==============================] - 3s 18ms/step - loss: 0.4583 - acc: 0.9060 - val_loss: 0.4693 - val_acc: 0.9052\n",
      "Epoch 55/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4562 - acc: 0.9064 - val_loss: 0.4737 - val_acc: 0.9026\n",
      "Epoch 56/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4598 - acc: 0.9056 - val_loss: 0.4710 - val_acc: 0.9047\n",
      "Epoch 57/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4522 - acc: 0.9070 - val_loss: 0.4653 - val_acc: 0.9051\n",
      "Epoch 58/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4527 - acc: 0.9069 - val_loss: 0.4659 - val_acc: 0.9047\n",
      "Epoch 59/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4492 - acc: 0.9069 - val_loss: 0.4669 - val_acc: 0.9053\n",
      "Epoch 60/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4471 - acc: 0.9077 - val_loss: 0.4657 - val_acc: 0.9055\n",
      "Epoch 61/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4452 - acc: 0.9079 - val_loss: 0.4684 - val_acc: 0.9063\n",
      "Epoch 62/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4421 - acc: 0.9084 - val_loss: 0.4683 - val_acc: 0.9064\n",
      "Epoch 63/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4422 - acc: 0.9085 - val_loss: 0.4670 - val_acc: 0.9052\n",
      "Epoch 64/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4405 - acc: 0.9090 - val_loss: 0.4725 - val_acc: 0.9062\n",
      "Epoch 65/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4380 - acc: 0.9094 - val_loss: 0.4672 - val_acc: 0.9062\n",
      "Epoch 66/200\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4372 - acc: 0.9095 - val_loss: 0.4660 - val_acc: 0.9067\n",
      "Epoch 67/200\n",
      "189/191 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.9097Restoring model weights from the end of the best epoch: 57.\n",
      "191/191 [==============================] - 3s 17ms/step - loss: 0.4363 - acc: 0.9097 - val_loss: 0.4663 - val_acc: 0.9066\n",
      "Epoch 67: early stopping\n",
      "[0.4670772850513458, 0.45947229862213135, 0.47801992297172546, 0.44863447546958923, 0.46532389521598816]\n",
      "[67, 63, 62, 53, 57]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = cv_grid_search(df_train_val, dropout_rates, latent_dims, epochs = 200, learning_rate = learning_rate, folds = folds)\n",
    "average_bleu4 = np.mean(metrics['smooth_bleu4'], axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d4021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Average smooth BLEU4, crossvalidated')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.xticks(range(len(dropout_rates)), dropout_rates)\n",
    "plt.ylabel('Latent Dim')\n",
    "plt.yticks(range(len(latent_dims)),latent_dims)\n",
    "plt.imshow(average_bleu4)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85cbd152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best latent dimension:  512\n",
      "Best dropout rate:  0.5\n"
     ]
    }
   ],
   "source": [
    "best_config_index = np.unravel_index(np.argmax(average_bleu4), average_bleu4.shape)\n",
    "best_latent_dim = latent_dims[best_config_index[0]]\n",
    "best_dropout_rate = dropout_rates[best_config_index[1]]\n",
    "print(\"Best latent dimension: \", best_latent_dim)\n",
    "print(\"Best dropout rate: \", best_dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4329fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_latent_dim = 512\n",
    "best_fropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ffb5f",
   "metadata": {},
   "source": [
    "## Finalni model za evaluaciju\n",
    "\n",
    "Na kraju koristimo kombinovani trening i validacioni skup da istreniramo konacan model za evaluaciju.\n",
    "\n",
    "Izdvajamo mali deo ovog skupa (300 redova) za validaciju tokom treniranja, da bismo znali kad da prekinemo trening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b41b29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val_np = df_train_val.to_numpy()\n",
    "np.random.shuffle(df_train_val_np)\n",
    "split_size = 300 \n",
    "train_data = df_train_val_np[:train_size + val_size - split_size,]\n",
    "val_data = df_train_val_np[train_size + val_size - split_size:,]\n",
    "input_texts, target_texts = clean_texts(train_data[:,1], train_data[:,0])\n",
    "input_word_index, target_word_index, max_input_seq_len, max_target_seq_len = analyse_texts(input_texts, target_texts)\n",
    "input_pad_len = 80\n",
    "target_pad_len = 60\n",
    "num_input_words = len(input_word_index) - 1\n",
    "num_target_words = len(target_word_index) - 1\n",
    "inverted_input_word_index = {value: key for key,value in input_word_index.items()}\n",
    "inverted_target_word_index = {value: key for (key,value) in target_word_index.items()}\n",
    "input_embedding_matrix, target_embedding_matrix = load_embedding_data_get_matrices(inverted_input_word_index, inverted_target_word_index)\n",
    "encoder_input_data, decoder_input_data, decoder_output_data = create_model_data(input_texts, target_texts, input_word_index, target_word_index, input_pad_len, target_pad_len)\n",
    "\n",
    "input_texts_val, target_texts_val = clean_texts(val_data[:,1], val_data[:,0])\n",
    "encoder_input_data_val, decoder_input_data_val, decoder_output_data_val = create_model_data(input_texts_val, target_texts_val, input_word_index, target_word_index, input_pad_len, target_pad_len)\n",
    "\n",
    "input_texts_test, target_texts_test = clean_texts_df(df_test)\n",
    "encoder_input_data_test, decoder_input_data_test, decoder_output_data_test = create_model_data(input_texts_test, target_texts_test, input_word_index, target_word_index, input_pad_len, target_pad_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79d59ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 7s 84ms/step - loss: 1.1941 - acc: 0.8315 - val_loss: 0.8315 - val_acc: 0.8528\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.8349 - acc: 0.8557 - val_loss: 0.7124 - val_acc: 0.8693\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.7765 - acc: 0.8636 - val_loss: 0.6976 - val_acc: 0.8701\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.7491 - acc: 0.8666 - val_loss: 0.6653 - val_acc: 0.8772\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.7130 - acc: 0.8696 - val_loss: 0.6275 - val_acc: 0.8814\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.6818 - acc: 0.8729 - val_loss: 0.5996 - val_acc: 0.8842\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.6504 - acc: 0.8773 - val_loss: 0.5754 - val_acc: 0.8881\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.6143 - acc: 0.8822 - val_loss: 0.5514 - val_acc: 0.8918\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.5796 - acc: 0.8872 - val_loss: 0.5160 - val_acc: 0.8959\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.5520 - acc: 0.8912 - val_loss: 0.4977 - val_acc: 0.9001\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.5279 - acc: 0.8948 - val_loss: 0.4822 - val_acc: 0.9012\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.5068 - acc: 0.8979 - val_loss: 0.4698 - val_acc: 0.9027\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.4902 - acc: 0.9003 - val_loss: 0.4613 - val_acc: 0.9047\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.4764 - acc: 0.9018 - val_loss: 0.4482 - val_acc: 0.9061\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.4604 - acc: 0.9044 - val_loss: 0.4396 - val_acc: 0.9088\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.4470 - acc: 0.9060 - val_loss: 0.4372 - val_acc: 0.9076\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.4387 - acc: 0.9069 - val_loss: 0.4237 - val_acc: 0.9118\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.4260 - acc: 0.9089 - val_loss: 0.4196 - val_acc: 0.9111\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.4172 - acc: 0.9102 - val_loss: 0.4133 - val_acc: 0.9140\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.4081 - acc: 0.9117 - val_loss: 0.4109 - val_acc: 0.9122\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.3967 - acc: 0.9134 - val_loss: 0.4175 - val_acc: 0.9125\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.3897 - acc: 0.9143 - val_loss: 0.4001 - val_acc: 0.9156\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.3800 - acc: 0.9157 - val_loss: 0.4055 - val_acc: 0.9129\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.3722 - acc: 0.9171 - val_loss: 0.4113 - val_acc: 0.9105\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.3678 - acc: 0.9176 - val_loss: 0.4017 - val_acc: 0.9157\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.3595 - acc: 0.9190 - val_loss: 0.3950 - val_acc: 0.9168\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.3521 - acc: 0.9201 - val_loss: 0.3987 - val_acc: 0.9161\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.3452 - acc: 0.9211 - val_loss: 0.3930 - val_acc: 0.9164\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.3411 - acc: 0.9217 - val_loss: 0.4015 - val_acc: 0.9164\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.3331 - acc: 0.9230 - val_loss: 0.4023 - val_acc: 0.9162\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.3249 - acc: 0.9241 - val_loss: 0.4001 - val_acc: 0.9167\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.3193 - acc: 0.9254 - val_loss: 0.3969 - val_acc: 0.9177\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.3168 - acc: 0.9254 - val_loss: 0.4017 - val_acc: 0.9149\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.3077 - acc: 0.9276 - val_loss: 0.3976 - val_acc: 0.9179\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.3031 - acc: 0.9279 - val_loss: 0.4105 - val_acc: 0.9166\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.2996 - acc: 0.9281 - val_loss: 0.3991 - val_acc: 0.9184\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.2916 - acc: 0.9299 - val_loss: 0.4025 - val_acc: 0.9162\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 0.2897 - acc: 0.9301 - val_loss: 0.4002 - val_acc: 0.9167\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.2811 - acc: 0.9316 - val_loss: 0.4103 - val_acc: 0.9144\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.2776 - acc: 0.9321 - val_loss: 0.4034 - val_acc: 0.9164\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 0.2718 - acc: 0.9333 - val_loss: 0.4093 - val_acc: 0.9164\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.2670 - acc: 0.9340 - val_loss: 0.4078 - val_acc: 0.9164\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.2601 - acc: 0.9354 - val_loss: 0.4076 - val_acc: 0.9176\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 0.2586 - acc: 0.9356 - val_loss: 0.4156 - val_acc: 0.9160\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.2517 - acc: 0.9370 - val_loss: 0.4160 - val_acc: 0.9162\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.2418 - acc: 0.9387 - val_loss: 0.4245 - val_acc: 0.9144\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.2440 - acc: 0.9381 - val_loss: 0.4274 - val_acc: 0.9156\n",
      "Epoch 48/200\n",
      "57/58 [============================>.] - ETA: 0s - loss: 0.2318 - acc: 0.9412Restoring model weights from the end of the best epoch: 28.\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 0.2317 - acc: 0.9412 - val_loss: 0.4199 - val_acc: 0.9171\n",
      "Epoch 48: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_for_evaluation = Transformer_Translation_Model(num_input_words, num_target_words, input_embedding_matrix, target_embedding_matrix)\n",
    "\n",
    "other_layers = model_for_evaluation.layers\n",
    "embedding_layers = [] \n",
    "optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers = [(Adam(learning_rate), other_layers), (Adam(learning_rate), embedding_layers)])\n",
    "model_for_evaluation.compile(optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "early_stopping_safe = EarlyStopping(patience = 20, restore_best_weights = True, monitor = 'val_loss', mode = 'min', verbose = 1)\n",
    "history = model_for_evaluation.fit([encoder_input_data, decoder_input_data], decoder_output_data, validation_data = ([encoder_input_data_val, decoder_input_data_val], decoder_output_data_val), epochs = 200, batch_size = 128, verbose = 1, callbacks = [early_stopping_safe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "478768af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer__translation__model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_4 (Functional)        (None, 80, 300)           3837512   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_7 (InputLayer)      [(None, 80)]              0         |\n",
      "|                                                               |\n",
      "| custom_dropout_2 (CustomDro  (None, 80)             0         |\n",
      "| pout)                                                         |\n",
      "|                                                               |\n",
      "| embedding_4 (Embedding)   (None, 80, 300)           640800    |\n",
      "|                                                               |\n",
      "| sine_position_encoding_4 (S  (None, 80, 300)        0         |\n",
      "| inePositionEncoding)                                          |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_14 (TF  (None, 80, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| multi_head_attention_6 (Mul  (None, 80, 300)        2887500   |\n",
      "| tiHeadAttention)                                              |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_15 (TF  (None, 80, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| layer_normalization_10 (Lay  (None, 80, 300)        600       |\n",
      "| erNormalization)                                              |\n",
      "|                                                               |\n",
      "| dense_10 (Dense)          (None, 80, 512)           154112    |\n",
      "|                                                               |\n",
      "| dense_11 (Dense)          (None, 80, 300)           153900    |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_16 (TF  (None, 80, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| layer_normalization_11 (Lay  (None, 80, 300)        600       |\n",
      "| erNormalization)                                              |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " model_5 (Functional)        (None, 60, 766)           6956178   \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_8 (InputLayer)      [(None, 60)]              0         |\n",
      "|                                                               |\n",
      "| embedding_5 (Embedding)   (None, 60, 300)           640800    |\n",
      "|                                                               |\n",
      "| sine_position_encoding_5 (S  (None, 60, 300)        0         |\n",
      "| inePositionEncoding)                                          |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_17 (TF  (None, 60, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| tf.compat.v1.shape_2 (TFOpL  (3,)                   0         |\n",
      "| ambda)                                                        |\n",
      "|                                                               |\n",
      "| tf.__operators__.getitem_11  ()                     0         |\n",
      "|  (SlicingOpLambda)                                            |\n",
      "|                                                               |\n",
      "| tf.range_4 (TFOpLambda)   (60,)                     0         |\n",
      "|                                                               |\n",
      "| tf.__operators__.getitem_12  (60, 1)                0         |\n",
      "|  (SlicingOpLambda)                                            |\n",
      "|                                                               |\n",
      "| tf.range_5 (TFOpLambda)   (60,)                     0         |\n",
      "|                                                               |\n",
      "| tf.math.greater_equal_2 (TF  (60, 60)               0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| tf.__operators__.getitem_10  ()                     0         |\n",
      "|  (SlicingOpLambda)                                            |\n",
      "|                                                               |\n",
      "| tf.cast_2 (TFOpLambda)    (60, 60)                  0         |\n",
      "|                                                               |\n",
      "| tf.__operators__.getitem_13  ()                     0         |\n",
      "|  (SlicingOpLambda)                                            |\n",
      "|                                                               |\n",
      "| tf.__operators__.getitem_14  ()                     0         |\n",
      "|  (SlicingOpLambda)                                            |\n",
      "|                                                               |\n",
      "| tf.expand_dims_2 (TFOpLambd  (1,)                   0         |\n",
      "| a)                                                            |\n",
      "|                                                               |\n",
      "| tf.reshape_2 (TFOpLambda)  (1, 60, 60)              0         |\n",
      "|                                                               |\n",
      "| tf.concat_2 (TFOpLambda)  (3,)                      0         |\n",
      "|                                                               |\n",
      "| tf.tile_2 (TFOpLambda)    (None, 60, 60)            0         |\n",
      "|                                                               |\n",
      "| multi_head_attention_7 (Mul  (None, 60, 300)        2887500   |\n",
      "| tiHeadAttention)                                              |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_18 (TF  (None, 60, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| layer_normalization_12 (Lay  (None, 60, 300)        600       |\n",
      "| erNormalization)                                              |\n",
      "|                                                               |\n",
      "| input_9 (InputLayer)      [(None, 80, 300)]         0         |\n",
      "|                                                               |\n",
      "| multi_head_attention_8 (Mul  (None, 60, 300)        2887500   |\n",
      "| tiHeadAttention)                                              |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_19 (TF  (None, 60, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| layer_normalization_13 (Lay  (None, 60, 300)        600       |\n",
      "| erNormalization)                                              |\n",
      "|                                                               |\n",
      "| dense_12 (Dense)          (None, 60, 512)           154112    |\n",
      "|                                                               |\n",
      "| dense_13 (Dense)          (None, 60, 300)           153900    |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_20 (TF  (None, 60, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| layer_normalization_14 (Lay  (None, 60, 300)        600       |\n",
      "| erNormalization)                                              |\n",
      "|                                                               |\n",
      "| dropout_2 (Dropout)       (None, 60, 300)           0         |\n",
      "|                                                               |\n",
      "| dense_14 (Dense)          (None, 60, 766)           230566    |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " transformer (Functional)    (None, 60, 766)           10793690  \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_7 (InputLayer)      [(None, 80)]              0         |\n",
      "|                                                               |\n",
      "| custom_dropout_2 (CustomDro  (None, 80)             0         |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| pout)                                                         |\n",
      "|                                                               |\n",
      "| embedding_4 (Embedding)   (None, 80, 300)           640800    |\n",
      "|                                                               |\n",
      "| sine_position_encoding_4 (S  (None, 80, 300)        0         |\n",
      "| inePositionEncoding)                                          |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_14 (TF  (None, 80, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| multi_head_attention_6 (Mul  (None, 80, 300)        2887500   |\n",
      "| tiHeadAttention)                                              |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_15 (TF  (None, 80, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| layer_normalization_10 (Lay  (None, 80, 300)        600       |\n",
      "| erNormalization)                                              |\n",
      "|                                                               |\n",
      "| dense_10 (Dense)          (None, 80, 512)           154112    |\n",
      "|                                                               |\n",
      "| dense_11 (Dense)          (None, 80, 300)           153900    |\n",
      "|                                                               |\n",
      "| tf.__operators__.add_16 (TF  (None, 80, 300)        0         |\n",
      "| OpLambda)                                                     |\n",
      "|                                                               |\n",
      "| input_8 (InputLayer)      [(None, 60)]              0         |\n",
      "|                                                               |\n",
      "| layer_normalization_11 (Lay  (None, 80, 300)        600       |\n",
      "| erNormalization)                                              |\n",
      "|                                                               |\n",
      "| model_5 (Functional)      (None, 60, 766)           6956178   |\n",
      "||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\n",
      "|| input_8 (InputLayer)    [(None, 60)]              0         ||\n",
      "||                                                             ||\n",
      "|| embedding_5 (Embedding)  (None, 60, 300)          640800    ||\n",
      "||                                                             ||\n",
      "|| sine_position_encoding_5 (S  (None, 60, 300)      0         ||\n",
      "|| inePositionEncoding)                                        ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.add_17 (TF  (None, 60, 300)      0         ||\n",
      "|| OpLambda)                                                   ||\n",
      "||                                                             ||\n",
      "|| tf.compat.v1.shape_2 (TFOpL  (3,)                 0         ||\n",
      "|| ambda)                                                      ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.getitem_11  ()                   0         ||\n",
      "||  (SlicingOpLambda)                                          ||\n",
      "||                                                             ||\n",
      "|| tf.range_4 (TFOpLambda)  (60,)                    0         ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.getitem_12  (60, 1)              0         ||\n",
      "||  (SlicingOpLambda)                                          ||\n",
      "||                                                             ||\n",
      "|| tf.range_5 (TFOpLambda)  (60,)                    0         ||\n",
      "||                                                             ||\n",
      "|| tf.math.greater_equal_2 (TF  (60, 60)             0         ||\n",
      "|| OpLambda)                                                   ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.getitem_10  ()                   0         ||\n",
      "||  (SlicingOpLambda)                                          ||\n",
      "||                                                             ||\n",
      "|| tf.cast_2 (TFOpLambda)  (60, 60)                  0         ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.getitem_13  ()                   0         ||\n",
      "||  (SlicingOpLambda)                                          ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.getitem_14  ()                   0         ||\n",
      "||  (SlicingOpLambda)                                          ||\n",
      "||                                                             ||\n",
      "|| tf.expand_dims_2 (TFOpLambd  (1,)                 0         ||\n",
      "|| a)                                                          ||\n",
      "||                                                             ||\n",
      "|| tf.reshape_2 (TFOpLambda)  (1, 60, 60)            0         ||\n",
      "||                                                             ||\n",
      "|| tf.concat_2 (TFOpLambda)  (3,)                    0         ||\n",
      "||                                                             ||\n",
      "|| tf.tile_2 (TFOpLambda)  (None, 60, 60)            0         ||\n",
      "||                                                             ||\n",
      "|| multi_head_attention_7 (Mul  (None, 60, 300)      2887500   ||\n",
      "|| tiHeadAttention)                                            ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.add_18 (TF  (None, 60, 300)      0         ||\n",
      "|| OpLambda)                                                   ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_12 (Lay  (None, 60, 300)      600       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| input_9 (InputLayer)    [(None, 80, 300)]         0         ||\n",
      "||                                                             ||\n",
      "|| multi_head_attention_8 (Mul  (None, 60, 300)      2887500   ||\n",
      "|| tiHeadAttention)                                            ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.add_19 (TF  (None, 60, 300)      0         ||\n",
      "|| OpLambda)                                                   ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_13 (Lay  (None, 60, 300)      600       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| dense_12 (Dense)        (None, 60, 512)           154112    ||\n",
      "||                                                             ||\n",
      "|| dense_13 (Dense)        (None, 60, 300)           153900    ||\n",
      "||                                                             ||\n",
      "|| tf.__operators__.add_20 (TF  (None, 60, 300)      0         ||\n",
      "|| OpLambda)                                                   ||\n",
      "||                                                             ||\n",
      "|| layer_normalization_14 (Lay  (None, 60, 300)      600       ||\n",
      "|| erNormalization)                                            ||\n",
      "||                                                             ||\n",
      "|| dropout_2 (Dropout)     (None, 60, 300)           0         ||\n",
      "||                                                             ||\n",
      "|| dense_14 (Dense)        (None, 60, 766)           230566    ||\n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      "=================================================================\n",
      "Total params: 10,793,690\n",
      "Trainable params: 10,152,890\n",
      "Non-trainable params: 640,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_evaluation.summary(expand_nested = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee91ebb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e6f8f4a0b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_counter = range(len(history.history['loss']))\n",
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "ax1.plot(epoch_counter, history.history['loss'], label = 'Train Loss')\n",
    "ax1.plot(epoch_counter, history.history['val_loss'], label = 'Validation Loss', linestyle = 'dashed')\n",
    "ax1.legend()\n",
    "ax2.plot(epoch_counter, history.history['acc'], label = 'Train accuracy')\n",
    "ax2.plot(epoch_counter, history.history['val_acc'], label = 'Validation Accuracy', linestyle = 'dashed')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f184763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test data:\n",
      "Word Error Rate:  63.02460142172897\n",
      "BLEU4(smooth):  23.950336243540228\n",
      "BLEU3(smooth):  33.031134571256985\n",
      "BLEU2(smooth):  45.623642166666365\n",
      "BLEU1(smooth):  60.89687900027197\n"
     ]
    }
   ],
   "source": [
    "wer, smooth_bleu4, smooth_bleu3, smooth_bleu2, smooth_bleu1 = evaluate(model_for_evaluation, input_texts_test, target_texts_test, input_word_index, target_word_index, inverted_target_word_index, input_pad_len, target_pad_len)\n",
    "print('Results on test data:')\n",
    "print('Word Error Rate: ', 100*wer) \n",
    "print('BLEU4(smooth): ', 100*smooth_bleu4) \n",
    "print('BLEU3(smooth): ', 100*smooth_bleu3) \n",
    "print('BLEU2(smooth): ', 100*smooth_bleu2) \n",
    "print('BLEU1(smooth): ', 100*smooth_bleu1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0b45201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originalna recenica:\n",
      "und nun die wettervorhersage für morgen dienstag den dreizehnten oktober\n",
      "Prevod:\n",
      "JETZT WETTER WIE-AUSSEHEN MORGEN DIENSTAG DREIZEHN OKTOBER \n",
      "Referenca:\n",
      "JETZT MORGEN WETTER WIE-AUSSEHEN DREIZEHN OKTOBER\n",
      "\n",
      "\n",
      "Originalna recenica:\n",
      "im westen ist es freundlich\n",
      "Prevod:\n",
      "WEST FREUNDLICH \n",
      "Referenca:\n",
      "WEST FREUNDLICH\n",
      "\n",
      "\n",
      "Originalna recenica:\n",
      "ähnliches wetter dann auch am donnerstag\n",
      "Prevod:\n",
      "GLEICH DONNERSTAG AUCH \n",
      "Referenca:\n",
      "AUCH DONNERSTAG\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_examples = 3\n",
    "starting_index = 38\n",
    "translation_examples = translate_from_text(model_for_evaluation, input_texts_test[starting_index:starting_index + n_examples], input_word_index, target_word_index, inverted_target_word_index, input_pad_len, target_pad_len)\n",
    "for i in range(n_examples):\n",
    "    print('Originalna recenica:')\n",
    "    print(input_texts_test[starting_index + i])\n",
    "    print('Prevod:')\n",
    "    print(translation_examples[i])\n",
    "    print('Referenca:')\n",
    "    print(df_test['orth'][starting_index + i])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
